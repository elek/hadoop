<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
<!-- Generated by the JDiff Javadoc doclet -->
<!-- (http://www.jdiff.org) -->
<!-- on Tue Aug 30 07:10:26 UTC 2016 -->

<api
  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
  xsi:noNamespaceSchemaLocation='api.xsd'
  name="Apache Hadoop HDFS 3.0.0-alpha1"
  jdversion="1.0.9">

<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.ExcludePrivateAnnotationsJDiffDoclet -docletpath /build/source/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-annotations.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs/target/jdiff.jar -verbose -classpath /build/source/hadoop-hdfs-project/hadoop-hdfs/target/classes:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.0.0-alpha1.jar:/usr/lib/jvm/java-8-oracle/lib/tools.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.0.0-alpha1.jar:/maven/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/maven/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/maven/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/3.9/nimbus-jose-jwt-3.9.jar:/maven/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/maven/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar:/maven/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/maven/jline/jline/0.9.94/jline-0.9.94.jar:/maven/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.0-RC2/kerb-simplekdc-1.0.0-RC2.jar:/maven/org/apache/kerby/kerby-config/1.0.0-RC2/kerby-config-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-core/1.0.0-RC2/kerb-core-1.0.0-RC2.jar:/maven/org/apache/kerby/kerby-asn1/1.0.0-RC2/kerby-asn1-1.0.0-RC2.jar:/maven/org/apache/kerby/kerby-pkix/1.0.0-RC2/kerby-pkix-1.0.0-RC2.jar:/maven/org/apache/kerby/kerby-util/1.0.0-RC2/kerby-util-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-client/1.0.0-RC2/kerb-client-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-common/1.0.0-RC2/kerb-common-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-util/1.0.0-RC2/kerb-util-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-crypto/1.0.0-RC2/kerb-crypto-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-server/1.0.0-RC2/kerb-server-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-identity/1.0.0-RC2/kerb-identity-1.0.0-RC2.jar:/maven/org/apache/kerby/kerb-admin/1.0.0-RC2/kerb-admin-1.0.0-RC2.jar:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.0.0-alpha1.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/commons-net/commons-net/3.1/commons-net-3.1.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/maven/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/maven/javax/activation/activation/1.1/activation-1.1.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/maven/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/maven/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/maven/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/maven/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/maven/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/maven/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/maven/com/google/re2j/re2j/1.0/re2j-1.0.jar:/maven/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/maven/com/jcraft/jsch/0.1.51/jsch-0.1.51.jar:/maven/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/maven/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/maven/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/maven/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/maven/org/tukaani/xz/1.0/xz-1.0.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/hadoop-hdfs-client-3.0.0-alpha1.jar:/maven/com/squareup/okhttp/okhttp/2.4.0/okhttp-2.4.0.jar:/maven/com/squareup/okio/okio/1.4.0/okio-1.4.0.jar:/maven/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/maven/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/maven/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/maven/commons-io/commons-io/2.4/commons-io-2.4.jar:/maven/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/maven/log4j/log4j/1.2.17/log4j-1.2.17.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/maven/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/maven/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/maven/io/netty/netty-all/4.1.0.Beta5/netty-all-4.1.0.Beta5.jar:/maven/com/twitter/hpack/0.11.0/hpack-0.11.0.jar:/maven/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/maven/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/maven/org/apache/htrace/htrace-core4/4.0.1-incubating/htrace-core4-4.0.1-incubating.jar:/maven/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar -sourcepath /build/source/hadoop-hdfs-project/hadoop-hdfs/src/main/java -doclet org.apache.hadoop.classification.tools.ExcludePrivateAnnotationsJDiffDoclet -docletpath /build/source/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-annotations.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs/target/jdiff.jar -apidir /build/source/hadoop-hdfs-project/hadoop-hdfs/target/site/jdiff/xml -apiname Apache Hadoop HDFS 3.0.0-alpha1 -->
<package name="org.apache.hadoop.hdfs">
  <!-- start class org.apache.hadoop.hdfs.DFSUtil.ConfiguredNNAddress -->
  <class name="DFSUtil.ConfiguredNNAddress" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getNameserviceId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getNamenodeId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAddress" return="java.net.InetSocketAddress"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Represent one of the NameNodes configured in the cluster.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.DFSUtil.ConfiguredNNAddress -->
  <!-- start class org.apache.hadoop.hdfs.HdfsDtFetcher -->
  <class name="HdfsDtFetcher" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.security.token.DtFetcher"/>
    <constructor name="HdfsDtFetcher"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getServiceName" return="org.apache.hadoop.io.Text"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the service name for HDFS, which is also a valid URL prefix.]]>
      </doc>
    </method>
    <method name="isTokenRequired" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="addDelegationTokens" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="creds" type="org.apache.hadoop.security.Credentials"/>
      <param name="renewer" type="java.lang.String"/>
      <param name="url" type="java.lang.String"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Returns Token object via FileSystem, null if bad argument.
  @param conf - a Configuration object used with FileSystem.get()
  @param creds - a Credentials object to which token(s) will be added
  @param renewer  - the renewer to send with the token request
  @param url  - the URL to which the request is sent
  @return a Token, or null if fetch fails.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[DtFetcher is an interface which permits the abstraction and separation of
  delegation token fetch implementaions across different packages and
  compilation units.  Resolution of fetcher impl will be done at runtime.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.HdfsDtFetcher -->
  <!-- start class org.apache.hadoop.hdfs.SWebHdfsDtFetcher -->
  <class name="SWebHdfsDtFetcher" extends="org.apache.hadoop.hdfs.HdfsDtFetcher"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SWebHdfsDtFetcher"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getServiceName" return="org.apache.hadoop.io.Text"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[DtFetcher for SWebHdfsFileSystem using the base class HdfsDtFetcher impl.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.SWebHdfsDtFetcher -->
  <!-- start class org.apache.hadoop.hdfs.WebHdfsDtFetcher -->
  <class name="WebHdfsDtFetcher" extends="org.apache.hadoop.hdfs.HdfsDtFetcher"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="WebHdfsDtFetcher"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getServiceName" return="org.apache.hadoop.io.Text"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[DtFetcher for WebHdfsFileSystem using the base class HdfsDtFetcher impl.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.WebHdfsDtFetcher -->
  <doc>
  <![CDATA[<p>A distributed implementation of {@link
org.apache.hadoop.fs.FileSystem}.  This is loosely modelled after
Google's <a href="http://research.google.com/archive/gfs.html">GFS</a>.</p>

<p>The most important difference is that unlike GFS, Hadoop DFS files 
have strictly one writer at any one time.  Bytes are always appended 
to the end of the writer's stream.  There is no notion of "record appends"
or "mutations" that are then checked or reordered.  Writers simply emit 
a byte stream.  That byte stream is guaranteed to be stored in the 
order written.</p>]]>
  </doc>
</package>
<package name="org.apache.hadoop.hdfs.client">
  <!-- start class org.apache.hadoop.hdfs.client.CreateEncryptionZoneFlag -->
  <class name="CreateEncryptionZoneFlag" extends="java.lang.Enum"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.client.CreateEncryptionZoneFlag[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.client.CreateEncryptionZoneFlag"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.client.CreateEncryptionZoneFlag"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="mode" type="short"/>
    </method>
    <method name="getMode" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[CreateEncryptionZoneFlag is used in
 {@link HdfsAdmin#createEncryptionZone(Path, String, EnumSet)} to indicate
 what should be done when creating an encryption zone.

 Use CreateEncryptionZoneFlag as follows:
 <ol>
   <li>PROVISION_TRASH - provision a trash directory for the encryption zone
   to support soft delete.</li>
 </ol>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.CreateEncryptionZoneFlag -->
  <!-- start class org.apache.hadoop.hdfs.client.HdfsAdmin -->
  <class name="HdfsAdmin" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HdfsAdmin" type="java.net.URI, org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a new HdfsAdmin client.
 
 @param uri the unique URI of the HDFS file system to administer
 @param conf configuration
 @throws IOException in the event the file system could not be created]]>
      </doc>
    </constructor>
    <method name="setQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="quota" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the namespace quota (count of files, directories, and sym links) for a
 directory.
 
 @param src the path to set the quota for
 @param quota the value to set for the quota
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="clearQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Clear the namespace quota (count of files, directories and sym links) for a
 directory.
 
 @param src the path to clear the quota of
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="setSpaceQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="spaceQuota" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the storage space quota (size of files) for a directory. Note that
 directories and sym links do not occupy storage space.
 
 @param src the path to set the space quota of
 @param spaceQuota the value to set for the space quota
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="clearSpaceQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Clear the storage space quota (size of files) for a directory. Note that
 directories and sym links do not occupy storage space.
 
 @param src the path to clear the space quota of
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="setQuotaByStorageType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="type" type="org.apache.hadoop.fs.StorageType"/>
      <param name="quota" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the quota by storage type for a directory. Note that
 directories and sym links do not occupy storage type quota.

 @param src the target directory to set the quota by storage type
 @param type the storage type to set for quota by storage type
 @param quota the value to set for quota by storage type
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="clearQuotaByStorageType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="type" type="org.apache.hadoop.fs.StorageType"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Clear the space quota by storage type for a directory. Note that
 directories and sym links do not occupy storage type quota.

 @param src the target directory to clear the quota by storage type
 @param type the storage type to clear for quota by storage type
 @throws IOException in the event of error]]>
      </doc>
    </method>
    <method name="allowSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Allow snapshot on a directory.
 @param path The path of the directory where snapshots will be taken.]]>
      </doc>
    </method>
    <method name="disallowSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Disallow snapshot on a directory.
 @param path The path of the snapshottable directory.]]>
      </doc>
    </method>
    <method name="addCacheDirective" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"/>
      <param name="flags" type="java.util.EnumSet"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Add a new CacheDirectiveInfo.
 
 @param info Information about a directive to add.
 @param flags {@link CacheFlag}s to use for this operation.
 @return the ID of the directive that was created.
 @throws IOException if the directive could not be added]]>
      </doc>
    </method>
    <method name="modifyCacheDirective"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"/>
      <param name="flags" type="java.util.EnumSet"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Modify a CacheDirective.
 
 @param info Information about the directive to modify. You must set the ID
          to indicate which CacheDirective you want to modify.
 @param flags {@link CacheFlag}s to use for this operation.
 @throws IOException if the directive could not be modified]]>
      </doc>
    </method>
    <method name="removeCacheDirective"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Remove a CacheDirective.
 
 @param id identifier of the CacheDirectiveInfo to remove
 @throws IOException if the directive could not be removed]]>
      </doc>
    </method>
    <method name="listCacheDirectives" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="filter" type="org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[List cache directives. Incrementally fetches results from the server.
 
 @param filter Filter parameters to use when listing the directives, null to
               list all directives visible to us.
 @return A RemoteIterator which returns CacheDirectiveInfo objects.]]>
      </doc>
    </method>
    <method name="addCachePool"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CachePoolInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Add a cache pool.

 @param info
          The request to add a cache pool.
 @throws IOException 
          If the request could not be completed.]]>
      </doc>
    </method>
    <method name="modifyCachePool"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.CachePoolInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Modify an existing cache pool.

 @param info
          The request to modify a cache pool.
 @throws IOException 
          If the request could not be completed.]]>
      </doc>
    </method>
    <method name="removeCachePool"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="poolName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Remove a cache pool.

 @param poolName
          Name of the cache pool to remove.
 @throws IOException 
          if the cache pool did not exist, or could not be removed.]]>
      </doc>
    </method>
    <method name="listCachePools" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[List all cache pools.

 @return A remote iterator from which you can get CachePoolEntry objects.
          Requests will be made as needed.
 @throws IOException
          If there was an error listing cache pools.]]>
      </doc>
    </method>
    <method name="createEncryptionZone"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <param name="keyName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <doc>
      <![CDATA[Create an encryption zone rooted at an empty existing directory, using the
 specified encryption key. An encryption zone has an associated encryption
 key used when reading and writing files within the zone.

 @param path    The path of the root of the encryption zone. Must refer to
                an empty, existing directory.
 @param keyName Name of key available at the KeyProvider.
 @throws IOException            if there was a general IO exception
 @throws AccessControlException if the caller does not have access to path
 @throws FileNotFoundException  if the path does not exist]]>
      </doc>
    </method>
    <method name="createEncryptionZone"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <param name="keyName" type="java.lang.String"/>
      <param name="flags" type="java.util.EnumSet"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="HadoopIllegalArgumentException" type="org.apache.hadoop.HadoopIllegalArgumentException"/>
      <doc>
      <![CDATA[Create an encryption zone rooted at an empty existing directory, using the
 specified encryption key. An encryption zone has an associated encryption
 key used when reading and writing files within the zone.

 Additional options, such as provisioning the trash directory, can be
 specified using {@link CreateEncryptionZoneFlag} flags.

 @param path    The path of the root of the encryption zone. Must refer to
                an empty, existing directory.
 @param keyName Name of key available at the KeyProvider.
 @param flags   flags for this operation.
 @throws IOException            if there was a general IO exception
 @throws AccessControlException if the caller does not have access to path
 @throws FileNotFoundException  if the path does not exist
 @throws HadoopIllegalArgumentException if the flags are invalid]]>
      </doc>
    </method>
    <method name="provisionEncryptionZoneTrash"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Provision a trash directory for a given encryption zone.

 @param path the root of the encryption zone
 @throws IOException if the trash directory can not be created.]]>
      </doc>
    </method>
    <method name="getEncryptionZoneForPath" return="org.apache.hadoop.hdfs.protocol.EncryptionZone"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <doc>
      <![CDATA[Get the path of the encryption zone for a given file or directory.

 @param path The path to get the ez for.

 @return The EncryptionZone of the ez, or null if path is not in an ez.
 @throws IOException            if there was a general IO exception
 @throws AccessControlException if the caller does not have access to path
 @throws FileNotFoundException  if the path does not exist]]>
      </doc>
    </method>
    <method name="listEncryptionZones" return="org.apache.hadoop.fs.RemoteIterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns a RemoteIterator which can be used to list the encryption zones
 in HDFS. For large numbers of encryption zones, the iterator will fetch
 the list of zones in a number of small batches.
 <p/>
 Since the list is fetched in batches, it does not represent a
 consistent snapshot of the entire list of encryption zones.
 <p/>
 This method can only be called by HDFS superusers.]]>
      </doc>
    </method>
    <method name="getInotifyEventStream" return="org.apache.hadoop.hdfs.DFSInotifyEventInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Exposes a stream of namesystem events. Only events occurring after the
 stream is created are available.
 See {@link org.apache.hadoop.hdfs.DFSInotifyEventInputStream}
 for information on stream usage.
 See {@link org.apache.hadoop.hdfs.inotify.Event}
 for information on the available events.
 <p/>
 Inotify users may want to tune the following HDFS parameters to
 ensure that enough extra HDFS edits are saved to support inotify clients
 that fall behind the current state of the namespace while reading events.
 The default parameter values should generally be reasonable. If edits are
 deleted before their corresponding events can be read, clients will see a
 {@link org.apache.hadoop.hdfs.inotify.MissingEventsException} on
 {@link org.apache.hadoop.hdfs.DFSInotifyEventInputStream} method calls.

 It should generally be sufficient to tune these parameters:
 dfs.namenode.num.extra.edits.retained
 dfs.namenode.max.extra.edits.segments.retained

 Parameters that affect the number of created segments and the number of
 edits that are considered necessary, i.e. do not count towards the
 dfs.namenode.num.extra.edits.retained quota):
 dfs.namenode.checkpoint.period
 dfs.namenode.checkpoint.txns
 dfs.namenode.num.checkpoints.retained
 dfs.ha.log-roll.period
 <p/>
 It is recommended that local journaling be configured
 (dfs.namenode.edits.dir) for inotify (in addition to a shared journal)
 so that edit transfers from the shared journal can be avoided.

 @throws IOException If there was an error obtaining the stream.]]>
      </doc>
    </method>
    <method name="getInotifyEventStream" return="org.apache.hadoop.hdfs.DFSInotifyEventInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="lastReadTxid" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[A version of {@link HdfsAdmin#getInotifyEventStream()} meant for advanced
 users who are aware of HDFS edits up to lastReadTxid (e.g. because they
 have access to an FSImage inclusive of lastReadTxid) and only want to read
 events after this point.]]>
      </doc>
    </method>
    <method name="setStoragePolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <param name="policyName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the source path to the specified storage policy.

 @param src The source path referring to either a directory or a file.
 @param policyName The name of the storage policy.]]>
      </doc>
    </method>
    <method name="unsetStoragePolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Unset the storage policy set for a given file or directory.

 @param src file or directory path.
 @throws IOException]]>
      </doc>
    </method>
    <method name="getStoragePolicy" return="org.apache.hadoop.fs.BlockStoragePolicySpi"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="src" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Query the effective storage policy ID for the given file or directory.

 @param src file or directory path.
 @return storage policy for the given file or directory.
 @throws IOException]]>
      </doc>
    </method>
    <method name="getAllStoragePolicies" return="java.util.Collection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Retrieve all the storage policies supported by HDFS file system.

 @return all storage policies supported by HDFS file system.
 @throws IOException]]>
      </doc>
    </method>
    <method name="setErasureCodingPolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <param name="ecPolicy" type="org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the source path to the specified erasure coding policy.

 @param path The source path referring to a directory.
 @param ecPolicy The erasure coding policy for the directory.
                 If null, the default will be used.
 @throws IOException]]>
      </doc>
    </method>
    <method name="getErasureCodingPolicy" return="org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="org.apache.hadoop.fs.Path"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the erasure coding policy information for the specified path

 @param path
 @return Returns the policy information if file or directory on the path is
          erasure coded. Null otherwise.
 @throws IOException]]>
      </doc>
    </method>
    <method name="getErasureCodingPolicies" return="org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the Erasure coding policies supported.

 @throws IOException]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The public API for performing administrative functions on HDFS. Those writing
 applications against HDFS should prefer this interface to directly accessing
 functionality in DistributedFileSystem or DFSClient.
 
 Note that this is distinct from the similarly-named {@link DFSAdmin}, which
 is a class that provides the functionality for the CLI `hdfs dfsadmin ...'
 commands.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.HdfsAdmin -->
  <!-- start class org.apache.hadoop.hdfs.client.HdfsUtils -->
  <class name="HdfsUtils" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HdfsUtils"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="isHealthy" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="uri" type="java.net.URI"/>
      <doc>
      <![CDATA[Is the HDFS healthy?
 HDFS is considered as healthy if it is up and not in safemode.

 @param uri the HDFS URI.  Note that the URI path is ignored.
 @return true if HDFS is healthy; false, otherwise.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The public utility API for HDFS.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.client.HdfsUtils -->
</package>
<package name="org.apache.hadoop.hdfs.net">
</package>
<package name="org.apache.hadoop.hdfs.protocol">
  <!-- start class org.apache.hadoop.hdfs.protocol.BlockListAsLongs.Builder -->
  <class name="BlockListAsLongs.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="add"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="replica" type="org.apache.hadoop.hdfs.server.datanode.Replica"/>
    </method>
    <method name="getNumberOfBlocks" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.protocol.BlockListAsLongs"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.BlockListAsLongs.Builder -->
  <!-- start class org.apache.hadoop.hdfs.protocol.FSLimitException.MaxDirectoryItemsExceededException -->
  <class name="FSLimitException.MaxDirectoryItemsExceededException" extends="org.apache.hadoop.hdfs.protocol.FSLimitException"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="MaxDirectoryItemsExceededException"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="MaxDirectoryItemsExceededException" type="java.lang.String"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="MaxDirectoryItemsExceededException" type="java.lang.String, long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getMessage" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="serialVersionUID" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Directory has too many items]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.FSLimitException.MaxDirectoryItemsExceededException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.FSLimitException.PathComponentTooLongException -->
  <class name="FSLimitException.PathComponentTooLongException" extends="org.apache.hadoop.hdfs.protocol.FSLimitException"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="PathComponentTooLongException"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="PathComponentTooLongException" type="java.lang.String"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="PathComponentTooLongException" type="long, long, java.lang.String, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getMessage" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="serialVersionUID" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Path component length is too long]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.FSLimitException.PathComponentTooLongException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature -->
  <class name="LayoutVersion.Feature" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature"/>
    <method name="values" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Enums for features that change the layout version before rolling
 upgrade is supported.
 <br><br>
 To add a new layout version:
 <ul>
 <li>Define a new enum constant with a short enum name, the new layout version 
 and description of the added feature.</li>
 <li>When adding a layout version with an ancestor that is not same as
 its immediate predecessor, use the constructor where a specific ancestor
 can be passed.
 </li>
 </ul>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature -->
  <!-- start class org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo -->
  <class name="LayoutVersion.FeatureInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="FeatureInfo" type="int, int, java.lang.String, boolean, org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="FeatureInfo" type="int, int, java.lang.Integer, java.lang.String, boolean, org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getLayoutVersion" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Accessor method for feature layout version 
 @return int lv value]]>
      </doc>
    </method>
    <method name="getAncestorLayoutVersion" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Accessor method for feature ancestor layout version 
 @return int ancestor LV value]]>
      </doc>
    </method>
    <method name="getMinimumCompatibleLayoutVersion" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Accessor method for feature minimum compatible layout version.  If the
 feature does not define a minimum compatible layout version, then this
 method returns the feature's own layout version.  This would indicate
 that the feature cannot provide compatibility with any prior layout
 version.

 @return int minimum compatible LV value]]>
      </doc>
    </method>
    <method name="getDescription" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Accessor method for feature description 
 @return String feature description]]>
      </doc>
    </method>
    <method name="isReservedForOldRelease" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSpecialFeatures" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Feature information.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo -->
  <!-- start interface org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature -->
  <interface name="LayoutVersion.LayoutFeature"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[The interface to be implemented by NameNode and DataNode layout features]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotException -->
  <class name="SnapshotException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotException" type="java.lang.Throwable"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Snapshot related exception.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotException -->
  <!-- start class org.apache.hadoop.hdfs.protocol.SnapshotInfo.Bean -->
  <class name="SnapshotInfo.Bean" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Bean" type="java.lang.String, java.lang.String, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getSnapshotID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshotDirectory" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getModificationTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.SnapshotInfo.Bean -->
</package>
<package name="org.apache.hadoop.hdfs.protocol.datatransfer">
  <!-- start class org.apache.hadoop.hdfs.protocol.datatransfer.WhitelistBasedTrustedChannelResolver -->
  <class name="WhitelistBasedTrustedChannelResolver" extends="org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="WhitelistBasedTrustedChannelResolver"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setConf"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <method name="isTrusted" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isTrusted" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clientAddress" type="java.net.InetAddress"/>
    </method>
    <field name="DFS_DATATRANSFER_SERVER_FIXEDWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form fixed whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_SERVER_VARIABLEWHITELIST_ENABLE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Enables/Disables variable whitelist]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_SERVER_VARIABLEWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form variable whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_SERVER_VARIABLEWHITELIST_CACHE_SECS" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[time in seconds by which the variable whitelist file is checked for updates]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_FIXEDWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form fixed whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_VARIABLEWHITELIST_ENABLE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Enables/Disables variable whitelist]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_VARIABLEWHITELIST_FILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Path to the file to containing subnets and ip addresses to form variable whitelist.]]>
      </doc>
    </field>
    <field name="DFS_DATATRANSFER_CLIENT_VARIABLEWHITELIST_CACHE_SECS" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[time in seconds by which the variable whitelist file is checked for updates]]>
      </doc>
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocol.datatransfer.WhitelistBasedTrustedChannelResolver -->
</package>
<package name="org.apache.hadoop.hdfs.protocol.datatransfer.sasl">
</package>
<package name="org.apache.hadoop.hdfs.protocolPB">
  <!-- start class org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB -->
  <class name="DatanodeProtocolServerSideTranslatorPB" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolPB"/>
    <constructor name="DatanodeProtocolServerSideTranslatorPB" type="org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol, int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="registerDatanode" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.RegisterDatanodeResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.RegisterDatanodeRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="sendHeartbeat" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.HeartbeatResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.HeartbeatRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="blockReport" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="cacheReport" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CacheReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CacheReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="blockReceivedAndDeleted" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReceivedAndDeletedResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReceivedAndDeletedRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="errorReport" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ErrorReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ErrorReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="versionRequest" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.VersionResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.VersionRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="reportBadBlocks" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReportBadBlocksResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReportBadBlocksRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="commitBlockSynchronization" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CommitBlockSynchronizationResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.CommitBlockSynchronizationRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB -->
  <!-- start class org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB -->
  <class name="NamenodeProtocolServerSideTranslatorPB" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolPB"/>
    <constructor name="NamenodeProtocolServerSideTranslatorPB" type="org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getBlocks" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlocksResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlocksRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getBlockKeys" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlockKeysResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetBlockKeysRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getTransactionId" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetTransactionIdResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetTransactionIdRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getMostRecentCheckpointTxId" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetMostRecentCheckpointTxIdResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetMostRecentCheckpointTxIdRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="rollEditLog" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RollEditLogResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RollEditLogRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="errorReport" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.ErrorReportResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.ErrorReportRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="registerSubordinateNamenode" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RegisterResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.RegisterRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="startCheckpoint" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.StartCheckpointResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.StartCheckpointRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="endCheckpoint" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.EndCheckpointResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.EndCheckpointRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getEditLogManifest" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetEditLogManifestResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.GetEditLogManifestRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="versionRequest" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.VersionResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.VersionRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="isUpgradeFinalized" return="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.IsUpgradeFinalizedResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos.IsUpgradeFinalizedRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <doc>
    <![CDATA[Implementation for protobuf service that forwards requests
 received on {@link NamenodeProtocolPB} to the
 {@link NamenodeProtocol} server implementation.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB -->
  <!-- start class org.apache.hadoop.hdfs.protocolPB.PBHelper -->
  <class name="PBHelper" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="convert" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="role" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamenodeRegistrationProto.NamenodeRoleProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamenodeRegistrationProto.NamenodeRoleProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="role" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.StorageInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.server.common.StorageInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.common.StorageInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.StorageInfoProto"/>
      <param name="type" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NodeType"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamenodeRegistrationProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reg" type="org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reg" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamenodeRegistrationProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.BlockWithLocationsProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blk" type="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.BlockWithLocations"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.BlockWithLocations"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.BlockWithLocationsProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.BlocksWithLocationsProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blks" type="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blocks" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.BlocksWithLocationsProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.BlockKeyProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="key" type="org.apache.hadoop.hdfs.security.token.block.BlockKey"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.security.token.block.BlockKey"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="k" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.BlockKeyProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.ExportedBlockKeysProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="keys" type="org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="keys" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.ExportedBlockKeysProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.CheckpointSignatureProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.server.namenode.CheckpointSignature"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.namenode.CheckpointSignature"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.CheckpointSignatureProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.RemoteEditLogProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="log" type="org.apache.hadoop.hdfs.server.protocol.RemoteEditLog"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.RemoteEditLog"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="l" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.RemoteEditLogProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.RemoteEditLogManifestProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="manifest" type="org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="manifest" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.RemoteEditLogManifestProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.CheckpointCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.CheckpointCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamenodeCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.NamenodeCommand"/>
    </method>
    <method name="convertBlockKeys" return="org.apache.hadoop.hdfs.security.token.block.BlockKey[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="list" type="java.util.List"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NamespaceInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamespaceInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NamenodeCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamenodeCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.RecoveringBlockProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.RecoveringBlockProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="state" type="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.ReplicaStateProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.ReplicaStateProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="state" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeRegistrationProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="registration" type="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeRegistrationProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BalancerBandwidthCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bbCmd" type="org.apache.hadoop.hdfs.server.protocol.BalancerBandwidthCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.KeyUpdateCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.KeyUpdateCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockRecoveryCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.FinalizeCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.FinalizeCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.BlockCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockIdCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.hadoop.hdfs.server.protocol.BlockIdCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.DatanodeCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="datanodeCommand" type="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.KeyUpdateCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="keyUpdateCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.KeyUpdateCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.FinalizeCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="finalizeCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.FinalizeCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="recoveryCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockRecoveryCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blkCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockIdCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blkIdCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockIdCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BalancerBandwidthCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="balancerCmd" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BalancerBandwidthCommandProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReceivedDeletedBlockInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="receivedDeletedBlockInfo" type="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.ReceivedDeletedBlockInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.HdfsServerProtos.NamespaceInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.server.protocol.NamespaceInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.NNHAStatusHeartbeat"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.NNHAStatusHeartbeatProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.NNHAStatusHeartbeatProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="hb" type="org.apache.hadoop.hdfs.server.protocol.NNHAStatusHeartbeat"/>
    </method>
    <method name="convertVolumeFailureSummary" return="org.apache.hadoop.hdfs.server.protocol.VolumeFailureSummary"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.VolumeFailureSummaryProto"/>
    </method>
    <method name="convertVolumeFailureSummary" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.VolumeFailureSummaryProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volumeFailureSummary" type="org.apache.hadoop.hdfs.server.protocol.VolumeFailureSummary"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.JournalInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="info" type="org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos.JournalInfoProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.JournalProtocolProtos.JournalInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="j" type="org.apache.hadoop.hdfs.server.protocol.JournalInfo"/>
      <doc>
      <![CDATA[Method used for converting {@link JournalInfoProto} sent from Namenode
 to Journal receivers to {@link NamenodeRegistration}.]]>
      </doc>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockReportContext"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReportContextProto"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockReportContextProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="context" type="org.apache.hadoop.hdfs.server.protocol.BlockReportContext"/>
    </method>
    <method name="convertBlockECReconstructionInfo" return="org.apache.hadoop.hdfs.server.protocol.BlockECReconstructionCommand.BlockECReconstructionInfo"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockEcReconstructionInfoProto" type="org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos.BlockECReconstructionInfoProto"/>
    </method>
    <method name="convertBlockECRecoveryInfo" return="org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos.BlockECReconstructionInfoProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockEcRecoveryInfo" type="org.apache.hadoop.hdfs.server.protocol.BlockECReconstructionCommand.BlockECReconstructionInfo"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockECReconstructionCommandProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blkECReconstructionCmd" type="org.apache.hadoop.hdfs.server.protocol.BlockECReconstructionCommand"/>
    </method>
    <method name="convert" return="org.apache.hadoop.hdfs.server.protocol.BlockECReconstructionCommand"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blkECReconstructionCmdProto" type="org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockECReconstructionCommandProto"/>
    </method>
    <doc>
    <![CDATA[Utilities for converting protobuf classes to and from implementation classes
 and other helper utilities to help in dealing with protobuf.
 
 Note that when converting from an internal type to protobuf type, the
 converter never return null for protobuf type. The check for internal type
 being null must be done before calling the convert() method.

 For those helper methods that convert HDFS client-side data structures from
 and to protobuf, see {@link PBHelperClient}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocolPB.PBHelper -->
  <!-- start class org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolServerSideTranslatorPB -->
  <class name="ReconfigurationProtocolServerSideTranslatorPB" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolPB"/>
    <constructor name="ReconfigurationProtocolServerSideTranslatorPB" type="org.apache.hadoop.hdfs.protocol.ReconfigurationProtocol"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="startReconfiguration" return="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.StartReconfigurationResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.StartReconfigurationRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="listReconfigurableProperties" return="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.ListReconfigurablePropertiesResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="controller" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.ListReconfigurablePropertiesRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <method name="getReconfigurationStatus" return="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.GetReconfigurationStatusResponseProto"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="unused" type="com.google.protobuf.RpcController"/>
      <param name="request" type="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.GetReconfigurationStatusRequestProto"/>
      <exception name="ServiceException" type="com.google.protobuf.ServiceException"/>
    </method>
    <doc>
    <![CDATA[This class is used on the server side. Calls come across the wire for the
 for protocol {@link ReconfigurationProtocolPB}.
 This class translates the PB data types
 to the native data types used inside the NN/DN as specified in the generic
 ReconfigurationProtocol.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolServerSideTranslatorPB -->
  <!-- start class org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolServerSideUtils -->
  <class name="ReconfigurationProtocolServerSideUtils" extends="java.lang.Object"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="listReconfigurableProperties" return="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.ListReconfigurablePropertiesResponseProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reconfigurableProperties" type="java.util.List"/>
    </method>
    <method name="getReconfigurationStatus" return="org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos.GetReconfigurationStatusResponseProto"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="status" type="org.apache.hadoop.conf.ReconfigurationTaskStatus"/>
    </method>
    <doc>
    <![CDATA[This is a server side utility class that handles
 common logic to to parameter reconfiguration.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolServerSideUtils -->
</package>
<package name="org.apache.hadoop.hdfs.qjournal.client">
</package>
<package name="org.apache.hadoop.hdfs.qjournal.protocol">
</package>
<package name="org.apache.hadoop.hdfs.qjournal.protocolPB">
</package>
<package name="org.apache.hadoop.hdfs.qjournal.server">
  <!-- start class org.apache.hadoop.hdfs.qjournal.server.Journal -->
  <class name="Journal" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Unlock and release resources.]]>
      </doc>
    </method>
    <method name="getLastWriterEpoch" return="long"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="heartbeat"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reqInfo" type="org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="isFormatted" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="startLogSegment"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reqInfo" type="org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo"/>
      <param name="txid" type="long"/>
      <param name="layoutVersion" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Start a new segment at the given txid. The previous segment
 must have already been finalized.]]>
      </doc>
    </method>
    <method name="finalizeLogSegment"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reqInfo" type="org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo"/>
      <param name="startTxId" type="long"/>
      <param name="endTxId" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Finalize the log segment at the given transaction ID.]]>
      </doc>
    </method>
    <method name="purgeLogsOlderThan"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reqInfo" type="org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo"/>
      <param name="minTxIdToKeep" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see JournalManager#purgeLogsOlderThan(long)]]>
      </doc>
    </method>
    <method name="getEditLogManifest" return="org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sinceTxId" type="long"/>
      <param name="inProgressOk" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see QJournalProtocol#getEditLogManifest(String, long, boolean)]]>
      </doc>
    </method>
    <method name="prepareRecovery" return="org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos.PrepareRecoveryResponseProto"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reqInfo" type="org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo"/>
      <param name="segmentTxId" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see QJournalProtocol#prepareRecovery(RequestInfo, long)]]>
      </doc>
    </method>
    <method name="acceptRecovery"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reqInfo" type="org.apache.hadoop.hdfs.qjournal.protocol.RequestInfo"/>
      <param name="segment" type="org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos.SegmentStateProto"/>
      <param name="fromUrl" type="java.net.URL"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@see QJournalProtocol#acceptRecovery(RequestInfo, QJournalProtocolProtos.SegmentStateProto, URL)]]>
      </doc>
    </method>
    <method name="doPreUpgrade"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="doUpgrade"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sInfo" type="org.apache.hadoop.hdfs.server.common.StorageInfo"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="doFinalize"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="canRollBack" return="java.lang.Boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storage" type="org.apache.hadoop.hdfs.server.common.StorageInfo"/>
      <param name="prevStorage" type="org.apache.hadoop.hdfs.server.common.StorageInfo"/>
      <param name="targetLayoutVersion" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="doRollback"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getJournalCTime" return="java.lang.Long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <field name="LAST_PROMISED_FILENAME" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="LAST_WRITER_EPOCH" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A JournalNode can manage journals for several clusters at once.
 Each such journal is entirely independent despite being hosted by
 the same JVM.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.qjournal.server.Journal -->
  <!-- start interface org.apache.hadoop.hdfs.qjournal.server.JournalNodeMXBean -->
  <interface name="JournalNodeMXBean"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getJournalsStatus" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get status information (e.g., whether formatted) of JournalNode's journals.
 
 @return A string presenting status for each journal]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This is the JMX management interface for JournalNode information]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.qjournal.server.JournalNodeMXBean -->
</package>
<package name="org.apache.hadoop.hdfs.security.token.block">
  <!-- start class org.apache.hadoop.hdfs.security.token.block.BlockPoolTokenSecretManager -->
  <class name="BlockPoolTokenSecretManager" extends="org.apache.hadoop.security.token.SecretManager"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockPoolTokenSecretManager"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="addBlockPool"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <param name="secretMgr" type="org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager"/>
      <doc>
      <![CDATA[Add a block pool Id and corresponding {@link BlockTokenSecretManager} to map
 @param bpid block pool Id
 @param secretMgr {@link BlockTokenSecretManager}]]>
      </doc>
    </method>
    <method name="isBlockPoolRegistered" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
    </method>
    <method name="createIdentifier" return="org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return an empty BlockTokenIdentifer]]>
      </doc>
    </method>
    <method name="createPassword" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="identifier" type="org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier"/>
    </method>
    <method name="retrievePassword" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="identifier" type="org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier"/>
      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
    </method>
    <method name="checkAccess"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier"/>
      <param name="userId" type="java.lang.String"/>
      <param name="block" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock"/>
      <param name="mode" type="org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.AccessMode"/>
      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
      <doc>
      <![CDATA[See {@link BlockTokenSecretManager#checkAccess(BlockTokenIdentifier, 
                String, ExtendedBlock, BlockTokenIdentifier.AccessMode)}]]>
      </doc>
    </method>
    <method name="checkAccess"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <param name="userId" type="java.lang.String"/>
      <param name="block" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock"/>
      <param name="mode" type="org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.AccessMode"/>
      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
      <doc>
      <![CDATA[See {@link BlockTokenSecretManager#checkAccess(Token, String, 
                ExtendedBlock, BlockTokenIdentifier.AccessMode)}]]>
      </doc>
    </method>
    <method name="addKeys"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <param name="exportedKeys" type="org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[See {@link BlockTokenSecretManager#addKeys(ExportedBlockKeys)}]]>
      </doc>
    </method>
    <method name="generateToken" return="org.apache.hadoop.security.token.Token"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock"/>
      <param name="of" type="java.util.EnumSet"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[See {@link BlockTokenSecretManager#generateToken(ExtendedBlock, EnumSet)}]]>
      </doc>
    </method>
    <method name="clearAllKeysForTesting"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="generateDataEncryptionKey" return="org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockPoolId" type="java.lang.String"/>
    </method>
    <method name="retrieveDataEncryptionKey" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="keyId" type="int"/>
      <param name="blockPoolId" type="java.lang.String"/>
      <param name="nonce" type="byte[]"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[Manages a {@link BlockTokenSecretManager} per block pool. Routes the requests
 given a block pool Id to corresponding {@link BlockTokenSecretManager}]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.security.token.block.BlockPoolTokenSecretManager -->
</package>
<package name="org.apache.hadoop.hdfs.security.token.delegation">
  <!-- start class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.SecretManagerState -->
  <class name="DelegationTokenSecretManager.SecretManagerState" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SecretManagerState" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.SecretManagerSection, java.util.List, java.util.List"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <field name="section" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.SecretManagerSection"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="keys" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="tokens" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.SecretManagerState -->
</package>
<package name="org.apache.hadoop.hdfs.server.balancer">
  <!-- start class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DBlock -->
  <class name="Dispatcher.DBlock" extends="org.apache.hadoop.hdfs.server.balancer.MovedBlocks.Locations"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DBlock" type="org.apache.hadoop.hdfs.protocol.Block"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getNumBytes" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storage" type="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup"/>
    </method>
    <doc>
    <![CDATA[A class for keeping track of block locations in the dispatcher.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DBlock -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DBlockStriped -->
  <class name="Dispatcher.DBlockStriped" extends="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DBlock"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DBlockStriped" type="org.apache.hadoop.hdfs.protocol.Block, byte[], short, int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInternalBlock" return="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storage" type="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup"/>
    </method>
    <method name="getNumBytes" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storage" type="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DBlockStriped -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode -->
  <class name="Dispatcher.DDatanode" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDatanodeInfo" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="addTarget" return="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storageType" type="org.apache.hadoop.fs.StorageType"/>
      <param name="maxSize2Move" type="long"/>
    </method>
    <method name="addSource" return="org.apache.hadoop.hdfs.server.balancer.Dispatcher.Source"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storageType" type="org.apache.hadoop.fs.StorageType"/>
      <param name="maxSize2Move" type="long"/>
      <param name="d" type="org.apache.hadoop.hdfs.server.balancer.Dispatcher"/>
    </method>
    <field name="delayUntil" type="long"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A class that keeps track of a datanode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup -->
  <class name="Dispatcher.DDatanode.StorageGroup" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getStorageType" return="org.apache.hadoop.fs.StorageType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDatanodeInfo" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incScheduledSize"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="size" type="long"/>
      <doc>
      <![CDATA[increment scheduled size]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <doc>
    <![CDATA[A group of storages in a datanode with the same storage type.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.Dispatcher.PendingMove -->
  <class name="Dispatcher.PendingMove" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class keeps track of a scheduled reportedBlock move]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.Dispatcher.PendingMove -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.Dispatcher.Source -->
  <class name="Dispatcher.Source" extends="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="addPendingMove" return="org.apache.hadoop.hdfs.server.balancer.Dispatcher.PendingMove"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DBlock"/>
      <param name="target" type="org.apache.hadoop.hdfs.server.balancer.Dispatcher.DDatanode.StorageGroup"/>
      <doc>
      <![CDATA[Add a pending move]]>
      </doc>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <doc>
    <![CDATA[A node that can be the sources of a block move]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.Dispatcher.Source -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.Dispatcher.StorageGroupMap -->
  <class name="Dispatcher.StorageGroupMap" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="StorageGroupMap"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="get" return="G"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="datanodeUuid" type="java.lang.String"/>
      <param name="storageType" type="org.apache.hadoop.fs.StorageType"/>
    </method>
    <method name="put"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="g" type="G"/>
    </method>
    <method name="values" return="java.util.Collection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.Dispatcher.StorageGroupMap -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.ExitStatus -->
  <class name="ExitStatus" extends="java.lang.Enum"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.balancer.ExitStatus[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.balancer.ExitStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getExitCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the command line exit code.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Exit status - The values associated with each exit status is directly mapped
 to the process's exit code in command line.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.ExitStatus -->
  <!-- start interface org.apache.hadoop.hdfs.server.balancer.Matcher -->
  <interface name="Matcher"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="match" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cluster" type="org.apache.hadoop.net.NetworkTopology"/>
      <param name="left" type="org.apache.hadoop.net.Node"/>
      <param name="right" type="org.apache.hadoop.net.Node"/>
      <doc>
      <![CDATA[Given the cluster topology, does the left node match the right node?]]>
      </doc>
    </method>
    <field name="SAME_NODE_GROUP" type="org.apache.hadoop.hdfs.server.balancer.Matcher"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Match datanodes in the same node group.]]>
      </doc>
    </field>
    <field name="SAME_RACK" type="org.apache.hadoop.hdfs.server.balancer.Matcher"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Match datanodes in the same rack.]]>
      </doc>
    </field>
    <field name="ANY_OTHER" type="org.apache.hadoop.hdfs.server.balancer.Matcher"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Match any datanode with any other datanode.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[A matcher interface for matching nodes.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.balancer.Matcher -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.MovedBlocks -->
  <class name="MovedBlocks" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="MovedBlocks" type="long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[initialize the moved blocks collection]]>
      </doc>
    </constructor>
    <method name="put"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.server.balancer.MovedBlocks.Locations"/>
      <doc>
      <![CDATA[add a block thus marking a block to be moved]]>
      </doc>
    </method>
    <method name="contains" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <doc>
      <![CDATA[@return if a block is marked as moved]]>
      </doc>
    </method>
    <method name="cleanup"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[remove old blocks]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This window makes sure to keep blocks that have been moved within a fixed
 time interval (default is 1.5 hour). Old window has blocks that are older;
 Current window has blocks that are more recent; Cleanup method triggers the
 check if blocks in the old window are more than the fixed time interval. If
 yes, purge the old window and then move blocks in current window to old
 window.
 
 @param <L> Location type]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.MovedBlocks -->
  <!-- start class org.apache.hadoop.hdfs.server.balancer.MovedBlocks.Locations -->
  <class name="MovedBlocks.Locations" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Locations" type="org.apache.hadoop.hdfs.protocol.Block"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="clearLocations"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[clean block locations]]>
      </doc>
    </method>
    <method name="addLocation"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="loc" type="L"/>
      <doc>
      <![CDATA[add a location]]>
      </doc>
    </method>
    <method name="isLocatedOn" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="loc" type="L"/>
      <doc>
      <![CDATA[@return if the block is located on the given location.]]>
      </doc>
    </method>
    <method name="getLocations" return="java.util.List"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return its locations]]>
      </doc>
    </method>
    <method name="getBlock" return="org.apache.hadoop.hdfs.protocol.Block"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getNumBytes" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="locations" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The locations of the replicas of the block.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[A class for keeping track of a block and its locations]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.balancer.MovedBlocks.Locations -->
</package>
<package name="org.apache.hadoop.hdfs.server.blockmanagement">
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy -->
  <class name="AvailableSpaceBlockPlacementPolicy" extends="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="AvailableSpaceBlockPlacementPolicy"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="initialize"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="stats" type="org.apache.hadoop.hdfs.server.blockmanagement.FSClusterStats"/>
      <param name="clusterMap" type="org.apache.hadoop.net.NetworkTopology"/>
      <param name="host2datanodeMap" type="org.apache.hadoop.hdfs.server.blockmanagement.Host2NodesMap"/>
    </method>
    <method name="chooseDataNode" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="scope" type="java.lang.String"/>
      <param name="excludedNode" type="java.util.Collection"/>
    </method>
    <method name="compareDataNode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="a" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"/>
      <param name="b" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"/>
      <doc>
      <![CDATA[Compare the two data nodes.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Space balanced block placement policy.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager -->
  <class name="BlockIdManager" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockIdManager" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockManager"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="upgradeLegacyGenerationStamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Upgrades the generation stamp for the filesystem
 by reserving a sufficient range for all existing blocks.
 Should be invoked only during the first upgrade to
 sequential block IDs.]]>
      </doc>
    </method>
    <method name="setLegacyGenerationStampLimit"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="stamp" type="long"/>
      <doc>
      <![CDATA[Sets the generation stamp that delineates random and sequentially
 allocated block IDs.

 @param stamp set generation stamp limit to this value]]>
      </doc>
    </method>
    <method name="getGenerationStampAtblockIdSwitch" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the value of the generation stamp that delineates sequential
 and random block IDs.]]>
      </doc>
    </method>
    <method name="setLastAllocatedContiguousBlockId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="long"/>
      <doc>
      <![CDATA[Sets the maximum allocated contiguous block ID for this filesystem. This is
 the basis for allocating new block IDs.]]>
      </doc>
    </method>
    <method name="getLastAllocatedContiguousBlockId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the maximum sequentially allocated contiguous block ID for this
 filesystem]]>
      </doc>
    </method>
    <method name="setLastAllocatedStripedBlockId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="long"/>
      <doc>
      <![CDATA[Sets the maximum allocated striped block ID for this filesystem. This is
 the basis for allocating new block IDs.]]>
      </doc>
    </method>
    <method name="getLastAllocatedStripedBlockId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the maximum sequentially allocated striped block ID for this
 filesystem]]>
      </doc>
    </method>
    <method name="setLegacyGenerationStamp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="stamp" type="long"/>
      <doc>
      <![CDATA[Sets the current generation stamp for legacy blocks]]>
      </doc>
    </method>
    <method name="getLegacyGenerationStamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the current generation stamp for legacy blocks]]>
      </doc>
    </method>
    <method name="setGenerationStamp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="stamp" type="long"/>
      <doc>
      <![CDATA[Gets the current generation stamp for this filesystem]]>
      </doc>
    </method>
    <method name="getGenerationStamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getLegacyGenerationStampLimit" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isStripedBlockID" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="long"/>
    </method>
    <method name="getBlockIndex" return="byte"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reportedBlock" type="org.apache.hadoop.hdfs.protocol.Block"/>
    </method>
    <doc>
    <![CDATA[BlockIdManager allocates the generation stamps and the block ID. The
 {@see FSNamesystem} is responsible for persisting the allocations in the
 {@see EditLog}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.BlockIdManager -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector -->
  <class name="BlockManagerFaultInjector" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockManagerFaultInjector"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInstance" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incomingBlockReportRpc"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nodeID" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
      <param name="context" type="org.apache.hadoop.hdfs.server.protocol.BlockReportContext"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="requestBlockReportLease"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"/>
      <param name="leaseId" type="long"/>
    </method>
    <method name="removeBlockReportLease"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"/>
      <param name="leaseId" type="long"/>
    </method>
    <field name="instance" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector"
      transient="false" volatile="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Used to inject certain faults for testing.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerFaultInjector -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyWithNodeGroup -->
  <class name="BlockPlacementPolicyWithNodeGroup" extends="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockPlacementPolicyWithNodeGroup"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <method name="initialize"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="stats" type="org.apache.hadoop.hdfs.server.blockmanagement.FSClusterStats"/>
      <param name="clusterMap" type="org.apache.hadoop.net.NetworkTopology"/>
      <param name="host2datanodeMap" type="org.apache.hadoop.hdfs.server.blockmanagement.Host2NodesMap"/>
    </method>
    <method name="chooseFavouredNodes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="src" type="java.lang.String"/>
      <param name="numOfReplicas" type="int"/>
      <param name="favoredNodes" type="java.util.List"/>
      <param name="favoriteAndExcludedNodes" type="java.util.Set"/>
      <param name="blocksize" type="long"/>
      <param name="maxNodesPerRack" type="int"/>
      <param name="results" type="java.util.List"/>
      <param name="avoidStaleNodes" type="boolean"/>
      <param name="storageTypes" type="java.util.EnumMap"/>
      <exception name="BlockPlacementPolicy.NotEnoughReplicasException" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy.NotEnoughReplicasException"/>
      <doc>
      <![CDATA[choose all good favored nodes as target.
 If no enough targets, then choose one replica from
 each bad favored node's node group.
 @throws NotEnoughReplicasException]]>
      </doc>
    </method>
    <method name="chooseLocalStorage" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="localMachine" type="org.apache.hadoop.net.Node"/>
      <param name="excludedNodes" type="java.util.Set"/>
      <param name="blocksize" type="long"/>
      <param name="maxNodesPerRack" type="int"/>
      <param name="results" type="java.util.List"/>
      <param name="avoidStaleNodes" type="boolean"/>
      <param name="storageTypes" type="java.util.EnumMap"/>
      <param name="fallbackToNodeGroupAndLocalRack" type="boolean"/>
      <exception name="BlockPlacementPolicy.NotEnoughReplicasException" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy.NotEnoughReplicasException"/>
      <doc>
      <![CDATA[choose local node of <i>localMachine</i> as the target.
 If localMachine is not available, will fallback to nodegroup/rack
 when flag <i>fallbackToNodeGroupAndLocalRack</i> is set.
 @return the chosen node]]>
      </doc>
    </method>
    <method name="chooseLocalRack" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="localMachine" type="org.apache.hadoop.net.Node"/>
      <param name="excludedNodes" type="java.util.Set"/>
      <param name="blocksize" type="long"/>
      <param name="maxNodesPerRack" type="int"/>
      <param name="results" type="java.util.List"/>
      <param name="avoidStaleNodes" type="boolean"/>
      <param name="storageTypes" type="java.util.EnumMap"/>
      <exception name="BlockPlacementPolicy.NotEnoughReplicasException" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy.NotEnoughReplicasException"/>
    </method>
    <method name="chooseRemoteRack"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="numOfReplicas" type="int"/>
      <param name="localMachine" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"/>
      <param name="excludedNodes" type="java.util.Set"/>
      <param name="blocksize" type="long"/>
      <param name="maxReplicasPerRack" type="int"/>
      <param name="results" type="java.util.List"/>
      <param name="avoidStaleNodes" type="boolean"/>
      <param name="storageTypes" type="java.util.EnumMap"/>
      <exception name="BlockPlacementPolicy.NotEnoughReplicasException" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy.NotEnoughReplicasException"/>
    </method>
    <method name="getRack" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="cur" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo"/>
    </method>
    <method name="addToExcludedNodes" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="chosenNode" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"/>
      <param name="excludedNodes" type="java.util.Set"/>
      <doc>
      <![CDATA[Find other nodes in the same nodegroup of <i>localMachine</i> and add them
 into <i>excludeNodes</i> as replica should not be duplicated for nodes 
 within the same nodegroup
 @return number of new excluded nodes]]>
      </doc>
    </method>
    <method name="pickupReplicaSet" return="java.util.Collection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="first" type="java.util.Collection"/>
      <param name="second" type="java.util.Collection"/>
      <param name="rackMap" type="java.util.Map"/>
      <doc>
      <![CDATA[Pick up replica node set for deleting replica as over-replicated. 
 First set contains replica nodes on rack with more than one
 replica while second set contains remaining replica nodes.
 If first is not empty, divide first set into two subsets:
   moreThanOne contains nodes on nodegroup with more than one replica
   exactlyOne contains the remaining nodes in first set
 then pickup priSet if not empty.
 If first is empty, then pick second.]]>
      </doc>
    </method>
    <method name="isMovable" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="locs" type="java.util.Collection"/>
      <param name="source" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo"/>
      <param name="target" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo"/>
      <doc>
      <![CDATA[Check if there are any replica (other than source) on the same node group
 with target. If true, then target is not a good candidate for placing
 specific replica as we don't want 2 replicas under the same nodegroup.

 @return true if there are any replica (other than source) on the same node
         group with target]]>
      </doc>
    </method>
    <method name="verifyBlockPlacement" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="locs" type="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"/>
      <param name="numberOfReplicas" type="int"/>
    </method>
    <doc>
    <![CDATA[The class is responsible for choosing the desired number of targets
 for placing block replicas on environment with node-group layer.
 The replica placement strategy is adjusted to:
 If the writer is on a datanode, the 1st replica is placed on the local 
     node(or local node-group or on local rack), otherwise a random datanode.
 The 2nd replica is placed on a datanode that is on a different rack with 1st
     replica node. 
 The 3rd replica is placed on a datanode which is on a different node-group
     but the same rack as the second replica node.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyWithNodeGroup -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementStatusDefault -->
  <class name="BlockPlacementStatusDefault" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementStatus"/>
    <constructor name="BlockPlacementStatusDefault" type="int, int, int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="isPlacementPolicySatisfied" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getErrorDescription" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementStatusDefault -->
  <!-- start interface org.apache.hadoop.hdfs.server.blockmanagement.BlockStatsMXBean -->
  <interface name="BlockStatsMXBean"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getStorageTypeStats" return="java.util.Map"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The statistics of storage types.

 @return get storage statistics per storage type]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This is an interface used to retrieve statistic information related to
 block management.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.blockmanagement.BlockStatsMXBean -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite -->
  <class name="BlockStoragePolicySuite" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockStoragePolicySuite" type="byte, org.apache.hadoop.hdfs.protocol.BlockStoragePolicy[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="createDefaultSuite" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPolicy" return="org.apache.hadoop.hdfs.protocol.BlockStoragePolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="byte"/>
      <doc>
      <![CDATA[@return the corresponding policy.]]>
      </doc>
    </method>
    <method name="getDefaultPolicy" return="org.apache.hadoop.hdfs.protocol.BlockStoragePolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the default policy.]]>
      </doc>
    </method>
    <method name="getPolicy" return="org.apache.hadoop.hdfs.protocol.BlockStoragePolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="policyName" type="java.lang.String"/>
    </method>
    <method name="getAllPolicies" return="org.apache.hadoop.hdfs.protocol.BlockStoragePolicy[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="buildXAttrName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="buildXAttr" return="org.apache.hadoop.fs.XAttr"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="policyId" type="byte"/>
    </method>
    <method name="getStoragePolicyXAttrPrefixedName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="STORAGE_POLICY_XATTR_NAME" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="XAttrNS" type="org.apache.hadoop.fs.XAttr.NameSpace"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="ID_BIT_LENGTH" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A collection of block storage policies.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.BlockUnderConstructionFeature -->
  <class name="BlockUnderConstructionFeature" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlockUnderConstructionFeature" type="org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.common.HdfsServerConstants.BlockUCState, org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[], boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setExpectedLocations"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <param name="targets" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"/>
      <param name="isStriped" type="boolean"/>
      <doc>
      <![CDATA[Set expected locations]]>
      </doc>
    </method>
    <method name="getExpectedStorageLocations" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create array of expected replica locations
 (as has been assigned by chooseTargets()).]]>
      </doc>
    </method>
    <method name="getBlockIndices" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the index array indicating the block index in each storage. Used
 only by striped blocks.]]>
      </doc>
    </method>
    <method name="getNumExpectedLocations" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBlockUCState" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.BlockUCState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the state of the block under construction.
 @see BlockUCState]]>
      </doc>
    </method>
    <method name="getBlockRecoveryId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTruncateBlock" return="org.apache.hadoop.hdfs.protocol.Block"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get recover block]]>
      </doc>
    </method>
    <method name="setTruncateBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="recoveryBlock" type="org.apache.hadoop.hdfs.protocol.Block"/>
    </method>
    <method name="initializeBlockRecovery"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockInfo" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo"/>
      <param name="recoveryId" type="long"/>
      <doc>
      <![CDATA[Initialize lease recovery for this block.
 Find the first alive data-node starting from the previous primary and
 make it primary.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="appendUCPartsConcise"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sb" type="java.lang.StringBuilder"/>
    </method>
    <doc>
    <![CDATA[Represents the under construction feature of a Block.
 This is usually the last block of a file opened for write or append.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.BlockUnderConstructionFeature -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager -->
  <class name="CombinedHostFileManager" extends="org.apache.hadoop.hdfs.server.blockmanagement.HostConfigManager"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CombinedHostFileManager"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getIncludes" return="java.lang.Iterable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getExcludes" return="java.lang.Iterable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setConf"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="refresh"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="isIncluded" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
    </method>
    <method name="isExcluded" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
    </method>
    <method name="getUpgradeDomain" return="java.lang.String"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
    </method>
    <doc>
    <![CDATA[This class manages datanode configuration using a json file.
 Please refer to {@link CombinedHostsFileReader} for the json format.
 <p/>
 <p/>
 Entries may or may not specify a port.  If they don't, we consider
 them to apply to every DataNode on that host. The code canonicalizes the
 entries into IP addresses.
 <p/>
 <p/>
 The code ignores all entries that the DNS fails to resolve their IP
 addresses. This is okay because by default the NN rejects the registrations
 of DNs when it fails to do a forward and reverse lookup. Note that DNS
 resolutions are only done during the loading time to minimize the latency.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap.Reason -->
  <class name="CorruptReplicasMap.Reason" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap.Reason[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap.Reason"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[The corruption reason code]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap.Reason -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList -->
  <class name="DatanodeDescriptor.CachedBlocksList" extends="org.apache.hadoop.util.IntrusiveCollection"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getDatanode" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getType" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList.Type"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A list of CachedBlock objects on this datanode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList.Type -->
  <class name="DatanodeDescriptor.CachedBlocksList.Type" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList.Type[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList.Type"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.CachedBlocksList.Type -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.DecommissioningStatus -->
  <class name="DatanodeDescriptor.DecommissioningStatus" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DecommissioningStatus"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getUnderReplicatedBlocks" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the number of under-replicated blocks]]>
      </doc>
    </method>
    <method name="getDecommissionOnlyReplicas" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the number of decommission-only replicas]]>
      </doc>
    </method>
    <method name="getUnderReplicatedInOpenFiles" return="int"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the number of under-replicated blocks in open files]]>
      </doc>
    </method>
    <method name="setStartTime"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="time" type="long"/>
      <doc>
      <![CDATA[Set start time]]>
      </doc>
    </method>
    <method name="getStartTime" return="long"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return start time]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Decommissioning status]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.DecommissioningStatus -->
  <!-- start interface org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStatistics -->
  <interface name="DatanodeStatistics"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getCapacityTotal" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the total capacity]]>
      </doc>
    </method>
    <method name="getCapacityUsed" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the used capacity]]>
      </doc>
    </method>
    <method name="getCapacityUsedPercent" return="float"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the percentage of the used capacity over the total capacity.]]>
      </doc>
    </method>
    <method name="getCapacityRemaining" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the remaining capacity]]>
      </doc>
    </method>
    <method name="getCapacityRemainingPercent" return="float"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the percentage of the remaining capacity over the total capacity.]]>
      </doc>
    </method>
    <method name="getBlockPoolUsed" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the block pool used.]]>
      </doc>
    </method>
    <method name="getPercentBlockPoolUsed" return="float"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the percentage of the block pool used space over the total capacity.]]>
      </doc>
    </method>
    <method name="getCacheCapacity" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the total cache capacity of all DataNodes]]>
      </doc>
    </method>
    <method name="getCacheUsed" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the total cache used by all DataNodes]]>
      </doc>
    </method>
    <method name="getXceiverCount" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the xceiver count]]>
      </doc>
    </method>
    <method name="getInServiceXceiverCount" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return average xceiver count for non-decommission(ing|ed) nodes]]>
      </doc>
    </method>
    <method name="getNumDatanodesInService" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return number of non-decommission(ing|ed) nodes]]>
      </doc>
    </method>
    <method name="getCapacityUsedNonDFS" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the total used space by data nodes for non-DFS purposes
 such as storing temporary files on the local file system]]>
      </doc>
    </method>
    <method name="getStats" return="long[]"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The same as {@link ClientProtocol#getStats()}.
 The block related entries are set to -1.]]>
      </doc>
    </method>
    <method name="getExpiredHeartbeats" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the expired heartbeats]]>
      </doc>
    </method>
    <method name="getStorageTypeStats" return="java.util.Map"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Storage Tier statistics]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Datanode statistics]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStatistics -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo -->
  <class name="DatanodeStorageInfo" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="toDatanodeInfos" return="org.apache.hadoop.hdfs.protocol.DatanodeInfo[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storages" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"/>
    </method>
    <method name="toStorageIDs" return="java.lang.String[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storages" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"/>
    </method>
    <method name="toStorageTypes" return="org.apache.hadoop.fs.StorageType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storages" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"/>
    </method>
    <method name="updateFromStorage"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storage" type="org.apache.hadoop.hdfs.server.protocol.DatanodeStorage"/>
    </method>
    <method name="getBlockReportCount" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="areBlockContentsStale" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setUtilizationForTesting"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="capacity" type="long"/>
      <param name="dfsUsed" type="long"/>
      <param name="remaining" type="long"/>
      <param name="blockPoolUsed" type="long"/>
    </method>
    <method name="getStorageID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStorageType" return="org.apache.hadoop.fs.StorageType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="addBlockInitial" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo.AddBlockResult"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo"/>
      <param name="reportedBlock" type="org.apache.hadoop.hdfs.protocol.Block"/>
      <doc>
      <![CDATA[For use during startup. Expects block to be added in sorted order
 to enable fast insert in to the DatanodeStorageInfo

 @param b Block to add to DatanodeStorageInfo
 @param reportedBlock The reported replica
 @return Enum describing if block was added, replaced or already existed]]>
      </doc>
    </method>
    <method name="addBlock" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo.AddBlockResult"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo"/>
      <param name="reportedBlock" type="org.apache.hadoop.hdfs.protocol.Block"/>
    </method>
    <method name="getDatanodeDescriptor" return="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrementBlocksScheduled"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storages" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"/>
      <doc>
      <![CDATA[Increment the number of blocks scheduled for each given storage]]>
      </doc>
    </method>
    <method name="decrementBlocksScheduled"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storages" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"/>
      <doc>
      <![CDATA[Decrement the number of blocks scheduled for each given storage. This will
 be called during abandon block or delete of UC block.]]>
      </doc>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="treeSetFillRatio" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The fill ratio of the underlying TreeSet holding blocks.

 @return the fill ratio of the tree]]>
      </doc>
    </method>
    <method name="treeSetCompact" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="timeout" type="long"/>
      <doc>
      <![CDATA[Compact the underlying TreeSet holding blocks.

 @param timeout Maximum time to spend compacting the tree set in
                milliseconds.

 @return true if compaction completed, false if aborted]]>
      </doc>
    </method>
    <field name="EMPTY_ARRAY" type="org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo[]"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A Datanode has one or more storages. A storage in the Datanode is represented
 by this class.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeStorageInfo -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager -->
  <class name="HostFileManager" extends="org.apache.hadoop.hdfs.server.blockmanagement.HostConfigManager"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HostFileManager"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setConf"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="refresh"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getIncludes" return="org.apache.hadoop.hdfs.server.blockmanagement.HostSet"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getExcludes" return="org.apache.hadoop.hdfs.server.blockmanagement.HostSet"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isIncluded" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
    </method>
    <method name="isExcluded" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
    </method>
    <method name="getUpgradeDomain" return="java.lang.String"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dn" type="org.apache.hadoop.hdfs.protocol.DatanodeID"/>
    </method>
    <doc>
    <![CDATA[This class manages the include and exclude files for HDFS.
 <p/>
 These files control which DataNodes the NameNode expects to see in the
 cluster.  Loosely speaking, the include file, if it exists and is not
 empty, is a list of everything we expect to see.  The exclude file is
 a list of everything we want to ignore if we do see it.
 <p/>
 Entries may or may not specify a port.  If they don't, we consider
 them to apply to every DataNode on that host. The code canonicalizes the
 entries into IP addresses.
 <p/>
 <p/>
 The code ignores all entries that the DNS fails to resolve their IP
 addresses. This is okay because by default the NN rejects the registrations
 of DNs when it fails to do a forward and reverse lookup. Note that DNS
 resolutions are only done during the loading time to minimize the latency.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.HostSet -->
  <class name="HostSet" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Iterable"/>
    <constructor name="HostSet"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="iterator" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[The HostSet allows efficient queries on matching wildcard addresses.
 <p/>
 For InetSocketAddress A and B with the same host address,
 we define a partial order between A and B, A <= B iff A.getPort() == B
 .getPort() || B.getPort() == 0.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.HostSet -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas -->
  <class name="NumberReplicas" extends="org.apache.hadoop.hdfs.util.EnumCounters"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NumberReplicas"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="liveReplicas" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="readOnlyReplicas" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="decommissionedAndDecommissioning" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return decommissioned and decommissioning replicas]]>
      </doc>
    </method>
    <method name="decommissioned" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return decommissioned replicas only]]>
      </doc>
    </method>
    <method name="decommissioning" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return decommissioning replicas only]]>
      </doc>
    </method>
    <method name="corruptReplicas" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="excessReplicas" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="replicasOnStaleNodes" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the number of replicas which are on stale nodes.
 This is not mutually exclusive with the other counts -- ie a
 replica may count as both "live" and "stale".]]>
      </doc>
    </method>
    <method name="redundantInternalBlocks" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A immutable object that stores the number of live replicas and
 the number of decommissioned Replicas.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas.StoredReplicaState -->
  <class name="NumberReplicas.StoredReplicaState" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas.StoredReplicaState[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas.StoredReplicaState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.NumberReplicas.StoredReplicaState -->
  <!-- start class org.apache.hadoop.hdfs.server.blockmanagement.UnresolvedTopologyException -->
  <class name="UnresolvedTopologyException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="UnresolvedTopologyException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[This exception is thrown if resolving topology path 
 for a node fails.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.blockmanagement.UnresolvedTopologyException -->
</package>
<package name="org.apache.hadoop.hdfs.server.common">
  <!-- start class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.BlockUCState -->
  <class name="HdfsServerConstants.BlockUCState" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.BlockUCState[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.BlockUCState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[States, which a block can go through while it is under construction.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.BlockUCState -->
  <!-- start class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole -->
  <class name="HdfsServerConstants.NamenodeRole" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Defines the NameNode role.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole -->
  <!-- start class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NodeType -->
  <class name="HdfsServerConstants.NodeType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NodeType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NodeType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Type of the node]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NodeType -->
  <!-- start class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState -->
  <class name="HdfsServerConstants.ReplicaState" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getValue" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getState" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="v" type="int"/>
    </method>
    <method name="read" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read from in]]>
      </doc>
    </method>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Write to out]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Block replica states, which it can go through while being constructed.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState -->
  <!-- start class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.RollingUpgradeStartupOption -->
  <class name="HdfsServerConstants.RollingUpgradeStartupOption" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.RollingUpgradeStartupOption[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.RollingUpgradeStartupOption"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getOptionString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="matches" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="option" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.StartupOption"/>
    </method>
    <method name="getAllOptionString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Startup options for rolling upgrade.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.RollingUpgradeStartupOption -->
  <!-- start class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.StartupOption -->
  <class name="HdfsServerConstants.StartupOption" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.StartupOption[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.StartupOption"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toNodeRole" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setClusterId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cid" type="java.lang.String"/>
    </method>
    <method name="getClusterId" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setRollingUpgradeStartupOption"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="opt" type="java.lang.String"/>
    </method>
    <method name="getRollingUpgradeStartupOption" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.RollingUpgradeStartupOption"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="createRecoveryContext" return="org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setForce"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="force" type="int"/>
    </method>
    <method name="getForce" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getForceFormat" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setForceFormat"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="force" type="boolean"/>
    </method>
    <method name="getInteractiveFormat" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setInteractiveFormat"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="interactive" type="boolean"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getEnum" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.StartupOption"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="value" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Startup options]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.HdfsServerConstants.StartupOption -->
  <!-- start class org.apache.hadoop.hdfs.server.common.MetricsLoggerTask -->
  <class name="MetricsLoggerTask" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Runnable"/>
    <constructor name="MetricsLoggerTask" type="org.apache.commons.logging.Log, java.lang.String, short"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="run"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Write metrics to the metrics appender when invoked.]]>
      </doc>
    </method>
    <method name="makeMetricsLoggerAsync"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="metricsLog" type="org.apache.commons.logging.Log"/>
      <doc>
      <![CDATA[Make the metrics logger async and add all pre-existing appenders to the
 async appender.]]>
      </doc>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[MetricsLoggerTask can be used as utility to dump metrics to log.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.MetricsLoggerTask -->
  <!-- start class org.apache.hadoop.hdfs.server.common.Storage.StorageState -->
  <class name="Storage.StorageState" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.common.Storage.StorageState[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.common.Storage.StorageState"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.common.Storage.StorageState -->
</package>
<package name="org.apache.hadoop.hdfs.server.datanode">
  <!-- start class org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker.RecoveryTaskStriped -->
  <class name="BlockRecoveryWorker.RecoveryTaskStriped" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="recover"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[blk_0  blk_1  blk_2  blk_3  blk_4  blk_5  blk_6  blk_7  blk_8
  64k    64k    64k    64k    64k    64k    64k    64k    64k   <-- stripe_0
  64k    64k    64k    64k    64k    64k    64k    64k    64k
  64k    64k    64k    64k    64k    64k    64k    61k    <-- startStripeIdx
  64k    64k    64k    64k    64k    64k    64k
  64k    64k    64k    64k    64k    64k    59k
  64k    64k    64k    64k    64k    64k
  64k    64k    64k    64k    64k    64k                <-- last full stripe
  64k    64k    13k    64k    55k     3k              <-- target last stripe
  64k    64k           64k     1k
  64k    64k           58k
  64k    64k
  64k    19k
  64k                                               <-- total visible stripe

  Due to different speed of streamers, the internal blocks in a block group
  could have different lengths when the block group isn't ended normally.
  The purpose of this class is to recover the UnderConstruction block group,
  so all internal blocks end at the same stripe.

 The steps:
 1. get all blocks lengths from DataNodes.
 2. calculate safe length, which is at the target last stripe.
 3. decode and feed blk_6~8, make them end at last full stripe. (the last
 full stripe means the last decodable stripe.)
 4. encode the target last stripe, with the remaining sequential data. In
 this case, the sequential data is 64k+64k+13k. Feed blk_6~8 the parity cells.
 Overwrite the parity cell if have to.
 5. truncate the stripes from visible stripe, to target last stripe.
 TODO: implement step 3,4]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker.RecoveryTaskStriped -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.BPServiceActorAction -->
  <interface name="BPServiceActorAction"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="reportTo"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpNamenode" type="org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB"/>
      <param name="bpRegistration" type="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration"/>
      <exception name="BPServiceActorActionException" type="org.apache.hadoop.hdfs.server.datanode.BPServiceActorActionException"/>
    </method>
    <doc>
    <![CDATA[Base class for BPServiceActor class
 Issued by BPOfferSerivce class to tell BPServiceActor 
 to take several actions.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.BPServiceActorAction -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.BPServiceActorActionException -->
  <class name="BPServiceActorActionException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BPServiceActorActionException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="BPServiceActorActionException" type="java.lang.String, java.lang.Throwable"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.BPServiceActorActionException -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ChunkChecksum -->
  <class name="ChunkChecksum" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ChunkChecksum" type="long, byte[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getDataLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getChecksum" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[holder class that holds checksum bytes and the length in a block at which
 the checksum bytes end
 
 ex: length = 1023 and checksum is 4 bytes which is for 512 bytes, then
     the checksum applies for the last chunk, or bytes 512 - 1023]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ChunkChecksum -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.DataNodeLayoutVersion.Feature -->
  <class name="DataNodeLayoutVersion.Feature" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature"/>
    <method name="values" return="org.apache.hadoop.hdfs.server.datanode.DataNodeLayoutVersion.Feature[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.datanode.DataNodeLayoutVersion.Feature"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Enums for features that change the layout version.
 <br><br>
 To add a new layout version:
 <ul>
 <li>Define a new enum constant with a short enum name, the new layout version 
 and description of the added feature.</li>
 <li>When adding a layout version with an ancestor that is not same as
 its immediate predecessor, use the constructor where a specific ancestor
 can be passed.
 </li>
 </ul>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.DataNodeLayoutVersion.Feature -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.DataNodeMXBean -->
  <interface name="DataNodeMXBean"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getVersion" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the version of Hadoop.
 
 @return the version of Hadoop]]>
      </doc>
    </method>
    <method name="getSoftwareVersion" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the version of software running on the DataNode

 @return a string representing the version]]>
      </doc>
    </method>
    <method name="getRpcPort" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the rpc port.
 
 @return the rpc port]]>
      </doc>
    </method>
    <method name="getHttpPort" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the http port.
 
 @return the http port]]>
      </doc>
    </method>
    <method name="getDataPort" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the data port.

 @return the data port]]>
      </doc>
    </method>
    <method name="getNamenodeAddresses" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the namenode IP addresses.
 
 @return the namenode IP addresses that the datanode is talking to]]>
      </doc>
    </method>
    <method name="getBPServiceActorInfo" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets information of the block pool service actors.

 @return block pool service actors info]]>
      </doc>
    </method>
    <method name="getVolumeInfo" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the information of each volume on the Datanode. Please
 see the implementation for the format of returned information.
 
 @return the volume info]]>
      </doc>
    </method>
    <method name="getClusterId" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the cluster id.
 
 @return the cluster id]]>
      </doc>
    </method>
    <method name="getXceiverCount" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns an estimate of the number of Datanode threads
 actively transferring blocks.]]>
      </doc>
    </method>
    <method name="getDatanodeNetworkCounts" return="java.util.Map"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the network error counts on a per-Datanode basis.]]>
      </doc>
    </method>
    <method name="getDiskBalancerStatus" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the diskBalancer Status.
 Please see implementation for the format of the returned information.

 @return  DiskBalancer Status]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This is the JMX management interface for data node information]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.DataNodeMXBean -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.DiskBalancer.BlockMover -->
  <interface name="DiskBalancer.BlockMover"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="copyBlocks"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pair" type="org.apache.hadoop.hdfs.server.datanode.DiskBalancer.VolumePair"/>
      <param name="item" type="org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem"/>
      <doc>
      <![CDATA[Copies blocks from a set of volumes.

 @param pair - Source and Destination Volumes.
 @param item - Number of bytes to move from volumes.]]>
      </doc>
    </method>
    <method name="setRunnable"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Begin the actual copy operations. This is useful in testing.]]>
      </doc>
    </method>
    <method name="setExitFlag"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Tells copyBlocks to exit from the copy routine.]]>
      </doc>
    </method>
    <method name="getDataset" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a pointer to the current dataset we are operating against.

 @return FsDatasetSpi]]>
      </doc>
    </method>
    <method name="getStartTime" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns time when this plan started executing.

 @return Start time in milliseconds.]]>
      </doc>
    </method>
    <method name="getElapsedSeconds" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Number of seconds elapsed.

 @return time in seconds]]>
      </doc>
    </method>
    <doc>
    <![CDATA[BlockMover supports moving blocks across Volumes.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.DiskBalancer.BlockMover -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.DiskBalancer.DiskBalancerMover -->
  <class name="DiskBalancer.DiskBalancerMover" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.datanode.DiskBalancer.BlockMover"/>
    <constructor name="DiskBalancerMover" type="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi, org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs diskBalancerMover.

 @param dataset Dataset
 @param conf    Configuration]]>
      </doc>
    </constructor>
    <method name="setRunnable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Sets Diskmover copyblocks into runnable state.]]>
      </doc>
    </method>
    <method name="setExitFlag"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Signals copy block to exit.]]>
      </doc>
    </method>
    <method name="shouldRun" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the shouldRun boolean flag.]]>
      </doc>
    </method>
    <method name="copyBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pair" type="org.apache.hadoop.hdfs.server.datanode.DiskBalancer.VolumePair"/>
      <param name="item" type="org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem"/>
      <doc>
      <![CDATA[Copies blocks from a set of volumes.

 @param pair - Source and Destination Volumes.
 @param item - Number of bytes to move from volumes.]]>
      </doc>
    </method>
    <method name="getDataset" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a pointer to the current dataset we are operating against.

 @return FsDatasetSpi]]>
      </doc>
    </method>
    <method name="getStartTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns time when this plan started executing.

 @return Start time in milliseconds.]]>
      </doc>
    </method>
    <method name="getElapsedSeconds" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Number of seconds elapsed.

 @return time in seconds]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Actual DataMover class for DiskBalancer.
 <p>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.DiskBalancer.DiskBalancerMover -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.DiskBalancer.VolumePair -->
  <class name="DiskBalancer.VolumePair" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="VolumePair" type="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a volume pair.

 @param source - Source Volume
 @param dest   - Destination Volume]]>
      </doc>
    </constructor>
    <method name="getSource" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[gets source volume.

 @return volume]]>
      </doc>
    </method>
    <method name="getDest" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets Destination volume.

 @return volume.]]>
      </doc>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Holds references to actual volumes that we will be operating against.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.DiskBalancer.VolumePair -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ErrorReportAction -->
  <class name="ErrorReportAction" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.datanode.BPServiceActorAction"/>
    <constructor name="ErrorReportAction" type="int, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="reportTo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpNamenode" type="org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB"/>
      <param name="bpRegistration" type="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration"/>
      <exception name="BPServiceActorActionException" type="org.apache.hadoop.hdfs.server.datanode.BPServiceActorActionException"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <doc>
    <![CDATA[A ErrorReportAction is an instruction issued by BPOfferService to 
 BPServiceActor about a particular block encapsulated in errorMessage.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ErrorReportAction -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.FinalizedReplica -->
  <class name="FinalizedReplica" extends="org.apache.hadoop.hdfs.server.datanode.ReplicaInfo"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="FinalizedReplica" type="long, long, long, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param blockId block id
 @param len replica length
 @param genStamp replica generation stamp
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located]]>
      </doc>
    </constructor>
    <constructor name="FinalizedReplica" type="org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param block a block
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located]]>
      </doc>
    </constructor>
    <constructor name="FinalizedReplica" type="org.apache.hadoop.hdfs.server.datanode.FinalizedReplica"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Copy constructor.
 @param from where to copy construct from]]>
      </doc>
    </constructor>
    <method name="getState" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBytesOnDisk" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class describes a replica that has been finalized.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.FinalizedReplica -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException -->
  <class name="ReplicaAlreadyExistsException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReplicaAlreadyExistsException"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="ReplicaAlreadyExistsException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Exception indicating that the target block already exists 
 and is not set to be recovered/overwritten.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReplicaBeingWritten -->
  <class name="ReplicaBeingWritten" extends="org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReplicaBeingWritten" type="long, long, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor for a zero length replica
 @param blockId block id
 @param genStamp replica generation stamp
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located
 @param bytesToReserve disk space to reserve for this replica, based on
                       the estimated maximum block length.]]>
      </doc>
    </constructor>
    <constructor name="ReplicaBeingWritten" type="org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File, java.lang.Thread"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param block a block
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located
 @param writer a thread that is writing to this replica]]>
      </doc>
    </constructor>
    <constructor name="ReplicaBeingWritten" type="long, long, long, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File, java.lang.Thread, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param blockId block id
 @param len replica length
 @param genStamp replica generation stamp
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located
 @param writer a thread that is writing to this replica
 @param bytesToReserve disk space to reserve for this replica, based on
                       the estimated maximum block length.]]>
      </doc>
    </constructor>
    <constructor name="ReplicaBeingWritten" type="org.apache.hadoop.hdfs.server.datanode.ReplicaBeingWritten"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Copy constructor.
 @param from where to copy from]]>
      </doc>
    </constructor>
    <method name="getVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getState" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class represents replicas being written. 
 Those are the replicas that
 are created in a pipeline initiated by a dfs client.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReplicaBeingWritten -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReplicaHandler -->
  <class name="ReplicaHandler" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <constructor name="ReplicaHandler" type="org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeReference"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getReplica" return="org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class includes a replica being actively written and the reference to
 the fs volume where this replica is located.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReplicaHandler -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReplicaInfo.ReplicaDirInfo -->
  <class name="ReplicaInfo.ReplicaDirInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReplicaDirInfo" type="java.lang.String, boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <field name="baseDirPath" type="java.lang.String"
      transient="false" volatile="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="hasSubidrs" type="boolean"
      transient="false" volatile="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReplicaInfo.ReplicaDirInfo -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline -->
  <class name="ReplicaInPipeline" extends="org.apache.hadoop.hdfs.server.datanode.ReplicaInfo"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface"/>
    <constructor name="ReplicaInPipeline" type="long, long, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor for a zero length replica
 @param blockId block id
 @param genStamp replica generation stamp
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located
 @param bytesToReserve disk space to reserve for this replica, based on
                       the estimated maximum block length.]]>
      </doc>
    </constructor>
    <constructor name="ReplicaInPipeline" type="org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Copy constructor.
 @param from where to copy from]]>
      </doc>
    </constructor>
    <method name="getVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getState" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBytesAcked" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setBytesAcked"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesAcked" type="long"/>
    </method>
    <method name="getBytesOnDisk" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBytesReserved" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getOriginalBytesReserved" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="releaseAllBytesReserved"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setLastChecksumAndDataLen"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dataLength" type="long"/>
      <param name="lastChecksum" type="byte[]"/>
    </method>
    <method name="getLastChecksumAndDataLen" return="org.apache.hadoop.hdfs.server.datanode.ChunkChecksum"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="interruptThread"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="attemptToSetWriter" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="prevWriter" type="java.lang.Thread"/>
      <param name="newWriter" type="java.lang.Thread"/>
      <doc>
      <![CDATA[Attempt to set the writer to a new value.]]>
      </doc>
    </method>
    <method name="stopWriter"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xceiverStopTimeout" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Interrupt the writing thread and wait until it dies
 @throws IOException the waiting is interrupted]]>
      </doc>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="createStreams" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaOutputStreams"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="isCreate" type="boolean"/>
      <param name="requestedChecksum" type="org.apache.hadoop.util.DataChecksum"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="createRestartMetaStream" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class defines a replica in a pipeline, which
 includes a persistent replica being written to by a dfs client or
 a temporary replica being replicated by a source datanode or
 being copied for the balancing purpose.
 
 The base class implements a temporary replica]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface -->
  <interface name="ReplicaInPipelineInterface"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.datanode.Replica"/>
    <method name="setNumBytes"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesReceived" type="long"/>
      <doc>
      <![CDATA[Set the number of bytes received
 @param bytesReceived number of bytes received]]>
      </doc>
    </method>
    <method name="getBytesAcked" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the number of bytes acked
 @return the number of bytes acked]]>
      </doc>
    </method>
    <method name="setBytesAcked"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesAcked" type="long"/>
      <doc>
      <![CDATA[Set the number bytes that have acked
 @param bytesAcked number bytes acked]]>
      </doc>
    </method>
    <method name="releaseAllBytesReserved"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Release any disk space reserved for this replica.]]>
      </doc>
    </method>
    <method name="setLastChecksumAndDataLen"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dataLength" type="long"/>
      <param name="lastChecksum" type="byte[]"/>
      <doc>
      <![CDATA[store the checksum for the last chunk along with the data length
 @param dataLength number of bytes on disk
 @param lastChecksum - checksum bytes for the last chunk]]>
      </doc>
    </method>
    <method name="getLastChecksumAndDataLen" return="org.apache.hadoop.hdfs.server.datanode.ChunkChecksum"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[gets the last chunk checksum and the length of the block corresponding
 to that checksum]]>
      </doc>
    </method>
    <method name="createStreams" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaOutputStreams"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="isCreate" type="boolean"/>
      <param name="requestedChecksum" type="org.apache.hadoop.util.DataChecksum"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create output streams for writing to this replica, 
 one for block file and one for CRC file
 
 @param isCreate if it is for creation
 @param requestedChecksum the checksum the writer would prefer to use
 @return output streams for writing
 @throws IOException if any error occurs]]>
      </doc>
    </method>
    <method name="createRestartMetaStream" return="java.io.OutputStream"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create an output stream to write restart metadata in case of datanode
 shutting down for quick restart.

 @return output stream for writing.
 @throws IOException if any error occurs]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This defines the interface of a replica in Pipeline that's being written to]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReplicaUnderRecovery -->
  <class name="ReplicaUnderRecovery" extends="org.apache.hadoop.hdfs.server.datanode.ReplicaInfo"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReplicaUnderRecovery" type="org.apache.hadoop.hdfs.server.datanode.ReplicaInfo, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="ReplicaUnderRecovery" type="org.apache.hadoop.hdfs.server.datanode.ReplicaUnderRecovery"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Copy constructor.
 @param from where to copy from]]>
      </doc>
    </constructor>
    <method name="getRecoveryID" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the recovery id
 @return the generation stamp that the replica will be bumped to]]>
      </doc>
    </method>
    <method name="setRecoveryID"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="recoveryId" type="long"/>
      <doc>
      <![CDATA[Set the recovery id
 @param recoveryId the new recoveryId]]>
      </doc>
    </method>
    <method name="getOriginalReplica" return="org.apache.hadoop.hdfs.server.datanode.ReplicaInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the original replica that's under recovery
 @return the original replica under recovery]]>
      </doc>
    </method>
    <method name="getState" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBytesOnDisk" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setBlockId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="long"/>
    </method>
    <method name="setGenerationStamp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="gs" type="long"/>
    </method>
    <method name="setNumBytes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="numBytes" type="long"/>
    </method>
    <method name="setDir"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="java.io.File"/>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="createInfo" return="org.apache.hadoop.hdfs.server.protocol.ReplicaRecoveryInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class represents replicas that are under block recovery
 It has a recovery id that is equal to the generation stamp 
 that the replica will be bumped to after recovery
 The recovery id is used to handle multiple concurrent block recoveries.
 A recovery with higher recovery id preempts recoveries with a lower id.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReplicaUnderRecovery -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReplicaWaitingToBeRecovered -->
  <class name="ReplicaWaitingToBeRecovered" extends="org.apache.hadoop.hdfs.server.datanode.ReplicaInfo"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReplicaWaitingToBeRecovered" type="long, long, long, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param blockId block id
 @param len replica length
 @param genStamp replica generation stamp
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located]]>
      </doc>
    </constructor>
    <constructor name="ReplicaWaitingToBeRecovered" type="org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi, java.io.File"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param block a block
 @param vol volume where replica is located
 @param dir directory path where block and meta files are located]]>
      </doc>
    </constructor>
    <constructor name="ReplicaWaitingToBeRecovered" type="org.apache.hadoop.hdfs.server.datanode.ReplicaWaitingToBeRecovered"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Copy constructor.
 @param from where to copy from]]>
      </doc>
    </constructor>
    <method name="getState" return="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getVisibleLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBytesOnDisk" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[This class represents a replica that is waiting to be recovered.
 After a datanode restart, any replica in "rbw" directory is loaded
 as a replica waiting to be recovered.
 A replica waiting to be recovered does not provision read nor
 participates in any pipeline recovery. It will become outdated if its
 client continues to write or be recovered as a result of
 lease recovery.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReplicaWaitingToBeRecovered -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ReportBadBlockAction -->
  <class name="ReportBadBlockAction" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.datanode.BPServiceActorAction"/>
    <constructor name="ReportBadBlockAction" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock, java.lang.String, org.apache.hadoop.fs.StorageType"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="reportTo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpNamenode" type="org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB"/>
      <param name="bpRegistration" type="org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration"/>
      <exception name="BPServiceActorActionException" type="org.apache.hadoop.hdfs.server.datanode.BPServiceActorActionException"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <doc>
    <![CDATA[ReportBadBlockAction is an instruction issued by {{BPOfferService}} to
 {{BPServiceActor}} to report bad block to namenode]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ReportBadBlockAction -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter -->
  <class name="SecureDataNodeStarter" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.commons.daemon.Daemon"/>
    <constructor name="SecureDataNodeStarter"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="init"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="context" type="org.apache.commons.daemon.DaemonContext"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="start"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="destroy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="stop"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="getSecureResources" return="org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Acquire privileged resources (i.e., the privileged ports) for the data
 node. The privileged resources consist of the port of the RPC server and
 the port of HTTP (not HTTPS) server.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Utility class to start a datanode in a secure cluster, first obtaining 
 privileged resources before main startup and handing them to the datanode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources -->
  <class name="SecureDataNodeStarter.SecureResources" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SecureResources" type="java.net.ServerSocket, java.nio.channels.ServerSocketChannel"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getStreamingSocket" return="java.net.ServerSocket"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getHttpServerChannel" return="java.nio.channels.ServerSocketChannel"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Stash necessary resources needed for datanode operation in a secure env.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry -->
  <class name="ShortCircuitRegistry" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ShortCircuitRegistry" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="removeShm"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="shm" type="org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm"/>
    </method>
    <method name="processBlockMlockEvent"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="org.apache.hadoop.hdfs.ExtendedBlockId"/>
      <doc>
      <![CDATA[Process a block mlock event from the FsDatasetCache.

 @param blockId    The block that was mlocked.]]>
      </doc>
    </method>
    <method name="processBlockMunlockRequest" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="org.apache.hadoop.hdfs.ExtendedBlockId"/>
      <doc>
      <![CDATA[Mark any slots associated with this blockId as unanchorable.

 @param blockId        The block ID.
 @return               True if we should allow the munlock request.]]>
      </doc>
    </method>
    <method name="processBlockInvalidation"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="org.apache.hadoop.hdfs.ExtendedBlockId"/>
      <doc>
      <![CDATA[Invalidate any slot associated with a blockId that we are invalidating
 (deleting) from this DataNode.  When a slot is invalid, the DFSClient will
 not use the corresponding replica for new read or mmap operations (although
 existing, ongoing read or mmap operations will complete.)

 @param blockId        The block ID.]]>
      </doc>
    </method>
    <method name="getClientNames" return="java.lang.String"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="org.apache.hadoop.hdfs.ExtendedBlockId"/>
    </method>
    <method name="createNewMemorySegment" return="org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.NewShmInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clientName" type="java.lang.String"/>
      <param name="sock" type="org.apache.hadoop.net.unix.DomainSocket"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Handle a DFSClient request to create a new memory segment.

 @param clientName    Client name as reported by the client.
 @param sock          The DomainSocket to associate with this memory
                        segment.  When this socket is closed, or the
                        other side writes anything to the socket, the
                        segment will be closed.  This can happen at any
                        time, including right after this function returns.
 @return              A NewShmInfo object.  The caller must close the
                        NewShmInfo object once they are done with it.
 @throws IOException  If the new memory segment could not be created.]]>
      </doc>
    </method>
    <method name="registerSlot"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blockId" type="org.apache.hadoop.hdfs.ExtendedBlockId"/>
      <param name="slotId" type="org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm.SlotId"/>
      <param name="isCached" type="boolean"/>
      <exception name="InvalidRequestException" type="org.apache.hadoop.fs.InvalidRequestException"/>
    </method>
    <method name="unregisterSlot"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="slotId" type="org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm.SlotId"/>
      <exception name="InvalidRequestException" type="org.apache.hadoop.fs.InvalidRequestException"/>
    </method>
    <method name="shutdown"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="visit" return="boolean"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="visitor" type="org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.Visitor"/>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Manages client short-circuit memory segments on the DataNode.

 DFSClients request shared memory segments from the DataNode.  The 
 ShortCircuitRegistry generates and manages these segments.  Each segment
 has a randomly generated 128-bit ID which uniquely identifies it.  The
 segments each contain several "slots."

 Before performing a short-circuit read, DFSClients must request a pair of
 file descriptors from the DataNode via the REQUEST_SHORT_CIRCUIT_FDS
 operation.  As part of this operation, DFSClients pass the ID of the shared
 memory segment they would like to use to communicate information about this
 replica, as well as the slot number within that segment they would like to
 use.  Slot allocation is always done by the client.

 Slots are used to track the state of the block on the both the client and
 datanode. When this DataNode mlocks a block, the corresponding slots for the
 replicas are marked as "anchorable".  Anchorable blocks can be safely read
 without verifying the checksum.  This means that BlockReaderLocal objects
 using these replicas can skip checksumming.  It also means that we can do
 zero-copy reads on these replicas (the ZCR interface has no way of
 verifying checksums.)
 
 When a DN needs to munlock a block, it needs to first wait for the block to
 be unanchored by clients doing a no-checksum read or a zero-copy read. The 
 DN also marks the block's slots as "unanchorable" to prevent additional 
 clients from initiating these operations in the future.
 
 The counterpart of this class on the client is {@link DfsClientShmManager}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.NewShmInfo -->
  <class name="ShortCircuitRegistry.NewShmInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <method name="getShmId" return="org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm.ShmId"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFileStream" return="java.io.FileInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.NewShmInfo -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.RegisteredShm -->
  <class name="ShortCircuitRegistry.RegisteredShm" extends="org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.net.unix.DomainSocketWatcher.Handler"/>
    <method name="handle" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sock" type="org.apache.hadoop.net.unix.DomainSocket"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.RegisteredShm -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.Visitor -->
  <interface name="ShortCircuitRegistry.Visitor"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="accept" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="segments" type="java.util.HashMap"/>
      <param name="slots" type="com.google.common.collect.HashMultimap"/>
    </method>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.Visitor -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.UnexpectedReplicaStateException -->
  <class name="UnexpectedReplicaStateException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="UnexpectedReplicaStateException"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="UnexpectedReplicaStateException" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock, org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="UnexpectedReplicaStateException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Exception indicating that the replica is in an unexpected state]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.UnexpectedReplicaStateException -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.VolumeScanner -->
  <class name="VolumeScanner" extends="java.lang.Thread"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="printStats"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="p" type="java.lang.StringBuilder"/>
    </method>
    <method name="run"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="shutdown"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Shut down this scanner.]]>
      </doc>
    </method>
    <method name="markSuspectBlock"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.protocol.ExtendedBlock"/>
    </method>
    <method name="enableBlockPoolId"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <doc>
      <![CDATA[Allow the scanner to scan the given block pool.

 @param bpid       The block pool id.]]>
      </doc>
    </method>
    <method name="disableBlockPoolId"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <doc>
      <![CDATA[Disallow the scanner from scanning the given block pool.

 @param bpid       The block pool id.]]>
      </doc>
    </method>
    <field name="LOG" type="org.slf4j.Logger"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[VolumeScanner scans a single volume.  Each VolumeScanner has its own thread.<p/>
 They are all managed by the DataNode's BlockScanner.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.VolumeScanner -->
</package>
<package name="org.apache.hadoop.hdfs.server.datanode.fsdataset">
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy -->
  <class name="AvailableSpaceVolumeChoosingPolicy" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.datanode.fsdataset.VolumeChoosingPolicy"/>
    <implements name="org.apache.hadoop.conf.Configurable"/>
    <constructor name="AvailableSpaceVolumeChoosingPolicy"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setConf"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="chooseVolume" return="V"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volumes" type="java.util.List"/>
      <param name="replicaSize" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[A DN volume choosing policy which takes into account the amount of free
 space on each of the available volumes when considering where to assign a
 new replica allocation. By default this policy prefers assigning replicas to
 those volumes with more available free space, so as to over time balance the
 available space of all the volumes within a DN.
 Use fine-grained locks to enable choosing volumes of different storage
 types concurrently.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi.Factory -->
  <class name="FsDatasetSpi.Factory" extends="java.lang.Object"
    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Factory"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getFactory" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi.Factory"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <doc>
      <![CDATA[@return the configured factory.]]>
      </doc>
    </method>
    <method name="newInstance" return="D"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="datanode" type="org.apache.hadoop.hdfs.server.datanode.DataNode"/>
      <param name="storage" type="org.apache.hadoop.hdfs.server.datanode.DataStorage"/>
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a new object.]]>
      </doc>
    </method>
    <method name="isSimulated" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Does the factory create simulated objects?]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A factory for creating {@link FsDatasetSpi} objects.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi.Factory -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi.FsVolumeReferences -->
  <class name="FsDatasetSpi.FsVolumeReferences" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Iterable"/>
    <implements name="java.io.Closeable"/>
    <constructor name="FsVolumeReferences" type="java.util.List"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="iterator" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="size" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the number of volumes.]]>
      </doc>
    </method>
    <method name="get" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="index" type="int"/>
      <doc>
      <![CDATA[Get the volume for a given index.]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[It behaviors as an unmodifiable list of FsVolume. Individual FsVolume can
 be obtained by using {@link #get(int)}.

 This also holds the reference counts for these volumes. It releases all the
 reference counts in {@link #close()}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi.FsVolumeReferences -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeReference -->
  <interface name="FsVolumeReference"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <method name="close"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Decrease the reference count of the volume.
 @throws IOException it never throws IOException.]]>
      </doc>
    </method>
    <method name="getVolume" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the underlying volume object. Return null if the reference was
 released.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This holds volume reference count as AutoClosable resource.
 It increases the reference count by one in the constructor, and decreases
 the reference count by one in {@link #close()}.

 <pre>
  {@code
    try (FsVolumeReference ref = volume.obtainReference()) {
      // Do IOs on the volume
      volume.createRwb(...);
      ...
    }
  }
 </pre>]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeReference -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi -->
  <interface name="FsVolumeSpi"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="obtainReference" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeReference"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="ClosedChannelException" type="java.nio.channels.ClosedChannelException"/>
      <doc>
      <![CDATA[Obtain a reference object that had increased 1 reference count of the
 volume.

 It is caller's responsibility to close {@link FsVolumeReference} to decrease
 the reference count on the volume.]]>
      </doc>
    </method>
    <method name="getStorageID" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the StorageUuid of the volume]]>
      </doc>
    </method>
    <method name="getBlockPoolList" return="java.lang.String[]"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return a list of block pools.]]>
      </doc>
    </method>
    <method name="getAvailable" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@return the available storage space in bytes.]]>
      </doc>
    </method>
    <method name="getBasePath" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the base path to the volume]]>
      </doc>
    </method>
    <method name="getPath" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@return the path to the volume]]>
      </doc>
    </method>
    <method name="getFinalizedDir" return="java.io.File"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[@return the directory for the finalized blocks in the block pool.]]>
      </doc>
    </method>
    <method name="getStorageType" return="org.apache.hadoop.fs.StorageType"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isTransientStorage" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns true if the volume is NOT backed by persistent storage.]]>
      </doc>
    </method>
    <method name="reserveSpaceForReplica"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesToReserve" type="long"/>
      <doc>
      <![CDATA[Reserve disk space for a block (RBW or Re-replicating)
 so a writer does not run out of space before the block is full.]]>
      </doc>
    </method>
    <method name="releaseReservedSpace"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesToRelease" type="long"/>
      <doc>
      <![CDATA[Release disk space previously reserved for block opened for write.]]>
      </doc>
    </method>
    <method name="releaseLockedMemory"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesToRelease" type="long"/>
      <doc>
      <![CDATA[Release reserved memory for an RBW block written to transient storage
 i.e. RAM.
 bytesToRelease will be rounded down to the OS page size since locked
 memory reservation must always be a multiple of the page size.]]>
      </doc>
    </method>
    <method name="newBlockIterator" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi.BlockIterator"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <param name="name" type="java.lang.String"/>
      <doc>
      <![CDATA[Create a new block iterator.  It will start at the beginning of the
 block set.

 @param bpid             The block pool id to iterate over.
 @param name             The name of the block iterator to create.

 @return                 The new block iterator.]]>
      </doc>
    </method>
    <method name="loadBlockIterator" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi.BlockIterator"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bpid" type="java.lang.String"/>
      <param name="name" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Load a saved block iterator.

 @param bpid             The block pool id to iterate over.
 @param name             The name of the block iterator to load.

 @return                 The saved block iterator.
 @throws IOException     If there was an IO error loading the saved
                           block iterator.]]>
      </doc>
    </method>
    <method name="getDataset" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the FSDatasetSpi which this volume is a part of.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This is an interface for the underlying volume.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi -->
  <!-- start interface org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi.BlockIterator -->
  <interface name="FsVolumeSpi.BlockIterator"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <method name="nextBlock" return="org.apache.hadoop.hdfs.protocol.ExtendedBlock"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get the next block.<p/>

 Note that this block may be removed in between the time we list it,
 and the time the caller tries to use it, or it may represent a stale
 entry.  Callers should handle the case where the returned block no
 longer exists.

 @return               The next block, or null if there are no
                         more blocks.  Null if there was an error
                         determining the next block.

 @throws IOException   If there was an error getting the next block in
                         this volume.  In this case, EOF will be set on
                         the iterator.]]>
      </doc>
    </method>
    <method name="atEnd" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns true if we got to the end of the block pool.]]>
      </doc>
    </method>
    <method name="rewind"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Repositions the iterator at the beginning of the block pool.]]>
      </doc>
    </method>
    <method name="save"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Save this block iterator to the underlying volume.
 Any existing saved block iterator with this name will be overwritten.
 maxStalenessMs will not be saved.

 @throws IOException   If there was an error when saving the block
                         iterator.]]>
      </doc>
    </method>
    <method name="setMaxStalenessMs"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="maxStalenessMs" type="long"/>
      <doc>
      <![CDATA[Set the maximum staleness of entries that we will return.<p/>

 A maximum staleness of 0 means we will never return stale entries; a
 larger value will allow us to reduce resource consumption in exchange
 for returning more potentially stale entries.  Even with staleness set
 to 0, consumers of this API must handle race conditions where block
 disappear before they can be processed.]]>
      </doc>
    </method>
    <method name="getIterStartMs" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the wall-clock time, measured in milliseconds since the Epoch,
 when this iterator was created.]]>
      </doc>
    </method>
    <method name="getLastSavedMs" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the wall-clock time, measured in milliseconds since the Epoch,
 when this iterator was last saved.  Returns iterStartMs if the
 iterator was never saved.]]>
      </doc>
    </method>
    <method name="getBlockPoolId" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the id of the block pool which this iterator traverses.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[BlockIterator will return ExtendedBlock entries from a block pool in
 this volume.  The entries will be returned in sorted order.<p/>

 BlockIterator objects themselves do not always have internal
 synchronization, so they can only safely be used by a single thread at a
 time.<p/>

 Closing the iterator does not save it.  You must call save to save it.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi.BlockIterator -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.LengthInputStream -->
  <class name="LengthInputStream" extends="java.io.FilterInputStream"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="LengthInputStream" type="java.io.InputStream, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create an stream.
 @param in the underlying input stream.
 @param length the length of the stream.]]>
      </doc>
    </constructor>
    <method name="getLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the length.]]>
      </doc>
    </method>
    <method name="getWrappedStream" return="java.io.InputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[An input stream with length.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.LengthInputStream -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaInputStreams -->
  <class name="ReplicaInputStreams" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <constructor name="ReplicaInputStreams" type="java.io.InputStream, java.io.InputStream, org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeReference"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create an object with a data input stream and a checksum input stream.]]>
      </doc>
    </constructor>
    <method name="getDataIn" return="java.io.InputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the data input stream.]]>
      </doc>
    </method>
    <method name="getChecksumIn" return="java.io.InputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the checksum input stream.]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Contains the input streams for the data and checksum of a replica.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaInputStreams -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaOutputStreams -->
  <class name="ReplicaOutputStreams" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <constructor name="ReplicaOutputStreams" type="java.io.OutputStream, java.io.OutputStream, org.apache.hadoop.util.DataChecksum, boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create an object with a data output stream, a checksum output stream
 and a checksum.]]>
      </doc>
    </constructor>
    <method name="getDataOut" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the data output stream.]]>
      </doc>
    </method>
    <method name="getChecksumOut" return="java.io.OutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the checksum output stream.]]>
      </doc>
    </method>
    <method name="getChecksum" return="org.apache.hadoop.util.DataChecksum"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the checksum.]]>
      </doc>
    </method>
    <method name="isTransientStorage" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return is writing to a transient storage?]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="syncDataOut"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Sync the data stream if it supports it.]]>
      </doc>
    </method>
    <method name="syncChecksumOut"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Sync the checksum stream if it supports it.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Contains the output streams for the data and checksum of a replica.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.ReplicaOutputStreams -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy -->
  <class name="RoundRobinVolumeChoosingPolicy" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.datanode.fsdataset.VolumeChoosingPolicy"/>
    <constructor name="RoundRobinVolumeChoosingPolicy"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="chooseVolume" return="V"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volumes" type="java.util.List"/>
      <param name="blockSize" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Choose volumes with the same storage type in round-robin order.
 Use fine-grained locks to synchronize volume choosing.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy -->
</package>
<package name="org.apache.hadoop.hdfs.server.datanode.fsdataset.impl">
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.PageRounder -->
  <class name="FsDatasetCache.PageRounder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="PageRounder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="roundUp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="count" type="long"/>
      <doc>
      <![CDATA[Round up a number to the operating system page size.]]>
      </doc>
    </method>
    <method name="roundDown" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="count" type="long"/>
      <doc>
      <![CDATA[Round down a number to the operating system page size.]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.PageRounder -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetFactory -->
  <class name="FsDatasetFactory" extends="org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi.Factory"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="FsDatasetFactory"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="newInstance" return="org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="datanode" type="org.apache.hadoop.hdfs.server.datanode.DataNode"/>
      <param name="storage" type="org.apache.hadoop.hdfs.server.datanode.DataStorage"/>
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[A factory for creating {@link FsDatasetImpl} objects.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetFactory -->
</package>
<package name="org.apache.hadoop.hdfs.server.datanode.metrics">
  <!-- start class org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetricHelper -->
  <class name="DataNodeMetricHelper" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DataNodeMetricHelper"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getMetrics"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="collector" type="org.apache.hadoop.metrics2.MetricsCollector"/>
      <param name="beanClass" type="org.apache.hadoop.hdfs.server.datanode.metrics.FSDatasetMBean"/>
      <param name="context" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Get metrics helper provides Helper function for
 metrics2 interface to act as a Metric source

 @param collector Metrics Collector that is passed in
 @param beanClass The Class that currently impliments the metric functions
 @param context A string that idenitifies the context

 @throws IOException]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetricHelper -->
</package>
<package name="org.apache.hadoop.hdfs.server.datanode.web">
  <!-- start class org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer -->
  <class name="DatanodeHttpServer" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <constructor name="DatanodeHttpServer" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.DataNode, java.nio.channels.ServerSocketChannel"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="getHttpAddress" return="java.net.InetSocketAddress"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getHttpsAddress" return="java.net.InetSocketAddress"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="start"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer -->
</package>
<package name="org.apache.hadoop.hdfs.server.datanode.web.dtp">
</package>
<package name="org.apache.hadoop.hdfs.server.datanode.web.webhdfs">
  <!-- start class org.apache.hadoop.hdfs.server.datanode.web.webhdfs.DataNodeUGIProvider -->
  <class name="DataNodeUGIProvider" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="init"
      abstract="false" native="false" synchronized="true"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Create UGI from the request for the WebHDFS requests for the DNs. Note that
 the DN does not authenticate the UGI -- the NN will authenticate them in
 subsequent operations.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.web.webhdfs.DataNodeUGIProvider -->
  <!-- start class org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler -->
  <class name="WebHdfsHandler" extends="io.netty.channel.SimpleChannelInboundHandler"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="WebHdfsHandler" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <method name="channelRead0"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ctx" type="io.netty.channel.ChannelHandlerContext"/>
      <param name="req" type="io.netty.handler.codec.http.HttpRequest"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="handle"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ctx" type="io.netty.channel.ChannelHandlerContext"/>
      <param name="req" type="io.netty.handler.codec.http.HttpRequest"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="URISyntaxException" type="java.net.URISyntaxException"/>
    </method>
    <method name="exceptionCaught"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ctx" type="io.netty.channel.ChannelHandlerContext"/>
      <param name="cause" type="java.lang.Throwable"/>
    </method>
    <field name="WEBHDFS_PREFIX" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="WEBHDFS_PREFIX_LENGTH" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="APPLICATION_OCTET_STREAM" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="APPLICATION_JSON_UTF8" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="EMPTY_CREATE_FLAG" type="java.util.EnumSet"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler -->
</package>
<package name="org.apache.hadoop.hdfs.server.diskbalancer">
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException -->
  <class name="DiskBalancerException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DiskBalancerException" type="java.lang.String, org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs an {@code IOException} with the specified detail message.

 @param message The detail message (which is saved for later retrieval by
                the {@link #getMessage()} method)]]>
      </doc>
    </constructor>
    <constructor name="DiskBalancerException" type="java.lang.String, java.lang.Throwable, org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs an {@code IOException} with the specified detail message and
 cause.
 <p/>
 <p> Note that the detail message associated with {@code cause} is
 <i>not</i>
 automatically incorporated into this exception's detail message.

 @param message The detail message (which is saved for later retrieval by
                the
                {@link #getMessage()} method)
 @param cause   The cause (which is saved for later retrieval by the {@link
                #getCause()} method).  (A null value is permitted, and
                indicates that the cause is nonexistent or unknown.)]]>
      </doc>
    </constructor>
    <constructor name="DiskBalancerException" type="java.lang.Throwable, org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs an {@code IOException} with the specified cause and a detail
 message of {@code (cause==null ? null : cause.toString())} (which typically
 contains the class and detail message of {@code cause}). This
 constructor is useful for IO exceptions that are little more than
 wrappers for other throwables.

 @param cause The cause (which is saved for later retrieval by the {@link
              #getCause()} method).  (A null value is permitted, and
              indicates
              that the cause is nonexistent or unknown.)]]>
      </doc>
    </constructor>
    <method name="getResult" return="org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the result.
 @return int]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Disk Balancer Exceptions.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result -->
  <class name="DiskBalancerException.Result" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Results returned by the RPC layer of DiskBalancer.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerException.Result -->
</package>
<package name="org.apache.hadoop.hdfs.server.diskbalancer.command">
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.command.CancelCommand -->
  <class name="CancelCommand" extends="org.apache.hadoop.hdfs.server.diskbalancer.command.Command"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CancelCommand" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Contructs a cancel Command.

 @param conf - Conf]]>
      </doc>
    </constructor>
    <method name="execute"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Executes the Client Calls.

 @param cmd - CommandLine]]>
      </doc>
    </method>
    <method name="printHelp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets extended help for this command.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Cancels a running plan.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.command.CancelCommand -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.command.Command -->
  <class name="Command" extends="org.apache.hadoop.conf.Configured"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Command" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a command.]]>
      </doc>
    </constructor>
    <method name="execute"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Executes the Client Calls.

 @param cmd - CommandLine
 @throws Exception]]>
      </doc>
    </method>
    <method name="printHelp"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets extended help for this command.]]>
      </doc>
    </method>
    <method name="readClusterInfo" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Process the URI and return the cluster with nodes setup. This is used in
 all commands.

 @param cmd - CommandLine
 @return DiskBalancerCluster
 @throws Exception]]>
      </doc>
    </method>
    <method name="setOutputPath"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Setup the outpath.

 @param path - Path or null to use default path.
 @throws IOException]]>
      </doc>
    </method>
    <method name="setNodesToProcess"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"/>
      <doc>
      <![CDATA[Sets the nodes to process.

 @param node - Node]]>
      </doc>
    </method>
    <method name="setNodesToProcess"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="nodes" type="java.util.List"/>
      <doc>
      <![CDATA[Sets the list of Nodes to process.

 @param nodes Nodes.]]>
      </doc>
    </method>
    <method name="verifyCommandOptions"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="commandName" type="java.lang.String"/>
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <doc>
      <![CDATA[Verifies if the command line options are sane.

 @param commandName - Name of the command
 @param cmd         - Parsed Command Line]]>
      </doc>
    </method>
    <method name="getClusterURI" return="java.net.URI"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets cluster URL.

 @return - URL]]>
      </doc>
    </method>
    <method name="setClusterURI"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clusterURI" type="java.net.URI"/>
      <doc>
      <![CDATA[Set cluster URL.

 @param clusterURI - URL]]>
      </doc>
    </method>
    <method name="getDataNodeProxy" return="org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="datanode" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Copied from DFSAdmin.java. -- Creates a connection to dataNode.

 @param datanode - dataNode.
 @return ClientDataNodeProtocol
 @throws IOException]]>
      </doc>
    </method>
    <method name="create" return="org.apache.hadoop.fs.FSDataOutputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="fileName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns a file created in the cluster.

 @param fileName - fileName to open.
 @return OutputStream.
 @throws IOException]]>
      </doc>
    </method>
    <method name="open" return="org.apache.hadoop.fs.FSDataInputStream"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="fileName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns a InputStream to read data.]]>
      </doc>
    </method>
    <method name="getOutputPath" return="org.apache.hadoop.fs.Path"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the output path where the plan and snapshot gets written.

 @return Path]]>
      </doc>
    </method>
    <method name="addValidCommandParameters"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="key" type="java.lang.String"/>
      <param name="desc" type="java.lang.String"/>
      <doc>
      <![CDATA[Adds valid params to the valid args table.

 @param key
 @param desc]]>
      </doc>
    </method>
    <method name="getCluster" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the cluster.

 @return Cluster.]]>
      </doc>
    </method>
    <method name="getDefaultTop" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[returns default top number of nodes.
 @return default top number of nodes.]]>
      </doc>
    </method>
    <method name="recordOutput"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="result" type="org.apache.commons.lang.text.StrBuilder"/>
      <param name="outputLine" type="java.lang.String"/>
      <doc>
      <![CDATA[Put output line to log and string buffer.]]>
      </doc>
    </method>
    <method name="parseTopNodes" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <param name="result" type="org.apache.commons.lang.text.StrBuilder"/>
      <doc>
      <![CDATA[Parse top number of nodes to be processed.
 @return top number of nodes to be processed.]]>
      </doc>
    </method>
    <method name="populatePathNames"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Reads the Physical path of the disks we are balancing. This is needed to
 make the disk balancer human friendly and not used in balancing.

 @param node - Disk Balancer Node.]]>
      </doc>
    </method>
    <method name="setTopNodes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="topNodes" type="int"/>
      <doc>
      <![CDATA[Set top number of nodes to be processed.]]>
      </doc>
    </method>
    <method name="getTopNodes" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get top number of nodes to be processed.
 @return top number of nodes to be processed.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Common interface for command handling.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.command.Command -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.command.ExecuteCommand -->
  <class name="ExecuteCommand" extends="org.apache.hadoop.hdfs.server.diskbalancer.command.Command"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ExecuteCommand" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs ExecuteCommand.

 @param conf - Configuration.]]>
      </doc>
    </constructor>
    <method name="execute"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Executes the Client Calls.

 @param cmd - CommandLine]]>
      </doc>
    </method>
    <method name="printHelp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets extended help for this command.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[executes a given plan.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.command.ExecuteCommand -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.command.HelpCommand -->
  <class name="HelpCommand" extends="org.apache.hadoop.hdfs.server.diskbalancer.command.Command"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="HelpCommand" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a help command.

 @param conf - config]]>
      </doc>
    </constructor>
    <method name="execute"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Executes the Client Calls.

 @param cmd - CommandLine]]>
      </doc>
    </method>
    <method name="printHelp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets extended help for this command.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Help Command prints out detailed help about each command.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.command.HelpCommand -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.command.PlanCommand -->
  <class name="PlanCommand" extends="org.apache.hadoop.hdfs.server.diskbalancer.command.Command"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="PlanCommand" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a plan command.]]>
      </doc>
    </constructor>
    <method name="execute"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Runs the plan command. This command can be run with various options like
 <p>
 -plan -node IP -plan -node hostName -plan -node DatanodeUUID

 @param cmd - CommandLine]]>
      </doc>
    </method>
    <method name="printHelp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets extended help for this command.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Class that implements Plan Command.
 <p>
 Plan command reads the Cluster Info and creates a plan for specified data
 node or a set of Data nodes.
 <p>
 It writes the output to a default location unless changed by the user.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.command.PlanCommand -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.command.QueryCommand -->
  <class name="QueryCommand" extends="org.apache.hadoop.hdfs.server.diskbalancer.command.Command"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="QueryCommand" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs QueryCommand.

 @param conf - Configuration.]]>
      </doc>
    </constructor>
    <method name="execute"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Executes the Client Calls.

 @param cmd - CommandLine]]>
      </doc>
    </method>
    <method name="printHelp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets extended help for this command.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Gets the current status of disk balancer command.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.command.QueryCommand -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.command.ReportCommand -->
  <class name="ReportCommand" extends="org.apache.hadoop.hdfs.server.diskbalancer.command.Command"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReportCommand" type="org.apache.hadoop.conf.Configuration, java.io.PrintStream"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="execute"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="cmd" type="org.apache.commons.cli.CommandLine"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="printHelp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Prints the help message.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Executes the report command.

 This command will report volume information for a specific DataNode or top X
 DataNode(s) benefiting from running DiskBalancer.

 This is done by reading the cluster info, sorting the DiskbalancerNodes by
 their NodeDataDensity and printing out the info.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.command.ReportCommand -->
</package>
<package name="org.apache.hadoop.hdfs.server.diskbalancer.connectors">
  <!-- start interface org.apache.hadoop.hdfs.server.diskbalancer.connectors.ClusterConnector -->
  <interface name="ClusterConnector"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getNodes" return="java.util.List"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[getNodes function returns a list of DiskBalancerDataNodes.

 @return Array of DiskBalancerDataNodes]]>
      </doc>
    </method>
    <method name="getConnectorInfo" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns info about the connector.

 @return String.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[ClusterConnector interface hides all specifics about how we communicate to
 the HDFS cluster. This interface returns data in classes that diskbalancer
 understands.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.diskbalancer.connectors.ClusterConnector -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.connectors.ConnectorFactory -->
  <class name="ConnectorFactory" extends="java.lang.Object"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="getCluster" return="org.apache.hadoop.hdfs.server.diskbalancer.connectors.ClusterConnector"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clusterURI" type="java.net.URI"/>
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="URISyntaxException" type="java.net.URISyntaxException"/>
      <doc>
      <![CDATA[Constructs an appropriate connector based on the URL.
 @param clusterURI - URL
 @return ClusterConnector]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Connector factory creates appropriate connector based on the URL.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.connectors.ConnectorFactory -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.connectors.JsonNodeConnector -->
  <class name="JsonNodeConnector" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.diskbalancer.connectors.ClusterConnector"/>
    <constructor name="JsonNodeConnector" type="java.net.URL"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a JsonNodeConnector.
 @param clusterURI - A file URL that contains cluster information.]]>
      </doc>
    </constructor>
    <method name="getNodes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[getNodes function connects to a cluster definition file
 and returns nodes defined in that file.

 @return Array of DiskBalancerDataNodes]]>
      </doc>
    </method>
    <method name="getConnectorInfo" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns info about the connector.

 @return String.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A connector that understands JSON data cluster models.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.connectors.JsonNodeConnector -->
</package>
<package name="org.apache.hadoop.hdfs.server.diskbalancer.datamodel">
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster -->
  <class name="DiskBalancerCluster" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DiskBalancerCluster"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Empty Constructor needed by Jackson.]]>
      </doc>
    </constructor>
    <constructor name="DiskBalancerCluster" type="org.apache.hadoop.hdfs.server.diskbalancer.connectors.ClusterConnector"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Constructs a DiskBalancerCluster.

 @param connector - ClusterConnector
 @throws IOException]]>
      </doc>
    </constructor>
    <method name="parseJson" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="json" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Parses a Json string and converts to DiskBalancerCluster.

 @param json - Json String
 @return DiskBalancerCluster
 @throws IOException]]>
      </doc>
    </method>
    <method name="readClusterInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[readClusterInfo connects to the cluster and reads the node's data.  This
 data is used as basis of rest of computation in DiskBalancerCluster]]>
      </doc>
    </method>
    <method name="getNodes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets all DataNodes in the Cluster.

 @return Array of DisKBalancerDataNodes]]>
      </doc>
    </method>
    <method name="setNodes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="clusterNodes" type="java.util.List"/>
      <doc>
      <![CDATA[Sets the list of nodes of this cluster.

 @param clusterNodes List of Nodes]]>
      </doc>
    </method>
    <method name="getExclusionList" return="java.util.Set"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the current ExclusionList.

 @return List of Nodes that are excluded from diskBalancer right now.]]>
      </doc>
    </method>
    <method name="setExclusionList"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="excludedNodes" type="java.util.Set"/>
      <doc>
      <![CDATA[sets the list of nodes to exclude from process of diskBalancer.

 @param excludedNodes - exclusionList of nodes.]]>
      </doc>
    </method>
    <method name="getThreshold" return="float"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the threshold value. This is used for indicating how much skew is
 acceptable, This is expressed as a percentage. For example to say 20% skew
 between volumes is acceptable set this value to 20.

 @return float]]>
      </doc>
    </method>
    <method name="setThreshold"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="thresholdPercent" type="float"/>
      <doc>
      <![CDATA[Sets the threshold value.

 @param thresholdPercent - float - in percentage]]>
      </doc>
    </method>
    <method name="getInclusionList" return="java.util.Set"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the Inclusion list.

 @return List of machine to be processed by diskBalancer.]]>
      </doc>
    </method>
    <method name="setInclusionList"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="includeNodes" type="java.util.Set"/>
      <doc>
      <![CDATA[Sets the inclusionList.

 @param includeNodes - set of machines to be processed by diskBalancer.]]>
      </doc>
    </method>
    <method name="toJson" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[returns a serialized json string.

 @return String - json
 @throws IOException]]>
      </doc>
    </method>
    <method name="getNodesToProcess" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the Nodes to Process which is the real list of nodes processed by
 diskBalancer.

 @return List of DiskBalancerDataNodes]]>
      </doc>
    </method>
    <method name="setNodesToProcess"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dnNodesToProcess" type="java.util.List"/>
      <doc>
      <![CDATA[Sets the nodes to process.

 @param dnNodesToProcess - List of DataNodes to process]]>
      </doc>
    </method>
    <method name="getOutput" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns th output path for this cluster.]]>
      </doc>
    </method>
    <method name="setOutput"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="output" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the output path for this run.

 @param output - Path]]>
      </doc>
    </method>
    <method name="createSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapShotName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Writes a snapshot of the cluster to the specified directory.

 @param snapShotName - name of the snapshot]]>
      </doc>
    </method>
    <method name="computePlan" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="thresholdPercent" type="double"/>
      <doc>
      <![CDATA[Compute plan takes a node and constructs a planner that creates a plan that
 we would like to follow.
 <p/>
 This function creates a thread pool and executes a planner on each node
 that we are supposed to plan for. Each of these planners return a NodePlan
 that we can persist or schedule for execution with a diskBalancer
 Executor.

 @param thresholdPercent - in percentage
 @return list of NodePlans]]>
      </doc>
    </method>
    <method name="getNodeByUUID" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="uuid" type="java.lang.String"/>
      <doc>
      <![CDATA[Returns a node by UUID.
 @param uuid - Node's UUID
 @return DiskBalancerDataNode.]]>
      </doc>
    </method>
    <method name="getNodeByIPAddress" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ipAddresss" type="java.lang.String"/>
      <doc>
      <![CDATA[Returns a node by IP Address.
 @param ipAddresss - IP address String.
 @return DiskBalancerDataNode.]]>
      </doc>
    </method>
    <method name="getNodeByName" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="hostName" type="java.lang.String"/>
      <doc>
      <![CDATA[Returns a node by hostName.
 @param hostName - HostName.
 @return DiskBalancerDataNode.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[DiskBalancerCluster represents the nodes that we are working against.
 <p/>
 Please Note :
 <p/>
 Semantics of inclusionList and exclusionLists.
 <p/>
 If a non-empty inclusionList is specified then the diskBalancer assumes that
 the user is only interested in processing that list of nodes. This node list
 is checked against the exclusionList and only the nodes in inclusionList but
 not in exclusionList is processed.
 <p/>
 if inclusionList is empty, then we assume that all live nodes in the nodes is
 to be processed by diskBalancer. In that case diskBalancer will avoid any
 nodes specified in the exclusionList but will process all nodes in the
 cluster.
 <p/>
 In other words, an empty inclusionList is means all the nodes otherwise
 only a given list is processed and ExclusionList is always honored.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode -->
  <class name="DiskBalancerDataNode" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Comparable"/>
    <constructor name="DiskBalancerDataNode"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs an Empty Data Node.]]>
      </doc>
    </constructor>
    <constructor name="DiskBalancerDataNode" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a DataNode.

 @param dataNodeID - Node ID]]>
      </doc>
    </constructor>
    <method name="getDataNodeIP" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the IP address of this Node.

 @return IP Address string]]>
      </doc>
    </method>
    <method name="setDataNodeIP"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ipaddress" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the IP address of this Node.

 @param ipaddress - IP Address]]>
      </doc>
    </method>
    <method name="getDataNodePort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the Port of this DataNode.

 @return Port Number]]>
      </doc>
    </method>
    <method name="setDataNodePort"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="port" type="int"/>
      <doc>
      <![CDATA[Sets the DataNode Port number.

 @param port - Datanode Port Number]]>
      </doc>
    </method>
    <method name="getDataNodeName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get DataNode DNS name.

 @return name of the node]]>
      </doc>
    </method>
    <method name="setDataNodeName"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets node's DNS name.

 @param name - Data node name]]>
      </doc>
    </method>
    <method name="getVolumeSets" return="java.util.Map"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the Volume sets on this node.

 @return a Map of VolumeSets]]>
      </doc>
    </method>
    <method name="getDataNodeUUID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns datanode ID.]]>
      </doc>
    </method>
    <method name="setDataNodeUUID"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nodeID" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets Datanode UUID.

 @param nodeID - Node ID.]]>
      </doc>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
      <doc>
      <![CDATA[Indicates whether some other object is "equal to" this one.]]>
      </doc>
    </method>
    <method name="compareTo" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"/>
      <doc>
      <![CDATA[Compares this object with the specified object for order.  Returns a
 negative integer, zero, or a positive integer as this object is less than,
 equal to, or greater than the specified object.

 @param that the object to be compared.
 @return a negative integer, zero, or a positive integer as this object is
 less than, equal to, or greater than the specified object.
 @throws NullPointerException if the specified object is null
 @throws ClassCastException   if the specified object's type prevents it
                              from being compared to this object.]]>
      </doc>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a hash code value for the object. This method is supported for the
 benefit of hash tables such as those provided by {@link HashMap}.]]>
      </doc>
    </method>
    <method name="getNodeDataDensity" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[returns NodeDataDensity Metric.

 @return float]]>
      </doc>
    </method>
    <method name="computeNodeDensity"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[computes nodes data density.
 <p/>
 This metric allows us to compare different  nodes and how well the data is
 spread across a set of volumes inside the node.]]>
      </doc>
    </method>
    <method name="isBalancingNeeded" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="threshold" type="double"/>
      <doc>
      <![CDATA[Computes if this node needs balancing at all.

 @param threshold - Percentage
 @return true or false]]>
      </doc>
    </method>
    <method name="addVolume"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volume" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Adds a volume to the DataNode.
 <p/>
 it is assumed that we have one thread per node hence this call is not
 synchronised neither is the map is protected.

 @param volume - volume]]>
      </doc>
    </method>
    <method name="getVolumeCount" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns how many volumes are in the DataNode.

 @return int]]>
      </doc>
    </method>
    <doc>
    <![CDATA[DiskBalancerDataNode represents a DataNode that exists in the cluster. It
 also contains a metric called nodeDataDensity which allows us to compare
 between a set of Nodes.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume -->
  <class name="DiskBalancerVolume" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DiskBalancerVolume"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs DiskBalancerVolume.]]>
      </doc>
    </constructor>
    <method name="parseJson" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="json" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Parses a Json string and converts to DiskBalancerVolume.

 @param json - Json String

 @return DiskBalancerCluster

 @throws IOException]]>
      </doc>
    </method>
    <method name="getVolumeDataDensity" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get this volume Data Density
 Please see DiskBalancerVolumeSet#computeVolumeDataDensity to see how
 this is computed.

 @return float.]]>
      </doc>
    </method>
    <method name="setVolumeDataDensity"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volDataDensity" type="double"/>
      <doc>
      <![CDATA[Sets this volume's data density.

 @param volDataDensity - density]]>
      </doc>
    </method>
    <method name="isTransient" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Indicates if the volume is Transient in nature.

 @return true or false.]]>
      </doc>
    </method>
    <method name="setTransient"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="aTransient" type="boolean"/>
      <doc>
      <![CDATA[Sets volumes transient nature.

 @param aTransient - bool]]>
      </doc>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
      <doc>
      <![CDATA[Compares two volumes and decides if it is the same volume.

 @param o Volume Object

 @return boolean]]>
      </doc>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Computes hash code for a diskBalancerVolume.

 @return int]]>
      </doc>
    </method>
    <method name="getCapacity" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Capacity of this volume.

 @return long]]>
      </doc>
    </method>
    <method name="getFreeSpace" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get free space of the volume.

 @return long]]>
      </doc>
    </method>
    <method name="getUsedRatio" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get ratio between used space and capacity.

 @return double]]>
      </doc>
    </method>
    <method name="getFreeRatio" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get ratio between free space and capacity.

 @return double]]>
      </doc>
    </method>
    <method name="setCapacity"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="totalCapacity" type="long"/>
      <doc>
      <![CDATA[Sets the capacity of this volume.

 @param totalCapacity long]]>
      </doc>
    </method>
    <method name="isFailed" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Indicates if this is a failed volume.

 @return boolean]]>
      </doc>
    </method>
    <method name="setFailed"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fail" type="boolean"/>
      <doc>
      <![CDATA[Sets the failed flag for this volume.

 @param fail boolean]]>
      </doc>
    </method>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the path for this volume.

 @return String]]>
      </doc>
    </method>
    <method name="setPath"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volPath" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the path for this volume.

 @param volPath Path]]>
      </doc>
    </method>
    <method name="getReserved" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the reserved size for this volume.

 @return Long - Reserved size.]]>
      </doc>
    </method>
    <method name="setReserved"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reservedSize" type="long"/>
      <doc>
      <![CDATA[Sets the reserved size.

 @param reservedSize -- Sets the reserved.]]>
      </doc>
    </method>
    <method name="getStorageType" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the StorageType.

 @return String StorageType.]]>
      </doc>
    </method>
    <method name="setStorageType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="typeOfStorage" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the StorageType.

 @param typeOfStorage - Storage Type String.]]>
      </doc>
    </method>
    <method name="getUsed" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the dfsUsed Size.

 @return - long - used space]]>
      </doc>
    </method>
    <method name="setUsed"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dfsUsedSpace" type="long"/>
      <doc>
      <![CDATA[Sets the used Space for Long.

 @param dfsUsedSpace - dfsUsedSpace for this volume.]]>
      </doc>
    </method>
    <method name="getUuid" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the uuid for this volume.

 @return String - uuid of th volume]]>
      </doc>
    </method>
    <method name="setUuid"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the uuid for this volume.

 @param id - String]]>
      </doc>
    </method>
    <method name="computeEffectiveCapacity" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns effective capacity of a volume.

 @return float - fraction that represents used capacity.]]>
      </doc>
    </method>
    <method name="toJson" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[returns a Json String.

 @return String

 @throws IOException]]>
      </doc>
    </method>
    <method name="isSkip" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[returns if we should skip this volume.
 @return true / false]]>
      </doc>
    </method>
    <method name="setSkip"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="skipValue" type="boolean"/>
      <doc>
      <![CDATA[Sets the Skip value for this volume.
 @param skipValue bool]]>
      </doc>
    </method>
    <method name="computeUsedPercentage" return="float"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the usedPercentage of a disk.
 This is useful in debugging disk usage
 @return float]]>
      </doc>
    </method>
    <method name="setIsTransient"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="transientValue" type="boolean"/>
      <doc>
      <![CDATA[Tells us if a volume is transient.
 @param transientValue]]>
      </doc>
    </method>
    <method name="isReadOnly" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Tells us if this volume is read-only.
 @return true / false]]>
      </doc>
    </method>
    <method name="setReadOnly"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="readOnly" type="boolean"/>
      <doc>
      <![CDATA[Sets this volume as read only.
 @param readOnly - boolean]]>
      </doc>
    </method>
    <doc>
    <![CDATA[DiskBalancerVolume represents a volume in the DataNode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet -->
  <class name="DiskBalancerVolumeSet" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DiskBalancerVolumeSet"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs Empty DiskNBalanceVolumeSet.
 This is needed by jackson]]>
      </doc>
    </constructor>
    <constructor name="DiskBalancerVolumeSet" type="boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a DiskBalancerVolumeSet.

 @param isTransient - boolean]]>
      </doc>
    </constructor>
    <constructor name="DiskBalancerVolumeSet" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a new DiskBalancerVolumeSet.]]>
      </doc>
    </constructor>
    <method name="isTransient" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Tells us if this volumeSet is transient.

 @return - true or false]]>
      </doc>
    </method>
    <method name="setTransient"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="transientValue" type="boolean"/>
      <doc>
      <![CDATA[Set the transient properties for this volumeSet.

 @param transientValue - Boolean]]>
      </doc>
    </method>
    <method name="computeVolumeDataDensity"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Computes Volume Data Density. Adding a new volume changes
 the volumeDataDensity for all volumes. So we throw away
 our priority queue and recompute everything.

 we discard failed volumes from this computation.

 totalCapacity = totalCapacity of this volumeSet
 totalUsed = totalDfsUsed for this volumeSet
 idealUsed = totalUsed / totalCapacity
 dfsUsedRatio = dfsUsedOnAVolume / Capacity On that Volume
 volumeDataDensity = idealUsed - dfsUsedRatio]]>
      </doc>
    </method>
    <method name="getVolumeCount" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the number of volumes in the Volume Set.

 @return int]]>
      </doc>
    </method>
    <method name="getStorageType" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get Storage Type.

 @return String]]>
      </doc>
    </method>
    <method name="setStorageType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="typeOfStorage" type="java.lang.String"/>
      <doc>
      <![CDATA[Set Storage Type.
 @param typeOfStorage -- StorageType]]>
      </doc>
    </method>
    <method name="addVolume"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volume" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[adds a given volume into this volume set.

 @param volume - volume to add.

 @throws Exception]]>
      </doc>
    </method>
    <method name="getVolumes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a list diskVolumes that are part of this volume set.

 @return List]]>
      </doc>
    </method>
    <method name="getSortedQueue" return="java.util.TreeSet"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isBalancingNeeded" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="thresholdPercentage" type="double"/>
      <doc>
      <![CDATA[Computes whether we need to do any balancing on this volume Set at all.
 It checks if any disks are out of threshold value

 @param thresholdPercentage - threshold - in percentage

 @return true if balancing is needed false otherwise.]]>
      </doc>
    </method>
    <method name="removeVolume"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volume" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"/>
      <doc>
      <![CDATA[Remove a volume from the current set.

 This call does not recompute the volumeDataDensity. It has to be
 done manually after this call.

 @param volume - Volume to remove]]>
      </doc>
    </method>
    <method name="getSetID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get Volume Set ID.
 @return String]]>
      </doc>
    </method>
    <method name="setSetID"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volID" type="java.lang.String"/>
      <doc>
      <![CDATA[Set VolumeSet ID.
 @param volID String]]>
      </doc>
    </method>
    <method name="getIdealUsed" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the idealUsed for this volume set.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[DiskBalancerVolumeSet is a collection of storage devices on the
 data node which are of similar StorageType.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet -->
</package>
<package name="org.apache.hadoop.hdfs.server.diskbalancer.planner">
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.planner.GreedyPlanner -->
  <class name="GreedyPlanner" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.diskbalancer.planner.Planner"/>
    <constructor name="GreedyPlanner" type="double, org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a greedy planner.

 @param threshold - Disk tolerance that we are ok with
 @param node      - node on which this planner is operating upon]]>
      </doc>
    </constructor>
    <method name="plan" return="org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Computes a node plan for the given node.

 @return NodePlan
 @throws Exception]]>
      </doc>
    </method>
    <method name="balanceVolumeSet"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"/>
      <param name="vSet" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet"/>
      <param name="plan" type="org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Computes Steps to make a DiskBalancerVolumeSet Balanced.

 @param node
 @param vSet - DiskBalancerVolumeSet
 @param plan - NodePlan]]>
      </doc>
    </method>
    <field name="MB" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="GB" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="TB" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Greedy Planner is a simple planner that computes the largest possible move at
 any point of time given a volumeSet.
 <p/>
 This is done by choosing the disks with largest  amount of data above and
 below the idealStorage and then a move is scheduled between them.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.planner.GreedyPlanner -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep -->
  <class name="MoveStep" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.diskbalancer.planner.Step"/>
    <constructor name="MoveStep" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume, double, org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume, long, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs a MoveStep for the volume set.

 @param sourceVolume      - Source Disk
 @param idealStorage      - Ideal Storage Value for this disk set
 @param destinationVolume - Destination dis
 @param bytesToMove       - number of bytes to move
 @param volumeSetID       - a diskBalancer generated id.]]>
      </doc>
    </constructor>
    <constructor name="MoveStep"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Empty Constructor for JSON serialization.]]>
      </doc>
    </constructor>
    <method name="getBytesToMove" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns number of bytes to move.

 @return - long]]>
      </doc>
    </method>
    <method name="getDestinationVolume" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the destination volume.

 @return - volume]]>
      </doc>
    </method>
    <method name="getIdealStorage" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the IdealStorage.

 @return float]]>
      </doc>
    </method>
    <method name="getSourceVolume" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets Source Volume.

 @return -- Source Volume]]>
      </doc>
    </method>
    <method name="getVolumeSetID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets a volume Set ID.

 @return String]]>
      </doc>
    </method>
    <method name="setSourceVolume"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sourceVolume" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"/>
      <doc>
      <![CDATA[Set source volume.

 @param sourceVolume - volume]]>
      </doc>
    </method>
    <method name="setDestinationVolume"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="destinationVolume" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"/>
      <doc>
      <![CDATA[Sets destination volume.

 @param destinationVolume - volume]]>
      </doc>
    </method>
    <method name="setIdealStorage"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="idealStorage" type="double"/>
      <doc>
      <![CDATA[Sets Ideal Storage.

 @param idealStorage - ideal Storage]]>
      </doc>
    </method>
    <method name="setBytesToMove"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesToMove" type="long"/>
      <doc>
      <![CDATA[Sets bytes to move.

 @param bytesToMove - number of bytes]]>
      </doc>
    </method>
    <method name="setVolumeSetID"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volumeSetID" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets volume id.

 @param volumeSetID - volume ID]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a string representation of the object.

 @return a string representation of the object.]]>
      </doc>
    </method>
    <method name="getSizeString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="size" type="long"/>
      <doc>
      <![CDATA[Returns human readable move sizes.

 @param size - bytes being moved.
 @return String]]>
      </doc>
    </method>
    <method name="getMaxDiskErrors" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets Maximum numbers of errors to be tolerated before this
 move operation is aborted.
 @return  long.]]>
      </doc>
    </method>
    <method name="setMaxDiskErrors"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="maxDiskErrors" type="long"/>
      <doc>
      <![CDATA[Sets the maximum numbers of Errors to be tolerated before this
 step is aborted.
 @param maxDiskErrors - long]]>
      </doc>
    </method>
    <method name="getTolerancePercent" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Tolerance Percentage indicates when a move operation is considered good
 enough. This is a percentage of deviation from ideal that is considered
 fine.

 For example : if the ideal amount on each disk was 1 TB and the
 tolerance was 10%, then getting to 900 GB on the destination disk is
 considerd good enough.

 @return tolerance percentage.]]>
      </doc>
    </method>
    <method name="setTolerancePercent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="tolerancePercent" type="long"/>
      <doc>
      <![CDATA[Sets the tolerance percentage.
 @param tolerancePercent  - long]]>
      </doc>
    </method>
    <method name="getBandwidth" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the disk Bandwidth. That is the MB/Sec to copied. We will max out
 on this amount of throughput. This is useful to prevent too much I/O on
 datanode while data node is in use.
 @return  long.]]>
      </doc>
    </method>
    <method name="setBandwidth"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bandwidth" type="long"/>
      <doc>
      <![CDATA[Sets the maximum disk bandwidth per sec to use for this step.
 @param bandwidth  - Long, MB / Sec of data to be moved between
                   source and destinatin volume.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Ignore fields with default values. In most cases Throughtput, diskErrors
 tolerancePercent and bandwidth will be the system defaults.
 So we will avoid serializing them into JSON.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.planner.MoveStep -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan -->
  <class name="NodePlan" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NodePlan"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs an Empty Node Plan.]]>
      </doc>
    </constructor>
    <constructor name="NodePlan" type="java.lang.String, int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructs an empty NodePlan.]]>
      </doc>
    </constructor>
    <method name="getTimeStamp" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[returns timestamp when this plan was created.

 @return long]]>
      </doc>
    </method>
    <method name="setTimeStamp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="timeStamp" type="long"/>
      <doc>
      <![CDATA[Sets the timestamp when this plan was created.

 @param timeStamp]]>
      </doc>
    </method>
    <method name="getVolumeSetPlans" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a Map of  VolumeSetIDs and volumeSetPlans.

 @return Map]]>
      </doc>
    </method>
    <method name="setNodeName"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nodeName" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets Node Name.

 @param nodeName - Name]]>
      </doc>
    </method>
    <method name="setVolumeSetPlans"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="volumeSetPlans" type="java.util.List"/>
      <doc>
      <![CDATA[Sets a volume List plan.

 @param volumeSetPlans - List of plans.]]>
      </doc>
    </method>
    <method name="getNodeName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the DataNode URI.

 @return URI]]>
      </doc>
    </method>
    <method name="setURI"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dataNodeName" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the DataNodeURI.

 @param dataNodeName - String]]>
      </doc>
    </method>
    <method name="getPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the DataNode RPC Port.

 @return port]]>
      </doc>
    </method>
    <method name="setPort"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="port" type="int"/>
      <doc>
      <![CDATA[Sets the DataNode RPC Port.

 @param port - int]]>
      </doc>
    </method>
    <method name="parseJson" return="org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="json" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Parses a Json string and converts to NodePlan.

 @param json - Json String
 @return NodePlan
 @throws IOException]]>
      </doc>
    </method>
    <method name="toJson" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Returns a Json representation of NodePlan.

 @return - json String
 @throws IOException]]>
      </doc>
    </method>
    <method name="getNodeUUID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[gets the Node UUID.

 @return Node UUID.]]>
      </doc>
    </method>
    <method name="setNodeUUID"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nodeUUID" type="java.lang.String"/>
      <doc>
      <![CDATA[Sets the Node UUID.

 @param nodeUUID - UUID of the node.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[NodePlan is a set of volumeSetPlans.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan -->
  <!-- start interface org.apache.hadoop.hdfs.server.diskbalancer.planner.Planner -->
  <interface name="Planner"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="plan" return="org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <doc>
    <![CDATA[Planner interface allows different planners to be created.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.diskbalancer.planner.Planner -->
  <!-- start class org.apache.hadoop.hdfs.server.diskbalancer.planner.PlannerFactory -->
  <class name="PlannerFactory" extends="java.lang.Object"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="getPlanner" return="org.apache.hadoop.hdfs.server.diskbalancer.planner.Planner"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="plannerName" type="java.lang.String"/>
      <param name="node" type="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode"/>
      <param name="threshold" type="double"/>
      <doc>
      <![CDATA[Gets a planner object.
 @param plannerName - name of the planner.
 @param node - Datanode.
 @param threshold - percentage
 @return Planner]]>
      </doc>
    </method>
    <field name="GREEDY_PLANNER" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Returns a planner based on the user defined tags.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.diskbalancer.planner.PlannerFactory -->
  <!-- start interface org.apache.hadoop.hdfs.server.diskbalancer.planner.Step -->
  <interface name="Step"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getBytesToMove" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the number of bytes to move.

 @return bytes]]>
      </doc>
    </method>
    <method name="getDestinationVolume" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the destination volume.

 @return - volume]]>
      </doc>
    </method>
    <method name="getIdealStorage" return="double"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the IdealStorage.

 @return idealStorage]]>
      </doc>
    </method>
    <method name="getSourceVolume" return="org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets Source Volume.

 @return -- Source Volume]]>
      </doc>
    </method>
    <method name="getVolumeSetID" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets a volume Set ID.

 @return String]]>
      </doc>
    </method>
    <method name="getSizeString" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="size" type="long"/>
      <doc>
      <![CDATA[Returns a String representation of the Step Size.

 @return String]]>
      </doc>
    </method>
    <method name="getMaxDiskErrors" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns maximum number of disk erros tolerated.
 @return long.]]>
      </doc>
    </method>
    <method name="getTolerancePercent" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns tolerance percentage, the good enough value
 when we move data from one to disk to another.
 @return long.]]>
      </doc>
    </method>
    <method name="getBandwidth" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns max disk bandwidth that disk balancer will use.
 Expressed in MB/sec. For example, a value like 10
 indicates that disk balancer will only move 10 MB / sec
 while it is running.
 @return long.]]>
      </doc>
    </method>
    <method name="setTolerancePercent"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="tolerancePercent" type="long"/>
      <doc>
      <![CDATA[Sets Tolerance percent on a specific step.
 @param tolerancePercent - tolerance in percentage.]]>
      </doc>
    </method>
    <method name="setBandwidth"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bandwidth" type="long"/>
      <doc>
      <![CDATA[Set Bandwidth on a specific step.
 @param bandwidth - in MB/s]]>
      </doc>
    </method>
    <method name="setMaxDiskErrors"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="maxDiskErrors" type="long"/>
      <doc>
      <![CDATA[Set maximum errors to tolerate before disk balancer step fails.
 @param maxDiskErrors - error count.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A step in the plan.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.diskbalancer.planner.Step -->
</package>
<package name="org.apache.hadoop.hdfs.server.mover">
</package>
<package name="org.apache.hadoop.hdfs.server.namenode">
  <!-- start class org.apache.hadoop.hdfs.server.namenode.AclEntryStatusFormat -->
  <class name="AclEntryStatusFormat" extends="java.lang.Enum"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.AclEntryStatusFormat[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.AclEntryStatusFormat"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="toInt" return="int[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="aclEntries" type="java.util.List"/>
    </method>
    <method name="toAclEntries" return="com.google.common.collect.ImmutableList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entries" type="int[]"/>
    </method>
    <doc>
    <![CDATA[Class to pack an AclEntry into an integer. <br>
 An ACL entry is represented by a 32-bit integer in Big Endian format. <br>
 The bits can be divided in four segments: <br>
 [0:1) || [1:3) || [3:6) || [6:7) || [7:32) <br>
 <br>
 [0:1) -- the scope of the entry (AclEntryScope) <br>
 [1:3) -- the type of the entry (AclEntryType) <br>
 [3:6) -- the permission of the entry (FsAction) <br>
 [6:7) -- A flag to indicate whether Named entry or not <br>
 [7:32) -- the name of the entry, which is an ID that points to a <br>
 string in the StringTableSection. <br>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.AclEntryStatusFormat -->
  <!-- start interface org.apache.hadoop.hdfs.server.namenode.AuditLogger -->
  <interface name="AuditLogger"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="initialize"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <doc>
      <![CDATA[Called during initialization of the logger.

 @param conf The configuration object.]]>
      </doc>
    </method>
    <method name="logAuditEvent"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="succeeded" type="boolean"/>
      <param name="userName" type="java.lang.String"/>
      <param name="addr" type="java.net.InetAddress"/>
      <param name="cmd" type="java.lang.String"/>
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <param name="stat" type="org.apache.hadoop.fs.FileStatus"/>
      <doc>
      <![CDATA[Called to log an audit event.
 <p>
 This method must return as quickly as possible, since it's called
 in a critical section of the NameNode's operation.

 @param succeeded Whether authorization succeeded.
 @param userName Name of the user executing the request.
 @param addr Remote address of the request.
 @param cmd The requested command.
 @param src Path of affected source file.
 @param dst Path of affected destination file (if any).
 @param stat File information for operations that change the file's
             metadata (permissions, owner, times, etc).]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Interface defining an audit logger.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.namenode.AuditLogger -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.CacheManager.PersistState -->
  <class name="CacheManager.PersistState" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="PersistState" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.CacheManagerSection, java.util.List, java.util.List"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <field name="section" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.CacheManagerSection"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="pools" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="directives" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.CacheManager.PersistState -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.CachePool.DirectiveList -->
  <class name="CachePool.DirectiveList" extends="org.apache.hadoop.util.IntrusiveCollection"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="getCachePool" return="org.apache.hadoop.hdfs.server.namenode.CachePool"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.CachePool.DirectiveList -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.Content -->
  <class name="Content" extends="java.lang.Enum"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.Content[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.Content"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[The content types such as file, directory and symlink to be computed.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.Content -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.Content.Counts -->
  <class name="Content.Counts" extends="org.apache.hadoop.hdfs.util.EnumCounters"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="newInstance" return="org.apache.hadoop.hdfs.server.namenode.Content.Counts"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Content counts.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.Content.Counts -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.Content.CountsMap -->
  <class name="Content.CountsMap" extends="org.apache.hadoop.hdfs.util.EnumCounters.Map"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <doc>
    <![CDATA[A map of counters for the current state and the snapshots.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.Content.CountsMap -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.Content.CountsMap.Key -->
  <class name="Content.CountsMap.Key" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.Content.CountsMap.Key[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.Content.CountsMap.Key"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[The key type of the map.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.Content.CountsMap.Key -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.ContentCounts -->
  <class name="ContentCounts" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getFileCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDirectoryCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSymlinkCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getLength" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStoragespace" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshotCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshotableDirectoryCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTypeSpaces" return="long[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTypeSpace" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="t" type="org.apache.hadoop.fs.StorageType"/>
    </method>
    <method name="addContent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="org.apache.hadoop.hdfs.server.namenode.Content"/>
      <param name="val" type="long"/>
    </method>
    <method name="addContents"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.server.namenode.ContentCounts"/>
    </method>
    <method name="addTypeSpace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="t" type="org.apache.hadoop.fs.StorageType"/>
      <param name="val" type="long"/>
    </method>
    <method name="addTypeSpaces"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.util.EnumCounters"/>
    </method>
    <doc>
    <![CDATA[The counter to be computed for content types such as file, directory and symlink,
 and the storage type usage such as SSD, DISK, ARCHIVE.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.ContentCounts -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder -->
  <class name="ContentCounts.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="file" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="file" type="long"/>
    </method>
    <method name="directory" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="directory" type="long"/>
    </method>
    <method name="symlink" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="symlink" type="long"/>
    </method>
    <method name="length" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="length" type="long"/>
    </method>
    <method name="storagespace" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="storagespace" type="long"/>
    </method>
    <method name="snapshot" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshot" type="long"/>
    </method>
    <method name="snapshotable_directory" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotable_directory" type="long"/>
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.server.namenode.ContentCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.ContentCounts.Builder -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.DefaultINodeAttributesProvider -->
  <class name="DefaultINodeAttributesProvider" extends="org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DefaultINodeAttributesProvider"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="start"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="stop"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pathElements" type="java.lang.String[]"/>
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
    </method>
    <field name="DEFAULT_PROVIDER" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider"
      transient="false" volatile="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A default implementation of the INodeAttributesProvider]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.DefaultINodeAttributesProvider -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature -->
  <class name="DirectoryWithQuotaFeature" extends="java.lang.Object"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.INode.Feature"/>
    <method name="addSpaceConsumed2Cache"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="delta" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
      <doc>
      <![CDATA[Update the space/namespace/type usage of the tree
 
 @param delta the change of the namespace/space/type usage]]>
      </doc>
    </method>
    <method name="getSpaceConsumed" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the namespace and storagespace and typespace consumed.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="DEFAULT_NAMESPACE_QUOTA" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="DEFAULT_STORAGE_SPACE_QUOTA" type="long"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Quota feature for {@link INodeDirectory}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.Builder -->
  <class name="DirectoryWithQuotaFeature.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="nameSpaceQuota" return="org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nameSpaceQuota" type="long"/>
    </method>
    <method name="storageSpaceQuota" return="org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="spaceQuota" type="long"/>
    </method>
    <method name="typeQuotas" return="org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="typeQuotas" type="org.apache.hadoop.hdfs.util.EnumCounters"/>
    </method>
    <method name="typeQuota" return="org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.fs.StorageType"/>
      <param name="quota" type="long"/>
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.Builder -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector -->
  <class name="EncryptionFaultInjector" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="EncryptionFaultInjector"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInstance" return="org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="startFileAfterGenerateKey"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <field name="instance" type="org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector"
      transient="false" volatile="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Used to inject certain faults for testing.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.EncryptionFaultInjector -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager -->
  <class name="EncryptionZoneManager" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="EncryptionZoneManager" type="org.apache.hadoop.hdfs.server.namenode.FSDirectory, org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct a new EncryptionZoneManager.

 @param dir Enclosing FSDirectory]]>
      </doc>
    </constructor>
    <method name="getNumEncryptionZones" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return number of encryption zones.]]>
      </doc>
    </method>
    <method name="hasCreatedEncryptionZone" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return Whether there has been any attempt to create an encryption zone in
 the cluster at all. If not, it is safe to quickly return null when
 checking the encryption information of any file or directory in the
 cluster.]]>
      </doc>
    </method>
    <field name="LOG" type="org.slf4j.Logger"
      transient="false" volatile="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Manages the list of encryption zones in the filesystem.
 <p/>
 The EncryptionZoneManager has its own lock, but relies on the FSDirectory
 lock being held for many operations. The FSDirectory lock should not be
 taken if the manager lock is already held.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp -->
  <class name="FSDirAttrOp" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="FSDirAttrOp"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.PositionTrackingInputStream -->
  <class name="FSEditLogLoader.PositionTrackingInputStream" extends="java.io.FilterInputStream"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.StreamLimiter"/>
    <constructor name="PositionTrackingInputStream" type="java.io.InputStream"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="data" type="byte[]"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="read" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="data" type="byte[]"/>
      <param name="offset" type="int"/>
      <param name="length" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="setLimit"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="limit" type="long"/>
    </method>
    <method name="clearLimit"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="mark"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="limit" type="int"/>
    </method>
    <method name="reset"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getPos" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="skip" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="amt" type="long"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[Stream wrapper that keeps track of the current stream position.
 
 This stream also allows us to set a limit on how many bytes we can read
 without getting an exception.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.PositionTrackingInputStream -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.OpInstanceCache -->
  <class name="FSEditLogOp.OpInstanceCache" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="OpInstanceCache"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="get" return="org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.OpInstanceCache"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="get" return="T"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="opCode" type="org.apache.hadoop.hdfs.server.namenode.FSEditLogOpCodes"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.OpInstanceCache -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.Reader -->
  <class name="FSEditLogOp.Reader" extends="java.lang.Object"
    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="create" return="org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.Reader"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInputStream"/>
      <param name="limiter" type="org.apache.hadoop.hdfs.server.namenode.StreamLimiter"/>
      <param name="logVersion" type="int"/>
    </method>
    <method name="setMaxOpSize"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="maxOpSize" type="int"/>
    </method>
    <method name="readOp" return="org.apache.hadoop.hdfs.server.namenode.FSEditLogOp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="skipBrokenEdits" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read an operation from the input stream.
 
 Note that the objects returned from this method may be re-used by future
 calls to the same method.
 
 @param skipBrokenEdits    If true, attempt to skip over damaged parts of
 the input stream, rather than throwing an IOException
 @return the operation read from the stream, or null at the end of the 
         file
 @throws IOException on error.  This function should only throw an
         exception when skipBrokenEdits is false.]]>
      </doc>
    </method>
    <method name="decodeOp" return="org.apache.hadoop.hdfs.server.namenode.FSEditLogOp"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read an opcode from the input stream.

 @return   the opcode, or null on EOF.

 If an exception is thrown, the stream's mark will be set to the first
 problematic byte.  This usually means the beginning of the opcode.]]>
      </doc>
    </method>
    <method name="scanOp" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Similar to decodeOp(), but we only retrieve the transaction ID of the
 Op rather than reading it.  If the edit log format supports length
 prefixing, this can be much faster than full decoding.

 @return the last txid of the segment, or INVALID_TXID on EOF.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Class for reading editlog ops from a stream]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.Reader -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.Writer -->
  <class name="FSEditLogOp.Writer" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Writer" type="org.apache.hadoop.io.DataOutputBuffer"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="writeOp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="op" type="org.apache.hadoop.hdfs.server.namenode.FSEditLogOp"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Write an operation to the output stream
 
 @param op The operation to write
 @throws IOException if an error occurs during writing.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Class for writing editlog ops]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.Writer -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormat.Loader -->
  <class name="FSImageFormat.Loader" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.FSImageFormat.AbstractLoader"/>
    <method name="getLoadedImageMd5" return="org.apache.hadoop.io.MD5Hash"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the MD5 checksum of the image that has been loaded.
 @throws IllegalStateException if load() has not yet been called.]]>
      </doc>
    </method>
    <method name="getLoadedImageTxId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="load"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="curFile" type="java.io.File"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="updateBlocksMap"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="file" type="org.apache.hadoop.hdfs.server.namenode.INodeFile"/>
    </method>
    <method name="getFSDirectoryInLoading" return="org.apache.hadoop.hdfs.server.namenode.FSDirectory"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The FSDirectory of the namesystem where the fsimage is loaded]]>
      </doc>
    </method>
    <method name="loadINodeWithLocalName" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="isSnapshotINode" type="boolean"/>
      <param name="in" type="java.io.DataInput"/>
      <param name="updateINodeMap" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="loadINodeWithLocalName" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="isSnapshotINode" type="boolean"/>
      <param name="in" type="java.io.DataInput"/>
      <param name="updateINodeMap" type="boolean"/>
      <param name="counter" type="org.apache.hadoop.hdfs.server.namenode.startupprogress.StartupProgress.Counter"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="loadINodeFileAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Load {@link INodeFileAttributes}.]]>
      </doc>
    </method>
    <method name="loadINodeDirectoryAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getSnapshot" return="org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[A one-shot class responsible for loading an image. The load() function
 should be called once, after which the getter methods may be used to retrieve
 information about the image that was loaded, if loading was successful.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormat.Loader -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode.Loader -->
  <class name="FSImageFormatPBINode.Loader" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="loadPermission" return="org.apache.hadoop.fs.permission.PermissionStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="long"/>
      <param name="stringTable" type="java.lang.String[]"/>
    </method>
    <method name="loadAclEntries" return="com.google.common.collect.ImmutableList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.AclFeatureProto"/>
      <param name="stringTable" type="java.lang.String[]"/>
    </method>
    <method name="loadXAttrs" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.XAttrFeatureProto"/>
      <param name="stringTable" type="java.lang.String[]"/>
    </method>
    <method name="loadQuotaByStorageTypeEntries" return="com.google.common.collect.ImmutableList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="proto" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.QuotaByStorageTypeFeatureProto"/>
    </method>
    <method name="loadINodeDirectory" return="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="n" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.INode"/>
      <param name="state" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.LoaderContext"/>
    </method>
    <method name="updateBlocksMap"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="file" type="org.apache.hadoop.hdfs.server.namenode.INodeFile"/>
      <param name="bm" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockManager"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode.Loader -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode.Saver -->
  <class name="FSImageFormatPBINode.Saver" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="buildINodeFile" return="org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.INodeFile.Builder"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="file" type="org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes"/>
      <param name="state" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext"/>
    </method>
    <method name="buildINodeDirectory" return="org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.INodeDirectory.Builder"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes"/>
      <param name="state" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode.Saver -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.Loader -->
  <class name="FSImageFormatProtobuf.Loader" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.FSImageFormat.AbstractLoader"/>
    <method name="getLoadedImageMd5" return="org.apache.hadoop.io.MD5Hash"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getLoadedImageTxId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getLoaderContext" return="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.LoaderContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.Loader -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.LoaderContext -->
  <class name="FSImageFormatProtobuf.LoaderContext" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="LoaderContext"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getStringTable" return="java.lang.String[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getRefList" return="java.util.ArrayList"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.LoaderContext -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.Saver -->
  <class name="FSImageFormatProtobuf.Saver" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="getSavedDigest" return="org.apache.hadoop.io.MD5Hash"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getContext" return="org.apache.hadoop.hdfs.server.namenode.SaveNamespaceContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSaverContext" return="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="commitSection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="summary" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.FileSummary.Builder"/>
      <param name="name" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SectionName"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <field name="CHECK_CANCEL_INTERVAL" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.Saver -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext -->
  <class name="FSImageFormatProtobuf.SaverContext" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="SaverContext"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getStringMap" return="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext.DeduplicationMap"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getRefList" return="java.util.ArrayList"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext.DeduplicationMap -->
  <class name="FSImageFormatProtobuf.SaverContext.DeduplicationMap" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SaverContext.DeduplicationMap -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SectionName -->
  <class name="FSImageFormatProtobuf.SectionName" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SectionName[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SectionName"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="fromString" return="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SectionName"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Supported section name. The order of the enum determines the order of
 loading.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.SectionName -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.HdfsAuditLogger -->
  <class name="HdfsAuditLogger" extends="java.lang.Object"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.AuditLogger"/>
    <constructor name="HdfsAuditLogger"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="logAuditEvent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="succeeded" type="boolean"/>
      <param name="userName" type="java.lang.String"/>
      <param name="addr" type="java.net.InetAddress"/>
      <param name="cmd" type="java.lang.String"/>
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <param name="status" type="org.apache.hadoop.fs.FileStatus"/>
    </method>
    <method name="logAuditEvent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="succeeded" type="boolean"/>
      <param name="userName" type="java.lang.String"/>
      <param name="addr" type="java.net.InetAddress"/>
      <param name="cmd" type="java.lang.String"/>
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <param name="stat" type="org.apache.hadoop.fs.FileStatus"/>
      <param name="callerContext" type="org.apache.hadoop.ipc.CallerContext"/>
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="dtSecretManager" type="org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager"/>
      <doc>
      <![CDATA[Same as
 {@link #logAuditEvent(boolean, String, InetAddress, String, String, String,
 FileStatus)} with additional parameters related to logging delegation token
 tracking IDs.
 
 @param succeeded Whether authorization succeeded.
 @param userName Name of the user executing the request.
 @param addr Remote address of the request.
 @param cmd The requested command.
 @param src Path of affected source file.
 @param dst Path of affected destination file (if any).
 @param stat File information for operations that change the file's metadata
          (permissions, owner, times, etc).
 @param callerContext Context information of the caller
 @param ugi UserGroupInformation of the current user, or null if not logging
          token tracking information
 @param dtSecretManager The token secret manager, or null if not logging
          token tracking information]]>
      </doc>
    </method>
    <method name="logAuditEvent"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="succeeded" type="boolean"/>
      <param name="userName" type="java.lang.String"/>
      <param name="addr" type="java.net.InetAddress"/>
      <param name="cmd" type="java.lang.String"/>
      <param name="src" type="java.lang.String"/>
      <param name="dst" type="java.lang.String"/>
      <param name="stat" type="org.apache.hadoop.fs.FileStatus"/>
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="dtSecretManager" type="org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager"/>
      <doc>
      <![CDATA[Same as
 {@link #logAuditEvent(boolean, String, InetAddress, String, String,
 String, FileStatus, CallerContext, UserGroupInformation,
 DelegationTokenSecretManager)} without {@link CallerContext} information.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Extension of {@link AuditLogger}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.HdfsAuditLogger -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo -->
  <class name="INode.BlocksMapUpdateInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BlocksMapUpdateInfo"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getToDeleteList" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The list of blocks that need to be removed from blocksMap]]>
      </doc>
    </method>
    <method name="toUpdateReplicationInfo" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="addDeleteBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="toDelete" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo"/>
      <doc>
      <![CDATA[Add a to-be-deleted block into the
 {@link BlocksMapUpdateInfo#toDeleteList}
 @param toDelete the to-be-deleted block]]>
      </doc>
    </method>
    <method name="addUpdateReplicationFactor"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="block" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo"/>
      <param name="targetRepl" type="short"/>
    </method>
    <method name="clear"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Clear {@link BlocksMapUpdateInfo#toDeleteList}]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Information used for updating the blocksMap when deleting files.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo.UpdatedReplicationInfo -->
  <class name="INode.BlocksMapUpdateInfo.UpdatedReplicationInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="UpdatedReplicationInfo" type="short, org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="block" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="targetReplication" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[The blocks whose replication factor need to be updated.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo.UpdatedReplicationInfo -->
  <!-- start interface org.apache.hadoop.hdfs.server.namenode.INode.Feature -->
  <interface name="INode.Feature"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <doc>
    <![CDATA[INode feature such as {@link FileUnderConstructionFeature}
 and {@link DirectoryWithQuotaFeature}.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.namenode.INode.Feature -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INode.QuotaDelta -->
  <class name="INode.QuotaDelta" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="QuotaDelta"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="add"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="update" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
    </method>
    <method name="addUpdatePath"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeReference"/>
      <param name="update" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
    </method>
    <method name="addQuotaDirUpdate"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
      <param name="update" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
    </method>
    <method name="getCountsCopy" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
    </method>
    <method name="getNsDelta" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getUpdateMap" return="java.util.Map"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getQuotaDirMap" return="java.util.Map"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Information used to record quota usage delta. This data structure is
 usually passed along with an operation like {@link #cleanSubtree}. Note
 that after the operation the delta counts should be decremented from the
 ancestral directories' quota usage.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INode.QuotaDelta -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext -->
  <class name="INode.ReclaimContext" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReclaimContext" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite, org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo, java.util.List, java.util.List"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@param bsps
          block storage policy suite to calculate intended storage type
          usage
 @param collectedBlocks
          blocks collected from the descents for further block
          deletion/update will be added to the given map.
 @param removedINodes
          INodes collected from the descents for further cleaning up of
 @param removedUCFiles]]>
      </doc>
    </constructor>
    <method name="storagePolicySuite" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="collectedBlocks" return="org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="quotaDelta" return="org.apache.hadoop.hdfs.server.namenode.INode.QuotaDelta"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCopy" return="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[make a copy with the same collectedBlocks, removedINodes, and
 removedUCFiles but a new quotaDelta.]]>
      </doc>
    </method>
    <field name="bsps" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="collectedBlocks" type="org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="removedINodes" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="removedUCFiles" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Context object to record blocks and inodes that need to be reclaimed]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider -->
  <class name="INodeAttributeProvider" extends="java.lang.Object"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="INodeAttributeProvider"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="start"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Initialize the provider. This method is called at NameNode startup
 time.]]>
      </doc>
    </method>
    <method name="stop"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Shutdown the provider. This method is called at NameNode shutdown time.]]>
      </doc>
    </method>
    <method name="getAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fullPath" type="java.lang.String"/>
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
    </method>
    <method name="getAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pathElements" type="java.lang.String[]"/>
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
    </method>
    <method name="getAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="components" type="byte[][]"/>
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
    </method>
    <method name="getExternalAccessControlEnforcer" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider.AccessControlEnforcer"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="defaultEnforcer" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider.AccessControlEnforcer"/>
      <doc>
      <![CDATA[Can be over-ridden by implementations to provide a custom Access Control
 Enforcer that can provide an alternate implementation of the
 default permission checking logic.
 @param defaultEnforcer The Default AccessControlEnforcer
 @return The AccessControlEnforcer to use]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider -->
  <!-- start interface org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider.AccessControlEnforcer -->
  <interface name="INodeAttributeProvider.AccessControlEnforcer"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="checkPermission"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fsOwner" type="java.lang.String"/>
      <param name="supergroup" type="java.lang.String"/>
      <param name="callerUgi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="inodeAttrs" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes[]"/>
      <param name="inodes" type="org.apache.hadoop.hdfs.server.namenode.INode[]"/>
      <param name="pathByNameArr" type="byte[][]"/>
      <param name="snapshotId" type="int"/>
      <param name="path" type="java.lang.String"/>
      <param name="ancestorIndex" type="int"/>
      <param name="doCheckOwner" type="boolean"/>
      <param name="ancestorAccess" type="org.apache.hadoop.fs.permission.FsAction"/>
      <param name="parentAccess" type="org.apache.hadoop.fs.permission.FsAction"/>
      <param name="access" type="org.apache.hadoop.fs.permission.FsAction"/>
      <param name="subAccess" type="org.apache.hadoop.fs.permission.FsAction"/>
      <param name="ignoreEmptyDir" type="boolean"/>
      <exception name="AccessControlException" type="org.apache.hadoop.security.AccessControlException"/>
      <doc>
      <![CDATA[Checks permission on a file system object. Has to throw an Exception
 if the filesystem object is not accessessible by the calling Ugi.
 @param fsOwner Filesystem owner (The Namenode user)
 @param supergroup super user geoup
 @param callerUgi UserGroupInformation of the caller
 @param inodeAttrs Array of INode attributes for each path element in the
                   the path
 @param inodes Array of INodes for each path element in the path
 @param pathByNameArr Array of byte arrays of the LocalName
 @param snapshotId the snapshotId of the requested path
 @param path Path String
 @param ancestorIndex Index of ancestor
 @param doCheckOwner perform ownership check
 @param ancestorAccess The access required by the ancestor of the path.
 @param parentAccess The access required by the parent of the path.
 @param access The access required by the path.
 @param subAccess If path is a directory, It is the access required of
                  the path and all the sub-directories. If path is not a
                  directory, there should ideally be no effect.
 @param ignoreEmptyDir Ignore permission checking for empty directory?
 @throws AccessControlException]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The AccessControlEnforcer allows implementations to override the
 default File System permission checking logic enforced on a file system
 object]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider.AccessControlEnforcer -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeAttributes.SnapshotCopy -->
  <class name="INodeAttributes.SnapshotCopy" extends="java.lang.Object"
    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
    <method name="getLocalNameBytes" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getUserName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getGroupName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFsPermission" return="org.apache.hadoop.fs.permission.FsPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFsPermissionShort" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPermissionLong" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAclFeature" return="org.apache.hadoop.hdfs.server.namenode.AclFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getModificationTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAccessTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getXAttrFeature" return="org.apache.hadoop.hdfs.server.namenode.XAttrFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A read-only copy of the inode attributes.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeAttributes.SnapshotCopy -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeDirectory -->
  <class name="INodeDirectory" extends="org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes"/>
    <constructor name="INodeDirectory" type="long, byte[], org.apache.hadoop.fs.permission.PermissionStatus, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[constructor]]>
      </doc>
    </constructor>
    <constructor name="INodeDirectory" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory, boolean, org.apache.hadoop.hdfs.server.namenode.INode.Feature[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Copy constructor
 @param other The INodeDirectory to be copied
 @param adopt Indicate whether or not need to set the parent field of child
              INodes to the new node
 @param featuresToCopy any number of features to copy to the new node.
              The method will do a reference copy, not a deep copy.]]>
      </doc>
    </constructor>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="path" type="java.lang.Object"/>
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
      <exception name="PathIsNotDirectoryException" type="org.apache.hadoop.fs.PathIsNotDirectoryException"/>
      <doc>
      <![CDATA[Cast INode to INodeDirectory.]]>
      </doc>
    </method>
    <method name="isDirectory" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return true unconditionally.]]>
      </doc>
    </method>
    <method name="asDirectory" return="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return this object.]]>
      </doc>
    </method>
    <method name="getLocalStoragePolicyID" return="byte"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStoragePolicyID" return="byte"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getQuotaCounts" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="addSpaceConsumed"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="counts" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
      <param name="verify" type="boolean"/>
      <exception name="QuotaExceededException" type="org.apache.hadoop.hdfs.protocol.QuotaExceededException"/>
    </method>
    <method name="getDirectoryWithQuotaFeature" return="org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[If the directory contains a {@link DirectoryWithQuotaFeature}, return it;
 otherwise, return null.]]>
      </doc>
    </method>
    <method name="addSnapshotFeature" return="org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="diffs" type="org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.DirectoryDiffList"/>
    </method>
    <method name="getDirectoryWithSnapshotFeature" return="org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[If feature list contains a {@link DirectoryWithSnapshotFeature}, return it;
 otherwise, return null.]]>
      </doc>
    </method>
    <method name="isWithSnapshot" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Is this file has the snapshot feature?]]>
      </doc>
    </method>
    <method name="getDiffs" return="org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.DirectoryDiffList"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshotINode" return="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="toDetailString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDirectorySnapshottableFeature" return="org.apache.hadoop.hdfs.server.namenode.snapshot.DirectorySnapshottableFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isSnapshottable" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshot" return="org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotName" type="byte[]"/>
    </method>
    <method name="setSnapshotQuota"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotQuota" type="int"/>
    </method>
    <method name="addSnapshot" return="org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="int"/>
      <param name="name" type="java.lang.String"/>
      <exception name="SnapshotException" type="org.apache.hadoop.hdfs.protocol.SnapshotException"/>
      <exception name="QuotaExceededException" type="org.apache.hadoop.hdfs.protocol.QuotaExceededException"/>
    </method>
    <method name="removeSnapshot" return="org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <param name="snapshotName" type="java.lang.String"/>
      <exception name="SnapshotException" type="org.apache.hadoop.hdfs.protocol.SnapshotException"/>
    </method>
    <method name="renameSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <param name="oldName" type="java.lang.String"/>
      <param name="newName" type="java.lang.String"/>
      <exception name="SnapshotException" type="org.apache.hadoop.hdfs.protocol.SnapshotException"/>
    </method>
    <method name="addSnapshottableFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[add DirectorySnapshottableFeature]]>
      </doc>
    </method>
    <method name="removeSnapshottableFeature"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[remove DirectorySnapshottableFeature]]>
      </doc>
    </method>
    <method name="replaceChild"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="oldChild" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="newChild" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="inodeMap" type="org.apache.hadoop.hdfs.server.namenode.INodeMap"/>
      <doc>
      <![CDATA[Replace the given child with a new child. Note that we no longer need to
 replace an normal INodeDirectory or INodeFile into an
 INodeDirectoryWithSnapshot or INodeFileUnderConstruction. The only cases
 for child replacement is for reference nodes.]]>
      </doc>
    </method>
    <method name="recordModification"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latestSnapshotId" type="int"/>
    </method>
    <method name="saveChild2Snapshot" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="child" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="latestSnapshotId" type="int"/>
      <param name="snapshotCopy" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Save the child to the latest snapshot.
 
 @return the child inode, which may be replaced.]]>
      </doc>
    </method>
    <method name="getChild" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="byte[]"/>
      <param name="snapshotId" type="int"/>
      <doc>
      <![CDATA[@param name the name of the child
 @param snapshotId
          if it is not {@link Snapshot#CURRENT_STATE_ID}, get the result
          from the corresponding snapshot; otherwise, get the result from
          the current directory.
 @return the child inode.]]>
      </doc>
    </method>
    <method name="searchChild" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Search for the given INode in the children list and the deleted lists of
 snapshots.
 @return {@link Snapshot#CURRENT_STATE_ID} if the inode is in the children
 list; {@link Snapshot#NO_SNAPSHOT_ID} if the inode is neither in the
 children list nor in any snapshot; otherwise the snapshot id of the
 corresponding snapshot diff list.]]>
      </doc>
    </method>
    <method name="getChildrenList" return="org.apache.hadoop.hdfs.util.ReadOnlyList"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
      <doc>
      <![CDATA[@param snapshotId
          if it is not {@link Snapshot#CURRENT_STATE_ID}, get the result
          from the corresponding snapshot; otherwise, get the result from
          the current directory.
 @return the current children list if the specified snapshot is null;
         otherwise, return the children list corresponding to the snapshot.
         Note that the returned list is never null.]]>
      </doc>
    </method>
    <method name="removeChild" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="child" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="latestSnapshotId" type="int"/>
      <doc>
      <![CDATA[Remove the specified child from this directory.]]>
      </doc>
    </method>
    <method name="removeChild" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="child" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Remove the specified child from this directory.
 The basic remove method which actually calls children.remove(..).

 @param child the child inode to be removed
 
 @return true if the child is removed; false if the child is not found.]]>
      </doc>
    </method>
    <method name="addChild" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="setModTime" type="boolean"/>
      <param name="latestSnapshotId" type="int"/>
      <exception name="QuotaExceededException" type="org.apache.hadoop.hdfs.protocol.QuotaExceededException"/>
      <doc>
      <![CDATA[Add a child inode to the directory.
 
 @param node INode to insert
 @param setModTime set modification time for the parent node
                   not needed when replaying the addition and 
                   the parent already has the proper mod time
 @return false if the child with this name already exists; 
         otherwise, return true;]]>
      </doc>
    </method>
    <method name="addChild" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="node" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
    </method>
    <method name="computeQuotaUsage" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bsps" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"/>
      <param name="blockStoragePolicyId" type="byte"/>
      <param name="useCache" type="boolean"/>
      <param name="lastSnapshotId" type="int"/>
    </method>
    <method name="computeQuotaUsage4CurrentDirectory" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bsps" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"/>
      <param name="storagePolicyId" type="byte"/>
      <param name="counts" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
      <doc>
      <![CDATA[Add quota usage for this inode excluding children.]]>
      </doc>
    </method>
    <method name="computeContentSummary" return="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
      <param name="summary" type="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"/>
    </method>
    <method name="computeDirectoryContentSummary" return="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="summary" type="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"/>
      <param name="snapshotId" type="int"/>
    </method>
    <method name="undoRename4ScrParent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="oldChild" type="org.apache.hadoop.hdfs.server.namenode.INodeReference"/>
      <param name="newChild" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <exception name="QuotaExceededException" type="org.apache.hadoop.hdfs.protocol.QuotaExceededException"/>
      <doc>
      <![CDATA[This method is usually called by the undo section of rename.
 
 Before calling this function, in the rename operation, we replace the
 original src node (of the rename operation) with a reference node (WithName
 instance) in both the children list and a created list, delete the
 reference node from the children list, and add it to the corresponding
 deleted list.
 
 To undo the above operations, we have the following steps in particular:
 
 <pre>
 1) remove the WithName node from the deleted list (if it exists) 
 2) replace the WithName node in the created list with srcChild 
 3) add srcChild back as a child of srcParent. Note that we already add 
 the node into the created list of a snapshot diff in step 2, we do not need
 to add srcChild to the created list of the latest snapshot.
 </pre>
 
 We do not need to update quota usage because the old child is in the 
 deleted list before. 
 
 @param oldChild
          The reference node to be removed/replaced
 @param newChild
          The node to be added back
 @throws QuotaExceededException should not throw this exception]]>
      </doc>
    </method>
    <method name="undoRename4DstParent"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bsps" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"/>
      <param name="deletedChild" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="latestSnapshotId" type="int"/>
      <exception name="QuotaExceededException" type="org.apache.hadoop.hdfs.protocol.QuotaExceededException"/>
      <doc>
      <![CDATA[Undo the rename operation for the dst tree, i.e., if the rename operation
 (with OVERWRITE option) removes a file/dir from the dst tree, add it back
 and delete possible record in the deleted list.]]>
      </doc>
    </method>
    <method name="clearChildren"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Set the children list to null.]]>
      </doc>
    </method>
    <method name="clear"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="cleanSubtreeRecursively"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <param name="snapshot" type="int"/>
      <param name="prior" type="int"/>
      <param name="excludedNodes" type="java.util.Map"/>
      <doc>
      <![CDATA[Call cleanSubtree(..) recursively down the subtree.]]>
      </doc>
    </method>
    <method name="destroyAndCollectBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
    </method>
    <method name="cleanSubtree"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <param name="snapshotId" type="int"/>
      <param name="priorSnapshotId" type="int"/>
    </method>
    <method name="metadataEquals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="other" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes"/>
      <doc>
      <![CDATA[Compare the metadata with another INodeDirectory]]>
      </doc>
    </method>
    <method name="dumpTreeRecursively"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.PrintWriter"/>
      <param name="prefix" type="java.lang.StringBuilder"/>
      <param name="snapshot" type="int"/>
    </method>
    <method name="dumpTreeRecursively"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.PrintWriter"/>
      <param name="prefix" type="java.lang.StringBuilder"/>
      <param name="subs" type="java.lang.Iterable"/>
      <doc>
      <![CDATA[Dump the given subtrees.
 @param prefix The prefix string that each line should print.
 @param subs The subtrees.]]>
      </doc>
    </method>
    <method name="getChildrenNum" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <field name="DEFAULT_FILES_PER_DIRECTORY" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Directory INode class.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeDirectory -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeDirectory.SnapshotAndINode -->
  <class name="INodeDirectory.SnapshotAndINode" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotAndINode" type="int, org.apache.hadoop.hdfs.server.namenode.INode"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <field name="snapshotId" type="int"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="inode" type="org.apache.hadoop.hdfs.server.namenode.INode"
      transient="false" volatile="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A pair of Snapshot and INode objects.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeDirectory.SnapshotAndINode -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes.CopyWithQuota -->
  <class name="INodeDirectoryAttributes.CopyWithQuota" extends="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes.SnapshotCopy"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CopyWithQuota" type="byte[], org.apache.hadoop.fs.permission.PermissionStatus, org.apache.hadoop.hdfs.server.namenode.AclFeature, long, long, long, org.apache.hadoop.hdfs.util.EnumCounters, org.apache.hadoop.hdfs.server.namenode.XAttrFeature"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="CopyWithQuota" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getQuotaCounts" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes.CopyWithQuota -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes.SnapshotCopy -->
  <class name="INodeDirectoryAttributes.SnapshotCopy" extends="org.apache.hadoop.hdfs.server.namenode.INodeAttributes.SnapshotCopy"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes"/>
    <constructor name="SnapshotCopy" type="byte[], org.apache.hadoop.fs.permission.PermissionStatus, org.apache.hadoop.hdfs.server.namenode.AclFeature, long, org.apache.hadoop.hdfs.server.namenode.XAttrFeature"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotCopy" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getQuotaCounts" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isDirectory" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="metadataEquals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="other" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes"/>
    </method>
    <doc>
    <![CDATA[A copy of the inode directory attributes]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeDirectoryAttributes.SnapshotCopy -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes.SnapshotCopy -->
  <class name="INodeFileAttributes.SnapshotCopy" extends="org.apache.hadoop.hdfs.server.namenode.INodeAttributes.SnapshotCopy"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes"/>
    <constructor name="SnapshotCopy" type="byte[], org.apache.hadoop.fs.permission.PermissionStatus, org.apache.hadoop.hdfs.server.namenode.AclFeature, long, long, short, long, byte, org.apache.hadoop.hdfs.server.namenode.XAttrFeature, boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="SnapshotCopy" type="org.apache.hadoop.hdfs.server.namenode.INodeFile"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="isDirectory" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFileReplication" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isStriped" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getErasureCodingPolicyID" return="byte"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPreferredBlockSize" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getLocalStoragePolicyID" return="byte"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getHeaderLong" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="metadataEquals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="other" type="org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes"/>
    </method>
    <doc>
    <![CDATA[A copy of the inode file attributes]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes.SnapshotCopy -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeMap -->
  <class name="INodeMap" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getMapIterator" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="put"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Add an {@link INode} into the {@link INode} map. Replace the old value if 
 necessary. 
 @param inode The {@link INode} to be added to the map.]]>
      </doc>
    </method>
    <method name="remove"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Remove a {@link INode} from the map.
 @param inode The {@link INode} to be removed.]]>
      </doc>
    </method>
    <method name="size" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return The size of the map.]]>
      </doc>
    </method>
    <method name="get" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="long"/>
      <doc>
      <![CDATA[Get the {@link INode} with the given id from the map.
 @param id ID of the {@link INode}.
 @return The {@link INode} in the map with the given id. Return null if no 
         such {@link INode} in the map.]]>
      </doc>
    </method>
    <method name="clear"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Clear the {@link #map}]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Storing all the {@link INode}s and maintaining the mapping between INode ID
 and INode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeMap -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeReference -->
  <class name="INodeReference" extends="org.apache.hadoop.hdfs.server.namenode.INode"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="INodeReference" type="org.apache.hadoop.hdfs.server.namenode.INode, org.apache.hadoop.hdfs.server.namenode.INode"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="tryRemoveReference" return="int"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Try to remove the given reference and then return the reference count.
 If the given inode is not a reference, return -1;]]>
      </doc>
    </method>
    <method name="getReferredINode" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setReferredINode"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="referred" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
    </method>
    <method name="isReference" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="asReference" return="org.apache.hadoop.hdfs.server.namenode.INodeReference"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isFile" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="asFile" return="org.apache.hadoop.hdfs.server.namenode.INodeFile"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isDirectory" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="asDirectory" return="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isSymlink" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="asSymlink" return="org.apache.hadoop.hdfs.server.namenode.INodeSymlink"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getLocalNameBytes" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setLocalName"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="byte[]"/>
    </method>
    <method name="getId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPermissionStatus" return="org.apache.hadoop.fs.permission.PermissionStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="getUserName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="getGroupName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="getFsPermission" return="org.apache.hadoop.fs.permission.FsPermission"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="getFsPermissionShort" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPermissionLong" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getModificationTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="updateModificationTime" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="mtime" type="long"/>
      <param name="latestSnapshotId" type="int"/>
    </method>
    <method name="setModificationTime"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="modificationTime" type="long"/>
    </method>
    <method name="getAccessTime" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="setAccessTime"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="accessTime" type="long"/>
    </method>
    <method name="getStoragePolicyID" return="byte"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getLocalStoragePolicyID" return="byte"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="cleanSubtree"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <param name="snapshot" type="int"/>
      <param name="prior" type="int"/>
    </method>
    <method name="destroyAndCollectBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
    </method>
    <method name="computeContentSummary" return="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
      <param name="summary" type="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"/>
    </method>
    <method name="computeQuotaUsage" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bsps" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"/>
      <param name="blockStoragePolicyId" type="byte"/>
      <param name="useCache" type="boolean"/>
      <param name="lastSnapshotId" type="int"/>
    </method>
    <method name="getSnapshotINode" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="getQuotaCounts" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="clear"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="dumpTreeRecursively"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.PrintWriter"/>
      <param name="prefix" type="java.lang.StringBuilder"/>
      <param name="snapshot" type="int"/>
    </method>
    <method name="getDstSnapshotId" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[An anonymous reference to an inode.

 This class and its subclasses are used to support multiple access paths.
 A file/directory may have multiple access paths when it is stored in some
 snapshots and it is renamed/moved to other locations.
 
 For example,
 (1) Suppose we have /abc/foo, say the inode of foo is inode(id=1000,name=foo)
 (2) create snapshot s0 for /abc
 (3) mv /abc/foo /xyz/bar, i.e. inode(id=1000,name=...) is renamed from "foo"
     to "bar" and its parent becomes /xyz.
 
 Then, /xyz/bar and /abc/.snapshot/s0/foo are two different access paths to
 the same inode, inode(id=1000,name=bar).

 With references, we have the following
 - /abc has a child ref(id=1001,name=foo).
 - /xyz has a child ref(id=1002) 
 - Both ref(id=1001,name=foo) and ref(id=1002) point to another reference,
   ref(id=1003,count=2).
 - Finally, ref(id=1003,count=2) points to inode(id=1000,name=bar).
 
 Note 1: For a reference without name, e.g. ref(id=1002), it uses the name
         of the referred inode.
 Note 2: getParent() always returns the parent in the current state, e.g.
         inode(id=1000,name=bar).getParent() returns /xyz but not /abc.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeReference -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeReference.DstReference -->
  <class name="INodeReference.DstReference" extends="org.apache.hadoop.hdfs.server.namenode.INodeReference"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DstReference" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory, org.apache.hadoop.hdfs.server.namenode.INodeReference.WithCount, int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getDstSnapshotId" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="cleanSubtree"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <param name="snapshot" type="int"/>
      <param name="prior" type="int"/>
    </method>
    <method name="destroyAndCollectBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <doc>
      <![CDATA[{@inheritDoc}
 <br/>
 To destroy a DstReference node, we first remove its link with the 
 referred node. If the reference number of the referred node is <= 0, we 
 destroy the subtree of the referred node. Otherwise, we clean the 
 referred node's subtree and delete everything created after the last 
 rename operation, i.e., everything outside of the scope of the prior 
 WithName nodes.
 @param reclaimContext]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeReference.DstReference -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeReference.WithCount -->
  <class name="INodeReference.WithCount" extends="org.apache.hadoop.hdfs.server.namenode.INodeReference"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="WithCount" type="org.apache.hadoop.hdfs.server.namenode.INodeReference, org.apache.hadoop.hdfs.server.namenode.INode"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getReferenceCount" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="addReference"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ref" type="org.apache.hadoop.hdfs.server.namenode.INodeReference"/>
      <doc>
      <![CDATA[Increment and then return the reference count.]]>
      </doc>
    </method>
    <method name="removeReference"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ref" type="org.apache.hadoop.hdfs.server.namenode.INodeReference"/>
      <doc>
      <![CDATA[Decrement and then return the reference count.]]>
      </doc>
    </method>
    <method name="getLastWithName" return="org.apache.hadoop.hdfs.server.namenode.INodeReference.WithName"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the last WithName reference if there is any, null otherwise.]]>
      </doc>
    </method>
    <method name="getParentRef" return="org.apache.hadoop.hdfs.server.namenode.INodeReference"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
      <doc>
      <![CDATA[@return the WithName/DstReference node contained in the given snapshot.]]>
      </doc>
    </method>
    <field name="WITHNAME_COMPARATOR" type="java.util.Comparator"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Compare snapshot with IDs, where null indicates the current status thus
 is greater than any non-null snapshot.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[An anonymous reference with reference count.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeReference.WithCount -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeReference.WithName -->
  <class name="INodeReference.WithName" extends="org.apache.hadoop.hdfs.server.namenode.INodeReference"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="WithName" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory, org.apache.hadoop.hdfs.server.namenode.INodeReference.WithCount, byte[], int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getLocalNameBytes" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setLocalName"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="byte[]"/>
    </method>
    <method name="getLastSnapshotId" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="computeContentSummary" return="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
      <param name="summary" type="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"/>
    </method>
    <method name="computeQuotaUsage" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="bsps" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite"/>
      <param name="blockStoragePolicyId" type="byte"/>
      <param name="useCache" type="boolean"/>
      <param name="lastSnapshotId" type="int"/>
    </method>
    <method name="cleanSubtree"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <param name="snapshot" type="int"/>
      <param name="prior" type="int"/>
    </method>
    <method name="destroyAndCollectBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
    </method>
    <doc>
    <![CDATA[A reference with a fixed name.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeReference.WithName -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodesInPath -->
  <class name="INodesInPath" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="replace" return="org.apache.hadoop.hdfs.server.namenode.INodesInPath"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="iip" type="org.apache.hadoop.hdfs.server.namenode.INodesInPath"/>
      <param name="pos" type="int"/>
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Replace an inode of the given INodesInPath in the given position. We do a
 deep copy of the INode array.
 @param pos the position of the replacement
 @param inode the new inode
 @return a new INodesInPath instance]]>
      </doc>
    </method>
    <method name="append" return="org.apache.hadoop.hdfs.server.namenode.INodesInPath"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="iip" type="org.apache.hadoop.hdfs.server.namenode.INodesInPath"/>
      <param name="child" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="childName" type="byte[]"/>
      <doc>
      <![CDATA[Extend a given INodesInPath with a child INode. The child INode will be
 appended to the end of the new INodesInPath.]]>
      </doc>
    </method>
    <method name="getLatestSnapshotId" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[For non-snapshot paths, return the latest snapshot id found in the path.]]>
      </doc>
    </method>
    <method name="getPathSnapshotId" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[For snapshot paths, return the id of the snapshot specified in the path.
 For non-snapshot paths, return {@link Snapshot#CURRENT_STATE_ID}.]]>
      </doc>
    </method>
    <method name="getINode" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="i" type="int"/>
      <doc>
      <![CDATA[@return the i-th inode if i >= 0;
         otherwise, i < 0, return the (length + i)-th inode.]]>
      </doc>
    </method>
    <method name="getLastINode" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the last inode.]]>
      </doc>
    </method>
    <method name="getPathComponents" return="byte[][]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPathComponent" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="i" type="int"/>
    </method>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the full path in string form]]>
      </doc>
    </method>
    <method name="getParentPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getPath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="pos" type="int"/>
    </method>
    <method name="length" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getReadOnlyINodes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getINodesArray" return="org.apache.hadoop.hdfs.server.namenode.INode[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getParentINodesInPath" return="org.apache.hadoop.hdfs.server.namenode.INodesInPath"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return an INodesInPath instance containing all the INodes in the parent
         path. We do a deep copy here.]]>
      </doc>
    </method>
    <method name="getExistingINodes" return="org.apache.hadoop.hdfs.server.namenode.INodesInPath"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return a new INodesInPath instance that only contains existing INodes.
 Note that this method only handles non-snapshot paths.]]>
      </doc>
    </method>
    <method name="isRaw" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return if this is a /.reserved/raw path.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Contains INodes information resolved from a given path.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodesInPath -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.JournalManager.CorruptionException -->
  <class name="JournalManager.CorruptionException" extends="java.io.IOException"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="CorruptionException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Indicate that a journal is cannot be used to load a certain range of 
 edits.
 This exception occurs in the case of a gap in the transactions, or a
 corrupt edit file.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.JournalManager.CorruptionException -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext.RequestStopException -->
  <class name="MetaRecoveryContext.RequestStopException" extends="java.io.IOException"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="RequestStopException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Exception thrown when the user has requested processing to stop.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext.RequestStopException -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.NameNode.NameNodeHAContext -->
  <class name="NameNode.NameNodeHAContext" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="protected"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.ha.HAContext"/>
    <constructor name="NameNodeHAContext"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <method name="setState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.server.namenode.ha.HAState"/>
    </method>
    <method name="getState" return="org.apache.hadoop.hdfs.server.namenode.ha.HAState"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="startActiveServices"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="stopActiveServices"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="startStandbyServices"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="prepareToStopStandbyServices"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="ServiceFailedException" type="org.apache.hadoop.ha.ServiceFailedException"/>
    </method>
    <method name="stopStandbyServices"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="writeLock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="writeUnlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="checkOperation"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="op" type="org.apache.hadoop.hdfs.server.namenode.NameNode.OperationCategory"/>
      <exception name="StandbyException" type="org.apache.hadoop.ipc.StandbyException"/>
      <doc>
      <![CDATA[Check if an operation of given category is allowed]]>
      </doc>
    </method>
    <method name="allowStaleReads" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Class used to expose {@link NameNode} as context to {@link HAState}]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.NameNode.NameNodeHAContext -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.NameNode.OperationCategory -->
  <class name="NameNode.OperationCategory" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.NameNode.OperationCategory[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.NameNode.OperationCategory"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Categories of operations supported by the namenode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.NameNode.OperationCategory -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.NameNodeLayoutVersion.Feature -->
  <class name="NameNodeLayoutVersion.Feature" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.protocol.LayoutVersion.LayoutFeature"/>
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.NameNodeLayoutVersion.Feature[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.NameNodeLayoutVersion.Feature"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getInfo" return="org.apache.hadoop.hdfs.protocol.LayoutVersion.FeatureInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Enums for features that change the layout version.
 <br><br>
 To add a new layout version:
 <ul>
 <li>Define a new enum constant with a short enum name, the new layout version 
 and description of the added feature.</li>
 <li>When adding a layout version with an ancestor that is not same as
 its immediate predecessor, use the constructor where a specific ancestor
 can be passed.
 </li>
 <li>Specify a minimum compatible layout version.  The minimum compatible
 layout version is the earliest prior version to which a downgrade is
 possible after initiating rolling upgrade.  If the feature cannot satisfy
 compatibility with any prior version, then set its minimum compatible
 lqyout version to itself to indicate that downgrade is impossible.
 Satisfying compatibility might require adding logic to the new feature to
 reject operations or handle them differently while rolling upgrade is in
 progress.  In general, it's possible to satisfy compatiblity for downgrade
 if the new feature just involves adding new edit log ops.  Deeper
 structural changes, such as changing the way we place files in the metadata
 directories, might be incompatible.  Feature implementations should strive
 for compatibility, because it's in the best interest of our users to
 support downgrade.
 </ul>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.NameNodeLayoutVersion.Feature -->
  <!-- start interface org.apache.hadoop.hdfs.server.namenode.NameNodeMXBean -->
  <interface name="NameNodeMXBean"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getVersion" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the version of Hadoop.
 
 @return the version]]>
      </doc>
    </method>
    <method name="getSoftwareVersion" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the version of software running on the Namenode
 @return a string representing the version]]>
      </doc>
    </method>
    <method name="getUsed" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the used space by data nodes.
 
 @return the used space by data nodes]]>
      </doc>
    </method>
    <method name="getFree" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets total non-used raw bytes.
 
 @return total non-used raw bytes]]>
      </doc>
    </method>
    <method name="getTotal" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets total raw bytes including non-dfs used space.
 
 @return the total raw bytes including non-dfs used space]]>
      </doc>
    </method>
    <method name="getSafemode" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the safemode status
 
 @return the safemode status]]>
      </doc>
    </method>
    <method name="isUpgradeFinalized" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Checks if upgrade is finalized.
 
 @return true, if upgrade is finalized]]>
      </doc>
    </method>
    <method name="getRollingUpgradeStatus" return="org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo.Bean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the RollingUpgrade information.

 @return Rolling upgrade information if an upgrade is in progress. Else
 (e.g. if there is no upgrade or the upgrade is finalized), returns null.]]>
      </doc>
    </method>
    <method name="getNonDfsUsedSpace" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets total used space by data nodes for non DFS purposes such as storing
 temporary files on the local file system
 
 @return the non dfs space of the cluster]]>
      </doc>
    </method>
    <method name="getPercentUsed" return="float"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the total used space by data nodes as percentage of total capacity
 
 @return the percentage of used space on the cluster.]]>
      </doc>
    </method>
    <method name="getPercentRemaining" return="float"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the total remaining space by data nodes as percentage of total 
 capacity
 
 @return the percentage of the remaining space on the cluster]]>
      </doc>
    </method>
    <method name="getCacheUsed" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the amount of cache used by the datanode (in bytes).]]>
      </doc>
    </method>
    <method name="getCacheCapacity" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the total cache capacity of the datanode (in bytes).]]>
      </doc>
    </method>
    <method name="getBlockPoolUsedSpace" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the total space used by the block pools of this namenode]]>
      </doc>
    </method>
    <method name="getPercentBlockPoolUsed" return="float"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the total space used by the block pool as percentage of total capacity]]>
      </doc>
    </method>
    <method name="getTotalBlocks" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the total numbers of blocks on the cluster.
 
 @return the total number of blocks of the cluster]]>
      </doc>
    </method>
    <method name="getNumberOfMissingBlocks" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the total number of missing blocks on the cluster
 
 @return the total number of missing blocks on the cluster]]>
      </doc>
    </method>
    <method name="getNumberOfMissingBlocksWithReplicationFactorOne" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the total number of missing blocks on the cluster with
 replication factor 1

 @return the total number of missing blocks on the cluster with
 replication factor 1]]>
      </doc>
    </method>
    <method name="getNumberOfSnapshottableDirs" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the total number of snapshottable dirs in the system.

 @return the total number of snapshottable dirs in the system]]>
      </doc>
    </method>
    <method name="getThreads" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the number of threads.
 
 @return the number of threads]]>
      </doc>
    </method>
    <method name="getLiveNodes" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the live node information of the cluster.
 
 @return the live node information]]>
      </doc>
    </method>
    <method name="getDeadNodes" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the dead node information of the cluster.
 
 @return the dead node information]]>
      </doc>
    </method>
    <method name="getDecomNodes" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the decommissioning node information of the cluster.
 
 @return the decommissioning node information]]>
      </doc>
    </method>
    <method name="getClusterId" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the cluster id.
 
 @return the cluster id]]>
      </doc>
    </method>
    <method name="getBlockPoolId" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the block pool id.
 
 @return the block pool id]]>
      </doc>
    </method>
    <method name="getNameDirStatuses" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get status information about the directories storing image and edits logs
 of the NN.
 
 @return the name dir status information, as a JSON string.]]>
      </doc>
    </method>
    <method name="getNodeUsage" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get Max, Median, Min and Standard Deviation of DataNodes usage.

 @return the DataNode usage information, as a JSON string.]]>
      </doc>
    </method>
    <method name="getNameJournalStatus" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get status information about the journals of the NN.

 @return the name journal status information, as a JSON string.]]>
      </doc>
    </method>
    <method name="getJournalTransactionInfo" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get information about the transaction ID, including the last applied 
 transaction ID and the most recent checkpoint's transaction ID]]>
      </doc>
    </method>
    <method name="getNNStartedTimeInMillis" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the NN start time in milliseconds.
 @return the NN start time in msec]]>
      </doc>
    </method>
    <method name="getCompileInfo" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the compilation information which contains date, user and branch

 @return the compilation information, as a JSON string.]]>
      </doc>
    </method>
    <method name="getCorruptFiles" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the list of corrupt files

 @return the list of corrupt files, as a JSON string.]]>
      </doc>
    </method>
    <method name="getDistinctVersionCount" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the number of distinct versions of live datanodes
 
 @return the number of distinct versions of live datanodes]]>
      </doc>
    </method>
    <method name="getDistinctVersions" return="java.util.Map"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the number of live datanodes for each distinct versions
 
 @return the number of live datanodes for each distinct versions]]>
      </doc>
    </method>
    <method name="getNameDirSize" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get namenode directory size.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This is the JMX management interface for namenode information]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.namenode.NameNodeMXBean -->
  <!-- start interface org.apache.hadoop.hdfs.server.namenode.NameNodeStatusMXBean -->
  <interface name="NameNodeStatusMXBean"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getNNRole" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the NameNode role.

 @return the NameNode role.]]>
      </doc>
    </method>
    <method name="getState" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the NameNode state.

 @return the NameNode state.]]>
      </doc>
    </method>
    <method name="getHostAndPort" return="java.lang.String"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the host and port colon separated.

 @return host and port colon separated.]]>
      </doc>
    </method>
    <method name="isSecurityEnabled" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets if security is enabled.

 @return true, if security is enabled.]]>
      </doc>
    </method>
    <method name="getLastHATransitionTime" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets the most recent HA transition time in milliseconds from the epoch.

 @return the most recent HA transition time in milliseconds from the epoch.]]>
      </doc>
    </method>
    <method name="getBytesWithFutureGenerationStamps" return="long"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Gets number of bytes in blocks with future generation stamps.
 @return number of bytes that can be deleted if exited from safe mode.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This is the JMX management interface for NameNode status information]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.namenode.NameNodeStatusMXBean -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeDirType -->
  <class name="NNStorage.NameNodeDirType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.common.Storage.StorageDirType"/>
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeDirType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeDirType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getStorageDirType" return="org.apache.hadoop.hdfs.server.common.Storage.StorageDirType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isOfType" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.server.common.Storage.StorageDirType"/>
    </method>
    <doc>
    <![CDATA[Implementation of StorageDirType specific to namenode storage
 A Storage directory could be of type IMAGE which stores only fsimage,
 or of type EDITS which stores edits or of type IMAGE_AND_EDITS which
 stores both fsimage and edits.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeDirType -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeFile -->
  <class name="NNStorage.NameNodeFile" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeFile[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeFile"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[The filenames used for storing the images.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.NNStorage.NameNodeFile -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager -->
  <class name="NNStorageRetentionManager" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NNStorageRetentionManager" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.namenode.NNStorage, org.apache.hadoop.hdfs.server.namenode.LogsPurgeable, org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager.StoragePurger"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="NNStorageRetentionManager" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.namenode.NNStorage, org.apache.hadoop.hdfs.server.namenode.LogsPurgeable"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[The NNStorageRetentionManager is responsible for inspecting the storage
 directories of the NN and enforcing a retention policy on checkpoints
 and edit logs.
 
 It delegates the actual removal of files to a StoragePurger
 implementation, which might delete the files or instead copy them to
 a filer or HDFS for later analysis.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil -->
  <class name="NNUpgradeUtil" extends="java.lang.Object"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NNUpgradeUtil"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="renameCurToTmp"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sd" type="org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Rename the existing current dir to previous.tmp, and create a new empty
 current dir.]]>
      </doc>
    </method>
    <method name="doUpgrade"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="sd" type="org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory"/>
      <param name="storage" type="org.apache.hadoop.hdfs.server.common.Storage"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Perform the upgrade of the storage dir to the given storage info. The new
 storage info is written into the current directory, and the previous.tmp
 directory is renamed to previous.
 
 @param sd the storage directory to upgrade
 @param storage info about the new upgraded versions.
 @throws IOException in the event of error]]>
      </doc>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.Quota -->
  <class name="Quota" extends="java.lang.Enum"
    abstract="false"
    static="false" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.Quota[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.Quota"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <doc>
    <![CDATA[Quota types.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.Quota -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.Quota.Counts -->
  <class name="Quota.Counts" extends="org.apache.hadoop.hdfs.util.EnumCounters"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="newInstance" return="org.apache.hadoop.hdfs.server.namenode.Quota.Counts"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="namespace" type="long"/>
      <param name="storagespace" type="long"/>
      <doc>
      <![CDATA[@return a new counter with the given namespace and storagespace usages.]]>
      </doc>
    </method>
    <method name="newInstance" return="org.apache.hadoop.hdfs.server.namenode.Quota.Counts"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Counters for quota counts.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.Quota.Counts -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry -->
  <class name="QuotaByStorageTypeEntry" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getStorageType" return="org.apache.hadoop.fs.StorageType"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getQuota" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry.Builder -->
  <class name="QuotaByStorageTypeEntry.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setStorageType" return="org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.fs.StorageType"/>
    </method>
    <method name="setQuota" return="org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="quota" type="long"/>
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.QuotaByStorageTypeEntry.Builder -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.QuotaCounts -->
  <class name="QuotaCounts" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="add" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
    </method>
    <method name="subtract" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
    </method>
    <method name="negation" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a QuotaCounts whose value is {@code (-this)}.

 @return {@code -this}]]>
      </doc>
    </method>
    <method name="getNameSpace" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setNameSpace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nameSpaceCount" type="long"/>
    </method>
    <method name="addNameSpace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="nsDelta" type="long"/>
    </method>
    <method name="getStorageSpace" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setStorageSpace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="spaceCount" type="long"/>
    </method>
    <method name="addStorageSpace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dsDelta" type="long"/>
    </method>
    <method name="getTypeSpaces" return="org.apache.hadoop.hdfs.util.EnumCounters"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="addTypeSpace"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.fs.StorageType"/>
      <param name="delta" type="long"/>
    </method>
    <method name="anyNsSsCountGreaterOrEqual" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <method name="anyTypeSpaceCountGreaterOrEqual" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Counters for namespace, storage space and storage type space quota and usage.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.QuotaCounts -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.QuotaCounts.Builder -->
  <class name="QuotaCounts.Builder" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Builder"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="nameSpace" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <method name="storageSpace" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <method name="typeSpaces" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="org.apache.hadoop.hdfs.util.EnumCounters"/>
    </method>
    <method name="typeSpaces" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <method name="quotaCount" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts.Builder"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"/>
    </method>
    <method name="build" return="org.apache.hadoop.hdfs.server.namenode.QuotaCounts"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.QuotaCounts.Builder -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.StoragePolicySummary -->
  <class name="StoragePolicySummary" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Aggregate the storage type information for a set of blocks]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.StoragePolicySummary -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.TransferFsImage.HttpGetFailedException -->
  <class name="TransferFsImage.HttpGetFailedException" extends="java.io.IOException"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getResponseCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.TransferFsImage.HttpGetFailedException -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.TransferFsImage.HttpPutFailedException -->
  <class name="TransferFsImage.HttpPutFailedException" extends="java.io.IOException"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getResponseCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.TransferFsImage.HttpPutFailedException -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.TransferFsImage.TransferResult -->
  <class name="TransferFsImage.TransferResult" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.namenode.TransferFsImage.TransferResult[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.namenode.TransferFsImage.TransferResult"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getResultForCode" return="org.apache.hadoop.hdfs.server.namenode.TransferFsImage.TransferResult"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="code" type="int"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.TransferFsImage.TransferResult -->
</package>
<package name="org.apache.hadoop.hdfs.server.namenode.ha">
  <!-- start class org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider -->
  <class name="ConfiguredFailoverProxyProvider" extends="org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ConfiguredFailoverProxyProvider" type="org.apache.hadoop.conf.Configuration, java.net.URI, java.lang.Class"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInterface" return="java.lang.Class"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getProxy" return="org.apache.hadoop.io.retry.FailoverProxyProvider.ProxyInfo"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Lazily initialize the RPC proxy object.]]>
      </doc>
    </method>
    <method name="performFailover"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="currentProxy" type="T"/>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Close all the proxy objects which have been opened over the lifetime of
 this proxy provider.]]>
      </doc>
    </method>
    <method name="useLogicalURI" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Logical URI is required for this failover proxy provider.]]>
      </doc>
    </method>
    <field name="conf" type="org.apache.hadoop.conf.Configuration"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="proxies" type="java.util.List"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="xface" type="java.lang.Class"
      transient="false" volatile="false"
      static="false" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A FailoverProxyProvider implementation which allows one to configure two URIs
 to connect to during fail-over. The first configured address is tried first,
 and on a fail-over event the other address is tried.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.ha.IPFailoverProxyProvider -->
  <class name="IPFailoverProxyProvider" extends="org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="IPFailoverProxyProvider" type="org.apache.hadoop.conf.Configuration, java.net.URI, java.lang.Class"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getInterface" return="java.lang.Class"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getProxy" return="org.apache.hadoop.io.retry.FailoverProxyProvider.ProxyInfo"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="performFailover"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="currentProxy" type="T"/>
      <doc>
      <![CDATA[Nothing to do for IP failover]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Close the proxy,]]>
      </doc>
    </method>
    <method name="useLogicalURI" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Logical URI is not used for IP failover.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A NNFailoverProxyProvider implementation which works on IP failover setup.
 Only one proxy is used to connect to both servers and switching between
 the servers is done by the environment/infrastructure, which guarantees
 clients can consistently reach only one node at a time.

 Clients with a live connection will likely get connection reset after an
 IP failover. This case will be handled by the 
 FailoverOnNetworkExceptionRetry retry policy. I.e. if the call is
 not idempotent, it won't get retried.

 A connection reset while setting up a connection (i.e. before sending a
 request) will be handled in ipc client.

 The namenode URI must contain a resolvable host name.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.ha.IPFailoverProxyProvider -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.ha.RemoteNameNodeInfo -->
  <class name="RemoteNameNodeInfo" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getRemoteNameNodes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getRemoteNameNodes" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="nsId" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getIpcAddress" return="java.net.InetSocketAddress"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getNameNodeID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getHttpAddress" return="java.net.URL"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getConfiguration" return="org.apache.hadoop.conf.Configuration"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setIpcAddress"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ipc" type="java.net.InetSocketAddress"/>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Information about a single remote NameNode]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.ha.RemoteNameNodeInfo -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.ha.RequestHedgingProxyProvider -->
  <class name="RequestHedgingProxyProvider" extends="org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="RequestHedgingProxyProvider" type="org.apache.hadoop.conf.Configuration, java.net.URI, java.lang.Class"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getProxy" return="org.apache.hadoop.io.retry.FailoverProxyProvider.ProxyInfo"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="performFailover"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="currentProxy" type="T"/>
    </method>
    <doc>
    <![CDATA[A FailoverProxyProvider implementation that technically does not "failover"
 per-se. It constructs a wrapper proxy that sends the request to ALL
 underlying proxies simultaneously. It assumes the in an HA setup, there will
 be only one Active, and the active should respond faster than any configured
 standbys. Once it recieve a response from any one of the configred proxies,
 outstanding requests to other proxies are immediately cancelled.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.ha.RequestHedgingProxyProvider -->
</package>
<package name="org.apache.hadoop.hdfs.server.namenode.metrics">
  <!-- start class org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics -->
  <class name="NameNodeMetrics" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="totalFileOps" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="create" return="org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <param name="r" type="org.apache.hadoop.hdfs.server.common.HdfsServerConstants.NamenodeRole"/>
    </method>
    <method name="getJvmMetrics" return="org.apache.hadoop.metrics2.source.JvmMetrics"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="shutdown"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrGetBlockLocations"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrFilesCreated"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrCreateFileOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrFilesAppended"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrAddBlockOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrGetAdditionalDatanodeOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrFilesRenamed"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrFilesTruncated"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrFilesDeleted"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="delta" type="long"/>
    </method>
    <method name="incrDeleteFileOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrGetListingOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrFilesInGetListingOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="delta" type="int"/>
    </method>
    <method name="incrFileInfoOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrCreateSymlinkOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrGetLinkTargetOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrAllowSnapshotOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrDisAllowSnapshotOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrCreateSnapshotOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrDeleteSnapshotOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrRenameSnapshotOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrListSnapshottableDirOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrSnapshotDiffReportOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrBlockReceivedAndDeletedOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrStorageBlockReportOps"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setBlockOpsQueued"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="size" type="int"/>
    </method>
    <method name="addBlockOpsBatched"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="count" type="int"/>
    </method>
    <method name="addTransaction"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <method name="incrTransactionsBatchedInSync"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="count" type="long"/>
    </method>
    <method name="addSync"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="elapsed" type="long"/>
    </method>
    <method name="setFsImageLoadTime"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="elapsed" type="long"/>
    </method>
    <method name="addBlockReport"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <method name="addCacheBlockReport"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <method name="setSafeModeTime"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="elapsed" type="long"/>
    </method>
    <method name="addGetEdit"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <method name="addGetImage"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <method name="addPutImage"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <method name="addGenerateEDEKTime"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <method name="addWarmUpEDEKTime"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latency" type="long"/>
    </method>
    <doc>
    <![CDATA[This class is for maintaining  the various NameNode activity statistics
 and publishing them through the metrics interfaces.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics -->
</package>
<package name="org.apache.hadoop.hdfs.server.namenode.snapshot">
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.DirectoryDiff -->
  <class name="DirectoryWithSnapshotFeature.DirectoryDiff" extends="org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getChildrenDiff" return="org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.ChildrenDiff"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[The difference of an {@link INodeDirectory} between two snapshots.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.DirectoryDiff -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.DirectoryDiffList -->
  <class name="DirectoryWithSnapshotFeature.DirectoryDiffList" extends="org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiffList"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DirectoryDiffList"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="replaceChild" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.util.Diff.ListType"/>
      <param name="oldChild" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <param name="newChild" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Replace the given child in the created/deleted list, if there is any.]]>
      </doc>
    </method>
    <method name="removeChild" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.util.Diff.ListType"/>
      <param name="child" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Remove the given child in the created/deleted list, if there is any.]]>
      </doc>
    </method>
    <method name="findSnapshotDeleted" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="child" type="org.apache.hadoop.hdfs.server.namenode.INode"/>
      <doc>
      <![CDATA[Find the corresponding snapshot whose deleted list contains the given
 inode.
 @return the id of the snapshot. {@link Snapshot#NO_SNAPSHOT_ID} if the
 given inode is not in any of the snapshot.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A list of directory diffs.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.DirectoryWithSnapshotFeature.DirectoryDiffList -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.FileDiff -->
  <class name="FileDiff" extends="org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiff"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getFileSize" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the file size in the snapshot.]]>
      </doc>
    </method>
    <method name="setBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blocks" type="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo[]"/>
      <doc>
      <![CDATA[Copy block references into the snapshot
 up to the current {@link #fileSize}.
 Should be done only once.]]>
      </doc>
    </method>
    <method name="getBlocks" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="destroyAndCollectSnapshotBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="collectedBlocks" type="org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo"/>
    </method>
    <doc>
    <![CDATA[The difference of an {@link INodeFile} between two snapshots.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.FileDiff -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.FileDiffList -->
  <class name="FileDiffList" extends="org.apache.hadoop.hdfs.server.namenode.snapshot.AbstractINodeDiffList"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="FileDiffList"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="destroyAndCollectSnapshotBlocks"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="collectedBlocks" type="org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo"/>
    </method>
    <method name="saveSelf2Snapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="latestSnapshotId" type="int"/>
      <param name="iNodeFile" type="org.apache.hadoop.hdfs.server.namenode.INodeFile"/>
      <param name="snapshotCopy" type="org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes"/>
      <param name="withBlocks" type="boolean"/>
    </method>
    <method name="findEarlierSnapshotBlocks" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="findLaterSnapshotBlocks" return="org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <doc>
    <![CDATA[A list of FileDiffs for storing snapshot data.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.FileDiffList -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot.Loader -->
  <class name="FSImageFormatPBSnapshot.Loader" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="Loader" type="org.apache.hadoop.hdfs.server.namenode.FSNamesystem, org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.Loader"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="loadINodeReferenceSection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.InputStream"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[The sequence of the ref node in refList must be strictly the same with
 the sequence in fsimage]]>
      </doc>
    </method>
    <method name="loadSnapshotSection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.InputStream"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Load the snapshots section from fsimage. Also add snapshottable feature
 to snapshottable directories.]]>
      </doc>
    </method>
    <method name="loadSnapshotDiffSection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.InputStream"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Load the snapshot diff section from fsimage.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Loading snapshot related information from protobuf based FSImage]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot.Loader -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot.Saver -->
  <class name="FSImageFormatPBSnapshot.Saver" extends="java.lang.Object"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <constructor name="Saver" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf.Saver, org.apache.hadoop.hdfs.server.namenode.FsImageProto.FileSummary.Builder, org.apache.hadoop.hdfs.server.namenode.SaveNamespaceContext, org.apache.hadoop.hdfs.server.namenode.FSNamesystem"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="serializeSnapshotSection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.OutputStream"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[save all the snapshottable directories and snapshots to fsimage]]>
      </doc>
    </method>
    <method name="serializeINodeReferenceSection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.OutputStream"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[This can only be called after serializing both INode_Dir and SnapshotDiff]]>
      </doc>
    </method>
    <method name="serializeSnapshotDiffSection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.OutputStream"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[save all the snapshot diff to fsimage]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Saving snapshot related information to protobuf based FSImage]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot.Saver -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot.Root -->
  <class name="Snapshot.Root" extends="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getChildrenList" return="org.apache.hadoop.hdfs.util.ReadOnlyList"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
    </method>
    <method name="getChild" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="byte[]"/>
      <param name="snapshotId" type="int"/>
    </method>
    <method name="computeContentSummary" return="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshotId" type="int"/>
      <param name="summary" type="org.apache.hadoop.hdfs.server.namenode.ContentSummaryComputationContext"/>
    </method>
    <method name="getFullPathName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getRootFullPathName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the full path name of the root directory of this snapshot.
 @return full path to the root directory of the snapshot]]>
      </doc>
    </method>
    <doc>
    <![CDATA[The root directory of the snapshot.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot.Root -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotFSImageFormat -->
  <class name="SnapshotFSImageFormat" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="SnapshotFSImageFormat"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="saveSnapshots"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="current" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Save snapshots and snapshot quota for a snapshottable directory.
 @param current The directory that the snapshots belongs to.
 @param out The {@link DataOutput} to write.
 @throws IOException]]>
      </doc>
    </method>
    <method name="saveDirectoryDiffList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
      <param name="out" type="java.io.DataOutput"/>
      <param name="referenceMap" type="org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotFSImageFormat.ReferenceMap"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="saveFileDiffList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="file" type="org.apache.hadoop.hdfs.server.namenode.INodeFile"/>
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="loadFileDiffList" return="org.apache.hadoop.hdfs.server.namenode.snapshot.FileDiffList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <param name="loader" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormat.Loader"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="loadCreated" return="org.apache.hadoop.hdfs.server.namenode.INode"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="createdNodeName" type="byte[]"/>
      <param name="parent" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Load a node stored in the created list from fsimage.
 @param createdNodeName The name of the created node.
 @param parent The directory that the created list belongs to.
 @return The created node.]]>
      </doc>
    </method>
    <method name="loadSnapshotList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="snapshottableParent" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
      <param name="numSnapshots" type="int"/>
      <param name="in" type="java.io.DataInput"/>
      <param name="loader" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormat.Loader"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Load snapshots and snapshotQuota for a Snapshottable directory.

 @param snapshottableParent
          The snapshottable directory for loading.
 @param numSnapshots
          The number of snapshots that the directory has.
 @param loader
          The loader]]>
      </doc>
    </method>
    <method name="loadDirectoryDiffList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
      <param name="in" type="java.io.DataInput"/>
      <param name="loader" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormat.Loader"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Load the {@link SnapshotDiff} list for the INodeDirectoryWithSnapshot
 directory.

 @param dir
          The snapshottable directory for loading.
 @param in
          The {@link DataInput} instance to read.
 @param loader
          The loader]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A helper class defining static methods for reading/writing snapshot related
 information from/to FSImage.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotFSImageFormat -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotFSImageFormat.ReferenceMap -->
  <class name="SnapshotFSImageFormat.ReferenceMap" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReferenceMap"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="writeINodeReferenceWithCount"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="withCount" type="org.apache.hadoop.hdfs.server.namenode.INodeReference.WithCount"/>
      <param name="out" type="java.io.DataOutput"/>
      <param name="writeUnderConstruction" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="toProcessSubtree" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="id" type="long"/>
    </method>
    <method name="loadINodeReferenceWithCount" return="org.apache.hadoop.hdfs.server.namenode.INodeReference.WithCount"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="isSnapshotINode" type="boolean"/>
      <param name="in" type="java.io.DataInput"/>
      <param name="loader" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormat.Loader"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[A reference map for fsimage serialization.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotFSImageFormat.ReferenceMap -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager -->
  <class name="SnapshotManager" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotStatsMXBean"/>
    <constructor name="SnapshotManager" type="org.apache.hadoop.hdfs.server.namenode.FSDirectory"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setSnapshottable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <param name="checkNestedSnapshottable" type="boolean"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the given directory as a snapshottable directory.
 If the path is already a snapshottable directory, update the quota.]]>
      </doc>
    </method>
    <method name="addSnapshottable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dir" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
      <doc>
      <![CDATA[Add the given snapshottable directory to {@link #snapshottables}.]]>
      </doc>
    </method>
    <method name="removeSnapshottable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="toRemove" type="java.util.List"/>
      <doc>
      <![CDATA[Remove snapshottable directories from {@link #snapshottables}]]>
      </doc>
    </method>
    <method name="resetSnapshottable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="path" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Set the given snapshottable directory to non-snapshottable.
 
 @throws SnapshotException if there are snapshots in the directory.]]>
      </doc>
    </method>
    <method name="getSnapshottableRoot" return="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="iip" type="org.apache.hadoop.hdfs.server.namenode.INodesInPath"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Find the source root directory where the snapshot will be taken
 for a given path.

 @return Snapshottable directory.
 @throws IOException
           Throw IOException when the given path does not lead to an
           existing snapshottable directory.]]>
      </doc>
    </method>
    <method name="createSnapshot" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="iip" type="org.apache.hadoop.hdfs.server.namenode.INodesInPath"/>
      <param name="snapshotRoot" type="java.lang.String"/>
      <param name="snapshotName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Create a snapshot of the given path.
 It is assumed that the caller will perform synchronization.

 @param iip the INodes resolved from the snapshottable directory's path
 @param snapshotName
          The name of the snapshot.
 @throws IOException
           Throw IOException when 1) the given path does not lead to an
           existing snapshottable directory, and/or 2) there exists a
           snapshot with the given name for the directory, and/or 3)
           snapshot number exceeds quota]]>
      </doc>
    </method>
    <method name="deleteSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="iip" type="org.apache.hadoop.hdfs.server.namenode.INodesInPath"/>
      <param name="snapshotName" type="java.lang.String"/>
      <param name="reclaimContext" type="org.apache.hadoop.hdfs.server.namenode.INode.ReclaimContext"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Delete a snapshot for a snapshottable directory
 @param snapshotName Name of the snapshot to be deleted
 @param reclaimContext Used to collect information to reclaim blocks
                       and inodes]]>
      </doc>
    </method>
    <method name="renameSnapshot"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="iip" type="org.apache.hadoop.hdfs.server.namenode.INodesInPath"/>
      <param name="snapshotRoot" type="java.lang.String"/>
      <param name="oldSnapshotName" type="java.lang.String"/>
      <param name="newSnapshotName" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Rename the given snapshot
 @param oldSnapshotName
          Old name of the snapshot
 @param newSnapshotName
          New name of the snapshot
 @throws IOException
           Throw IOException when 1) the given path does not lead to an
           existing snapshottable directory, and/or 2) the snapshot with the
           old name does not exist for the directory, and/or 3) there exists
           a snapshot with the new name for the directory]]>
      </doc>
    </method>
    <method name="getNumSnapshottableDirs" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getNumSnapshots" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.DataOutput"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Write {@link #snapshotCounter}, {@link #numSnapshots},
 and all snapshots to the DataOutput.]]>
      </doc>
    </method>
    <method name="read" return="java.util.Map"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="in" type="java.io.DataInput"/>
      <param name="loader" type="org.apache.hadoop.hdfs.server.namenode.FSImageFormat.Loader"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read values of {@link #snapshotCounter}, {@link #numSnapshots}, and
 all snapshots from the DataInput]]>
      </doc>
    </method>
    <method name="getSnapshottableDirListing" return="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="userName" type="java.lang.String"/>
      <doc>
      <![CDATA[List all the snapshottable directories that are owned by the current user.
 @param userName Current user name.
 @return Snapshottable directories that are owned by the current user,
         represented as an array of {@link SnapshottableDirectoryStatus}. If
         {@code userName} is null, return all the snapshottable dirs.]]>
      </doc>
    </method>
    <method name="diff" return="org.apache.hadoop.hdfs.protocol.SnapshotDiffReport"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="iip" type="org.apache.hadoop.hdfs.server.namenode.INodesInPath"/>
      <param name="snapshotRootPath" type="java.lang.String"/>
      <param name="from" type="java.lang.String"/>
      <param name="to" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Compute the difference between two snapshots of a directory, or between a
 snapshot of the directory and its current tree.]]>
      </doc>
    </method>
    <method name="clearSnapshottableDirs"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getMaxSnapshotID" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the maximum allowable snapshot ID based on the bit width of the
 snapshot ID.

 @return maximum allowable snapshot ID.]]>
      </doc>
    </method>
    <method name="registerMXBean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="shutdown"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshottableDirectories" return="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.Bean[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getSnapshots" return="org.apache.hadoop.hdfs.protocol.SnapshotInfo.Bean[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toBean" return="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.Bean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="d" type="org.apache.hadoop.hdfs.server.namenode.INodeDirectory"/>
    </method>
    <method name="toBean" return="org.apache.hadoop.hdfs.protocol.SnapshotInfo.Bean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="s" type="org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot"/>
    </method>
    <doc>
    <![CDATA[Manage snapshottable directories and their snapshots.
 
 This class includes operations that create, access, modify snapshots and/or
 snapshot-related data. In general, the locking structure of snapshot
 operations is: <br>
 
 1. Lock the {@link FSNamesystem} lock in {@link FSNamesystem} before calling
 into {@link SnapshotManager} methods.<br>
 2. Lock the {@link FSDirectory} lock for the {@link SnapshotManager} methods
 if necessary.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager -->
  <!-- start interface org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotStatsMXBean -->
  <interface name="SnapshotStatsMXBean"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getSnapshottableDirectories" return="org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.Bean[]"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the list of snapshottable directories

 @return the list of snapshottable directories]]>
      </doc>
    </method>
    <method name="getSnapshots" return="org.apache.hadoop.hdfs.protocol.SnapshotInfo.Bean[]"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the list of snapshots

 @return the list of snapshots]]>
      </doc>
    </method>
    <doc>
    <![CDATA[This is an interface used to retrieve statistic information related to
 snapshots]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotStatsMXBean -->
</package>
<package name="org.apache.hadoop.hdfs.server.namenode.top">
</package>
<package name="org.apache.hadoop.hdfs.server.namenode.top.metrics">
</package>
<package name="org.apache.hadoop.hdfs.server.namenode.top.window">
  <!-- start class org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.Op -->
  <class name="RollingWindowManager.Op" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Op" type="java.lang.String, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="addUser"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="u" type="org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.User"/>
    </method>
    <method name="getOpType" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTopUsers" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getTotalCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Represents an operation within a TopWindow. It contains a ranked 
 set of the top users for the operation.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.Op -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.TopWindow -->
  <class name="RollingWindowManager.TopWindow" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="TopWindow" type="int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="addOp"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="op" type="org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.Op"/>
    </method>
    <method name="getWindowLenMs" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getOps" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Represents a snapshot of the rolling window. It contains one Op per 
 operation in the window, with ranked users for each Op.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.TopWindow -->
  <!-- start class org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.User -->
  <class name="RollingWindowManager.User" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="User" type="java.lang.String, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getUser" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCount" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Represents a user who called an Op within a TopWindow. Specifies the 
 user and the number of times the user called the operation.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.User -->
</package>
<package name="org.apache.hadoop.hdfs.server.namenode.web.resources">
  <!-- start class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods -->
  <class name="NamenodeWebHdfsMethods" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NamenodeWebHdfsMethods"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getRemoteAddress" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the remote client address.]]>
      </doc>
    </method>
    <method name="getRemoteIp" return="java.net.InetAddress"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isWebHdfsInvocation" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns true if a WebHdfs request is in progress.  Akin to
 {@link Server#isRpcInvocation()}.]]>
      </doc>
    </method>
    <method name="putRoot" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.PutOpParam"/>
      <param name="destination" type="org.apache.hadoop.hdfs.web.resources.DestinationParam"/>
      <param name="owner" type="org.apache.hadoop.hdfs.web.resources.OwnerParam"/>
      <param name="group" type="org.apache.hadoop.hdfs.web.resources.GroupParam"/>
      <param name="permission" type="org.apache.hadoop.hdfs.web.resources.PermissionParam"/>
      <param name="overwrite" type="org.apache.hadoop.hdfs.web.resources.OverwriteParam"/>
      <param name="bufferSize" type="org.apache.hadoop.hdfs.web.resources.BufferSizeParam"/>
      <param name="replication" type="org.apache.hadoop.hdfs.web.resources.ReplicationParam"/>
      <param name="blockSize" type="org.apache.hadoop.hdfs.web.resources.BlockSizeParam"/>
      <param name="modificationTime" type="org.apache.hadoop.hdfs.web.resources.ModificationTimeParam"/>
      <param name="accessTime" type="org.apache.hadoop.hdfs.web.resources.AccessTimeParam"/>
      <param name="renameOptions" type="org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam"/>
      <param name="createParent" type="org.apache.hadoop.hdfs.web.resources.CreateParentParam"/>
      <param name="delegationTokenArgument" type="org.apache.hadoop.hdfs.web.resources.TokenArgumentParam"/>
      <param name="aclPermission" type="org.apache.hadoop.hdfs.web.resources.AclPermissionParam"/>
      <param name="xattrName" type="org.apache.hadoop.hdfs.web.resources.XAttrNameParam"/>
      <param name="xattrValue" type="org.apache.hadoop.hdfs.web.resources.XAttrValueParam"/>
      <param name="xattrSetFlag" type="org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam"/>
      <param name="snapshotName" type="org.apache.hadoop.hdfs.web.resources.SnapshotNameParam"/>
      <param name="oldSnapshotName" type="org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam"/>
      <param name="excludeDatanodes" type="org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam"/>
      <param name="createFlagParam" type="org.apache.hadoop.hdfs.web.resources.CreateFlagParam"/>
      <param name="noredirect" type="org.apache.hadoop.hdfs.web.resources.NoRedirectParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP PUT request for the root.]]>
      </doc>
    </method>
    <method name="put" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="path" type="org.apache.hadoop.hdfs.web.resources.UriFsPathParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.PutOpParam"/>
      <param name="destination" type="org.apache.hadoop.hdfs.web.resources.DestinationParam"/>
      <param name="owner" type="org.apache.hadoop.hdfs.web.resources.OwnerParam"/>
      <param name="group" type="org.apache.hadoop.hdfs.web.resources.GroupParam"/>
      <param name="permission" type="org.apache.hadoop.hdfs.web.resources.PermissionParam"/>
      <param name="overwrite" type="org.apache.hadoop.hdfs.web.resources.OverwriteParam"/>
      <param name="bufferSize" type="org.apache.hadoop.hdfs.web.resources.BufferSizeParam"/>
      <param name="replication" type="org.apache.hadoop.hdfs.web.resources.ReplicationParam"/>
      <param name="blockSize" type="org.apache.hadoop.hdfs.web.resources.BlockSizeParam"/>
      <param name="modificationTime" type="org.apache.hadoop.hdfs.web.resources.ModificationTimeParam"/>
      <param name="accessTime" type="org.apache.hadoop.hdfs.web.resources.AccessTimeParam"/>
      <param name="renameOptions" type="org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam"/>
      <param name="createParent" type="org.apache.hadoop.hdfs.web.resources.CreateParentParam"/>
      <param name="delegationTokenArgument" type="org.apache.hadoop.hdfs.web.resources.TokenArgumentParam"/>
      <param name="aclPermission" type="org.apache.hadoop.hdfs.web.resources.AclPermissionParam"/>
      <param name="xattrName" type="org.apache.hadoop.hdfs.web.resources.XAttrNameParam"/>
      <param name="xattrValue" type="org.apache.hadoop.hdfs.web.resources.XAttrValueParam"/>
      <param name="xattrSetFlag" type="org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam"/>
      <param name="snapshotName" type="org.apache.hadoop.hdfs.web.resources.SnapshotNameParam"/>
      <param name="oldSnapshotName" type="org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam"/>
      <param name="excludeDatanodes" type="org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam"/>
      <param name="createFlagParam" type="org.apache.hadoop.hdfs.web.resources.CreateFlagParam"/>
      <param name="noredirect" type="org.apache.hadoop.hdfs.web.resources.NoRedirectParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP PUT request.]]>
      </doc>
    </method>
    <method name="postRoot" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.PostOpParam"/>
      <param name="concatSrcs" type="org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam"/>
      <param name="bufferSize" type="org.apache.hadoop.hdfs.web.resources.BufferSizeParam"/>
      <param name="excludeDatanodes" type="org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam"/>
      <param name="newLength" type="org.apache.hadoop.hdfs.web.resources.NewLengthParam"/>
      <param name="noredirect" type="org.apache.hadoop.hdfs.web.resources.NoRedirectParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP POST request for the root.]]>
      </doc>
    </method>
    <method name="post" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="path" type="org.apache.hadoop.hdfs.web.resources.UriFsPathParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.PostOpParam"/>
      <param name="concatSrcs" type="org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam"/>
      <param name="bufferSize" type="org.apache.hadoop.hdfs.web.resources.BufferSizeParam"/>
      <param name="excludeDatanodes" type="org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam"/>
      <param name="newLength" type="org.apache.hadoop.hdfs.web.resources.NewLengthParam"/>
      <param name="noredirect" type="org.apache.hadoop.hdfs.web.resources.NoRedirectParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP POST request.]]>
      </doc>
    </method>
    <method name="getRoot" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.GetOpParam"/>
      <param name="offset" type="org.apache.hadoop.hdfs.web.resources.OffsetParam"/>
      <param name="length" type="org.apache.hadoop.hdfs.web.resources.LengthParam"/>
      <param name="renewer" type="org.apache.hadoop.hdfs.web.resources.RenewerParam"/>
      <param name="bufferSize" type="org.apache.hadoop.hdfs.web.resources.BufferSizeParam"/>
      <param name="xattrNames" type="java.util.List"/>
      <param name="xattrEncoding" type="org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam"/>
      <param name="excludeDatanodes" type="org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam"/>
      <param name="fsAction" type="org.apache.hadoop.hdfs.web.resources.FsActionParam"/>
      <param name="tokenKind" type="org.apache.hadoop.hdfs.web.resources.TokenKindParam"/>
      <param name="tokenService" type="org.apache.hadoop.hdfs.web.resources.TokenServiceParam"/>
      <param name="noredirect" type="org.apache.hadoop.hdfs.web.resources.NoRedirectParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP GET request for the root.]]>
      </doc>
    </method>
    <method name="get" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="path" type="org.apache.hadoop.hdfs.web.resources.UriFsPathParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.GetOpParam"/>
      <param name="offset" type="org.apache.hadoop.hdfs.web.resources.OffsetParam"/>
      <param name="length" type="org.apache.hadoop.hdfs.web.resources.LengthParam"/>
      <param name="renewer" type="org.apache.hadoop.hdfs.web.resources.RenewerParam"/>
      <param name="bufferSize" type="org.apache.hadoop.hdfs.web.resources.BufferSizeParam"/>
      <param name="xattrNames" type="java.util.List"/>
      <param name="xattrEncoding" type="org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam"/>
      <param name="excludeDatanodes" type="org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam"/>
      <param name="fsAction" type="org.apache.hadoop.hdfs.web.resources.FsActionParam"/>
      <param name="tokenKind" type="org.apache.hadoop.hdfs.web.resources.TokenKindParam"/>
      <param name="tokenService" type="org.apache.hadoop.hdfs.web.resources.TokenServiceParam"/>
      <param name="noredirect" type="org.apache.hadoop.hdfs.web.resources.NoRedirectParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP GET request.]]>
      </doc>
    </method>
    <method name="deleteRoot" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.DeleteOpParam"/>
      <param name="recursive" type="org.apache.hadoop.hdfs.web.resources.RecursiveParam"/>
      <param name="snapshotName" type="org.apache.hadoop.hdfs.web.resources.SnapshotNameParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP DELETE request for the root.]]>
      </doc>
    </method>
    <method name="delete" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
      <param name="delegation" type="org.apache.hadoop.hdfs.web.resources.DelegationParam"/>
      <param name="username" type="org.apache.hadoop.hdfs.web.resources.UserParam"/>
      <param name="doAsUser" type="org.apache.hadoop.hdfs.web.resources.DoAsParam"/>
      <param name="path" type="org.apache.hadoop.hdfs.web.resources.UriFsPathParam"/>
      <param name="op" type="org.apache.hadoop.hdfs.web.resources.DeleteOpParam"/>
      <param name="recursive" type="org.apache.hadoop.hdfs.web.resources.RecursiveParam"/>
      <param name="snapshotName" type="org.apache.hadoop.hdfs.web.resources.SnapshotNameParam"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Handle HTTP DELETE request.]]>
      </doc>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Web-hdfs NameNode implementation.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods -->
</package>
<package name="org.apache.hadoop.hdfs.server.protocol">
  <!-- start class org.apache.hadoop.hdfs.server.protocol.BalancerBandwidthCommand -->
  <class name="BalancerBandwidthCommand" extends="org.apache.hadoop.hdfs.server.protocol.DatanodeCommand"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="BalancerBandwidthCommand" type="long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Balancer Bandwidth Command constructor.

 @param bandwidth Blanacer bandwidth in bytes per second.]]>
      </doc>
    </constructor>
    <method name="getBalancerBandwidthValue" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get current value of the max balancer bandwidth in bytes per second.

 @return bandwidth Blanacer bandwidth in bytes per second for this datanode.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Balancer bandwidth command instructs each datanode to change its value for
 the max amount of network bandwidth it may use during the block balancing
 operation.
 
 The Balancer Bandwidth Command contains the new bandwidth value as its
 payload. The bandwidth value is in bytes per second.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.BalancerBandwidthCommand -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringStripedBlock -->
  <class name="BlockRecoveryCommand.RecoveringStripedBlock" extends="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="RecoveringStripedBlock" type="org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock, byte[], org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getBlockIndices" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getErasureCodingPolicy" return="org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isStriped" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringStripedBlock -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.StripedBlockWithLocations -->
  <class name="BlocksWithLocations.StripedBlockWithLocations" extends="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.BlockWithLocations"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="StripedBlockWithLocations" type="org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.BlockWithLocations, byte[], short, int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getIndices" return="byte[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getDataBlockNum" return="short"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCellSize" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.StripedBlockWithLocations -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.FencedException -->
  <class name="FencedException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="FencedException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[If a previous user of a resource tries to use a shared resource, after
 fenced by another user, this exception is thrown.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.FencedException -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.Capability -->
  <class name="NamespaceInfo.Capability" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.Capability[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.Capability"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getMask" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.Capability -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo -->
  <class name="ReceivedDeletedBlockInfo" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="ReceivedDeletedBlockInfo"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="ReceivedDeletedBlockInfo" type="org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo.BlockStatus, java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getBlock" return="org.apache.hadoop.hdfs.protocol.Block"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setBlock"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="blk" type="org.apache.hadoop.hdfs.protocol.Block"/>
    </method>
    <method name="getDelHints" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setDelHints"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="hints" type="java.lang.String"/>
    </method>
    <method name="getStatus" return="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo.BlockStatus"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="blockEquals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="org.apache.hadoop.hdfs.protocol.Block"/>
    </method>
    <method name="isDeletedBlock" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A data structure to store the blocks in an incremental block report.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo.BlockStatus -->
  <class name="ReceivedDeletedBlockInfo.BlockStatus" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo.BlockStatus[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo.BlockStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
    <method name="getCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="fromCode" return="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo.BlockStatus"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="code" type="int"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo.BlockStatus -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.RemoteEditLog -->
  <class name="RemoteEditLog" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Comparable"/>
    <constructor name="RemoteEditLog"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="RemoteEditLog" type="long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="RemoteEditLog" type="long, long, boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getStartTxId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getEndTxId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isInProgress" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="compareTo" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="log" type="org.apache.hadoop.hdfs.server.protocol.RemoteEditLog"/>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="o" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="GET_START_TXID" type="com.google.common.base.Function"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Guava <code>Function</code> which applies {@link #getStartTxId()}]]>
      </doc>
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.RemoteEditLog -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest -->
  <class name="RemoteEditLogManifest" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="RemoteEditLogManifest"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="RemoteEditLogManifest" type="java.util.List, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getLogs" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getCommittedTxnId" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[An enumeration of logs available on a remote NameNode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.StorageBlockReport -->
  <class name="StorageBlockReport" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="StorageBlockReport" type="org.apache.hadoop.hdfs.server.protocol.DatanodeStorage, org.apache.hadoop.hdfs.protocol.BlockListAsLongs"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getStorage" return="org.apache.hadoop.hdfs.server.protocol.DatanodeStorage"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBlocks" return="org.apache.hadoop.hdfs.protocol.BlockListAsLongs"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Block report for a Datanode storage]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.StorageBlockReport -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks -->
  <class name="StorageReceivedDeletedBlocks" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="StorageReceivedDeletedBlocks" type="java.lang.String, org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="StorageReceivedDeletedBlocks" type="org.apache.hadoop.hdfs.server.protocol.DatanodeStorage, org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getStorageID" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getStorage" return="org.apache.hadoop.hdfs.server.protocol.DatanodeStorage"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getBlocks" return="org.apache.hadoop.hdfs.server.protocol.ReceivedDeletedBlockInfo[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Report of block received and deleted per Datanode
 storage.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks -->
  <!-- start class org.apache.hadoop.hdfs.server.protocol.VolumeFailureSummary -->
  <class name="VolumeFailureSummary" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="VolumeFailureSummary" type="java.lang.String[], long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Creates a new VolumeFailureSummary.

 @param failedStorageLocations storage locations that have failed
 @param lastVolumeFailureDate date/time of last volume failure in
     milliseconds since epoch
 @param estimatedCapacityLostTotal estimate of capacity lost in bytes]]>
      </doc>
    </constructor>
    <method name="getFailedStorageLocations" return="java.lang.String[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns each storage location that has failed, sorted.

 @return each storage location that has failed, sorted]]>
      </doc>
    </method>
    <method name="getLastVolumeFailureDate" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the date/time of the last volume failure in milliseconds since
 epoch.

 @return date/time of last volume failure in milliseconds since epoch]]>
      </doc>
    </method>
    <method name="getEstimatedCapacityLostTotal" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns estimate of capacity lost.  This is said to be an estimate, because
 in some cases it's impossible to know the capacity of the volume, such as if
 we never had a chance to query its capacity before the failure occurred.

 @return estimate of capacity lost in bytes]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Summarizes information about data volume failures on a DataNode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.server.protocol.VolumeFailureSummary -->
</package>
<package name="org.apache.hadoop.hdfs.tools">
  <!-- start class org.apache.hadoop.hdfs.tools.AdminHelper -->
  <class name="AdminHelper" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="AdminHelper"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Helper methods for CacheAdmin/CryptoAdmin/StoragePolicyAdmin]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.AdminHelper -->
  <!-- start class org.apache.hadoop.hdfs.tools.DFSHAAdmin -->
  <class name="DFSHAAdmin" extends="org.apache.hadoop.ha.HAAdmin"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DFSHAAdmin"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setErrOut"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="errOut" type="java.io.PrintStream"/>
    </method>
    <method name="setOut"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="out" type="java.io.PrintStream"/>
    </method>
    <method name="setConf"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
    </method>
    <method name="addSecurityConfiguration" return="org.apache.hadoop.conf.Configuration"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
      <doc>
      <![CDATA[Add the requisite security principal settings to the given Configuration,
 returning a copy.
 @param conf the original config
 @return a copy with the security settings added]]>
      </doc>
    </method>
    <method name="resolveTarget" return="org.apache.hadoop.ha.HAServiceTarget"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="nnId" type="java.lang.String"/>
      <doc>
      <![CDATA[Try to map the given namenode ID to its service address.]]>
      </doc>
    </method>
    <method name="getUsageString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </method>
    <method name="runCmd" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="argv" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="getTargetIds" return="java.util.Collection"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="namenodeToActivate" type="java.lang.String"/>
      <doc>
      <![CDATA[returns the list of all namenode ids for the given configuration]]>
      </doc>
    </method>
    <method name="main"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="argv" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <doc>
    <![CDATA[Class to extend HAAdmin to do a little bit of HDFS-specific configuration.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.DFSHAAdmin -->
  <!-- start class org.apache.hadoop.hdfs.tools.DiskBalancer -->
  <class name="DiskBalancer" extends="org.apache.hadoop.conf.Configured"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.util.Tool"/>
    <constructor name="DiskBalancer" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct a DiskBalancer.

 @param conf]]>
      </doc>
    </constructor>
    <method name="main"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="argv" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Main for the  DiskBalancer Command handling.

 @param argv - System Args Strings[]
 @throws Exception]]>
      </doc>
    </method>
    <method name="run" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="args" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Execute the command with the given arguments.

 @param args command specific arguments.
 @return exit code.
 @throws Exception]]>
      </doc>
    </method>
    <method name="run" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="args" type="java.lang.String[]"/>
      <param name="out" type="java.io.PrintStream"/>
      <exception name="Exception" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Execute the command with the given arguments.

 @param args command specific arguments.
 @param out  the output stream used for printing
 @return exit code.
 @throws Exception]]>
      </doc>
    </method>
    <method name="getPlanOptions" return="org.apache.commons.cli.Options"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns Plan options.

 @return Options.]]>
      </doc>
    </method>
    <method name="getHelpOptions" return="org.apache.commons.cli.Options"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns help options.

 @return - help options.]]>
      </doc>
    </method>
    <method name="getExecuteOptions" return="org.apache.commons.cli.Options"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Retuns execute options.

 @return - execute options.]]>
      </doc>
    </method>
    <method name="getQueryOptions" return="org.apache.commons.cli.Options"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns Query Options.

 @return query Options]]>
      </doc>
    </method>
    <method name="getCancelOptions" return="org.apache.commons.cli.Options"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns Cancel Options.

 @return Options]]>
      </doc>
    </method>
    <method name="getReportOptions" return="org.apache.commons.cli.Options"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns Report Options.

 @return Options]]>
      </doc>
    </method>
    <field name="PLAN" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Computes a plan for a given set of nodes.]]>
      </doc>
    </field>
    <field name="OUTFILE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Output file name, for commands like report, plan etc. This is an optional
 argument, by default diskbalancer will write all its output to
 /system/reports/diskbalancer of the current cluster it is operating
 against.]]>
      </doc>
    </field>
    <field name="HELP" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Help for the program.]]>
      </doc>
    </field>
    <field name="THRESHOLD" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Percentage of data unevenness that we are willing to live with. For example
 - a value like 10 indicates that we are okay with 10 % +/- from
 idealStorage Target.]]>
      </doc>
    </field>
    <field name="BANDWIDTH" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Specifies the maximum disk bandwidth to use per second.]]>
      </doc>
    </field>
    <field name="MAXERROR" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Specifies the maximum errors to tolerate.]]>
      </doc>
    </field>
    <field name="EXECUTE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Executes a given plan file on the target datanode.]]>
      </doc>
    </field>
    <field name="REPORT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The report command prints out a disk fragmentation report about the data
 cluster. By default it prints the DEFAULT_TOP machines names with high
 nodeDataDensity {DiskBalancerDataNode#getNodeDataDensity} values. This
 means that these are the nodes that deviates from the ideal data
 distribution.]]>
      </doc>
    </field>
    <field name="TOP" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[specify top number of nodes to be processed.]]>
      </doc>
    </field>
    <field name="DEFAULT_TOP" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[specify default top number of nodes to be processed.]]>
      </doc>
    </field>
    <field name="NODE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Name or address of the node to execute against.]]>
      </doc>
    </field>
    <field name="VERBOSE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Runs the command in verbose mode.]]>
      </doc>
    </field>
    <field name="PLAN_VERSION" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <field name="QUERY" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Reports the status of disk balancer operation.]]>
      </doc>
    </field>
    <field name="CANCEL" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Cancels a running plan.]]>
      </doc>
    </field>
    <field name="BEFORE_TEMPLATE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Template for the Before File. It is node.before.json.]]>
      </doc>
    </field>
    <field name="PLAN_TEMPLATE" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Template for the plan file. it is node.plan.json.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[DiskBalancer is a tool that can be used to ensure that data is spread evenly
 across volumes of same storage type.
 <p>
 For example, if you have 3 disks, with 100 GB , 600 GB and 200 GB on each
 disk, this tool will ensure that each disk will have 300 GB.
 <p>
 This tool can be run while data nodes are fully functional.
 <p>
 At very high level diskbalancer computes a set of moves that will make disk
 utilization equal and then those moves are executed by the datanode.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.DiskBalancer -->
  <!-- start class org.apache.hadoop.hdfs.tools.GetConf -->
  <class name="GetConf" extends="org.apache.hadoop.conf.Configured"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.util.Tool"/>
    <method name="run" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="args" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="main"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="args" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <doc>
    <![CDATA[Tool for getting configuration information from a configuration file.
 
 Adding more options:
 <ul>
 <li>
 If adding a simple option to get a value corresponding to a key in the 
 configuration, use regular {@link GetConf.CommandHandler}. 
 See {@link GetConf.Command#EXCLUDE_FILE} example.
 </li>
 <li>
 If adding an option that is does not return a value for a key, add
 a subclass of {@link GetConf.CommandHandler} and set it up in 
 {@link GetConf.Command}.
 
 See {@link GetConf.Command#NAMENODE} for example.
 
 Add for the new option added, a map entry with the corresponding
 {@link GetConf.CommandHandler}.
 </ul>]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.GetConf -->
  <!-- start class org.apache.hadoop.hdfs.tools.StoragePolicyAdmin -->
  <class name="StoragePolicyAdmin" extends="org.apache.hadoop.conf.Configured"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="org.apache.hadoop.util.Tool"/>
    <constructor name="StoragePolicyAdmin" type="org.apache.hadoop.conf.Configuration"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="main"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="argsArray" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <method name="run" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="args" type="java.lang.String[]"/>
      <exception name="Exception" type="java.lang.Exception"/>
    </method>
    <doc>
    <![CDATA[This class implements block storage policy operations.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.StoragePolicyAdmin -->
</package>
<package name="org.apache.hadoop.hdfs.tools.erasurecode">
</package>
<package name="org.apache.hadoop.hdfs.tools.offlineEditsViewer">
  <!-- start class org.apache.hadoop.hdfs.tools.offlineEditsViewer.OfflineEditsViewer.Flags -->
  <class name="OfflineEditsViewer.Flags" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Flags"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getPrintToScreen" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setPrintToScreen"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getFixTxIds" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setFixTxIds"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getRecoveryMode" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="setRecoveryMode"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.offlineEditsViewer.OfflineEditsViewer.Flags -->
  <!-- start class org.apache.hadoop.hdfs.tools.offlineEditsViewer.TeeOutputStream -->
  <class name="TeeOutputStream" extends="java.io.OutputStream"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="TeeOutputStream" type="java.io.OutputStream[]"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="byte[]"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="write"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="b" type="byte[]"/>
      <param name="off" type="int"/>
      <param name="len" type="int"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="flush"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[A TeeOutputStream writes its output to multiple output streams.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.offlineEditsViewer.TeeOutputStream -->
</package>
<package name="org.apache.hadoop.hdfs.tools.offlineImageViewer">
  <!-- start class org.apache.hadoop.hdfs.tools.offlineImageViewer.IgnoreSnapshotException -->
  <class name="IgnoreSnapshotException" extends="java.io.IOException"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="IgnoreSnapshotException"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Signals that a snapshot is ignored.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.offlineImageViewer.IgnoreSnapshotException -->
  <!-- start class org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageDelimitedTextWriter -->
  <class name="PBImageDelimitedTextWriter" extends="org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageTextWriter"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getEntry" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="parent" type="java.lang.String"/>
      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.FsImageProto.INodeSection.INode"/>
    </method>
    <method name="getHeader" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A PBImageDelimitedTextWriter generates a text representation of the PB fsimage,
 with each element separated by a delimiter string.  All of the elements
 common to both inodes and inodes-under-construction are included. When
 processing an fsimage with a layout version that did not include an
 element, such as AccessTime, the output file will include a column
 for the value, but no value will be included.

 Individual block information for each file is not currently included.

 The default delimiter is tab, as this is an unlikely value to be included in
 an inode path or other text metadata. The delimiter value can be via the
 constructor.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.offlineImageViewer.PBImageDelimitedTextWriter -->
  <!-- start class org.apache.hadoop.hdfs.tools.offlineImageViewer.WebImageViewer -->
  <class name="WebImageViewer" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.io.Closeable"/>
    <constructor name="WebImageViewer" type="java.net.InetSocketAddress"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="start"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fsimage" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Start WebImageViewer and wait until the thread is interrupted.
 @param fsimage the fsimage to load.
 @throws IOException if failed to load the fsimage.]]>
      </doc>
    </method>
    <method name="initServer"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fsimage" type="java.lang.String"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Start WebImageViewer.
 @param fsimage the fsimage to load.
 @throws IOException if fail to load the fsimage.]]>
      </doc>
    </method>
    <method name="getPort" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Get the listening port.
 @return the port WebImageViewer is listening on]]>
      </doc>
    </method>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[WebImageViewer loads a fsimage and exposes read-only WebHDFS API for its
 namespace.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.offlineImageViewer.WebImageViewer -->
  <!-- start class org.apache.hadoop.hdfs.tools.offlineImageViewer.XmlImageVisitor -->
  <class name="XmlImageVisitor" extends="org.apache.hadoop.hdfs.tools.offlineImageViewer.TextWriterImageVisitor"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="XmlImageVisitor" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <constructor name="XmlImageVisitor" type="java.lang.String, boolean"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </constructor>
    <doc>
    <![CDATA[An XmlImageVisitor walks over an fsimage structure and writes out
 an equivalent XML document that contains the fsimage's components.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.tools.offlineImageViewer.XmlImageVisitor -->
</package>
<package name="org.apache.hadoop.hdfs.tools.snapshot">
</package>
<package name="org.apache.hadoop.hdfs.util">
  <!-- start class org.apache.hadoop.hdfs.util.AtomicFileOutputStream -->
  <class name="AtomicFileOutputStream" extends="java.io.FilterOutputStream"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="AtomicFileOutputStream" type="java.io.File"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
    </constructor>
    <method name="close"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="abort"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Close the atomic file, but do not "commit" the temporary file
 on top of the destination. This should be used if there is a failure
 in writing.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A FileOutputStream that has the property that it will only show
 up at its destination once it has been entirely written and flushed
 to disk. While being written, it will use a .tmp suffix.
 
 When the output stream is closed, it is flushed, fsynced, and
 will be moved into place, overwriting any file that already
 exists at that location.
 
 <b>NOTE</b>: on Windows platforms, it will not atomically
 replace the target file - instead the target file is deleted
 before this one is moved into place.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.AtomicFileOutputStream -->
  <!-- start class org.apache.hadoop.hdfs.util.DataTransferThrottler -->
  <class name="DataTransferThrottler" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="DataTransferThrottler" type="long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor 
 @param bandwidthPerSec bandwidth allowed in bytes per second.]]>
      </doc>
    </constructor>
    <constructor name="DataTransferThrottler" type="long, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor
 @param period in milliseconds. Bandwidth is enforced over this
        period.
 @param bandwidthPerSec bandwidth allowed in bytes per second.]]>
      </doc>
    </constructor>
    <method name="getBandwidth" return="long"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return current throttle bandwidth in bytes per second.]]>
      </doc>
    </method>
    <method name="setBandwidth"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="bytesPerSecond" type="long"/>
      <doc>
      <![CDATA[Sets throttle bandwidth. This takes affect latest by the end of current
 period.]]>
      </doc>
    </method>
    <method name="throttle"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="numOfBytes" type="long"/>
      <doc>
      <![CDATA[Given the numOfBytes sent/received since last time throttle was called,
 make the current thread sleep if I/O rate is too fast
 compared to the given bandwidth.

 @param numOfBytes
     number of bytes sent/received since last time throttle was called]]>
      </doc>
    </method>
    <method name="throttle"
      abstract="false" native="false" synchronized="true"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="numOfBytes" type="long"/>
      <param name="canceler" type="org.apache.hadoop.hdfs.util.Canceler"/>
      <doc>
      <![CDATA[Given the numOfBytes sent/received since last time throttle was called,
 make the current thread sleep if I/O rate is too fast
 compared to the given bandwidth.  Allows for optional external cancelation.

 @param numOfBytes
     number of bytes sent/received since last time throttle was called
 @param canceler
     optional canceler to check for abort of throttle]]>
      </doc>
    </method>
    <doc>
    <![CDATA[a class to throttle the data transfers.
 This class is thread safe. It can be shared by multiple threads.
 The parameter bandwidthPerSec specifies the total bandwidth shared by
 threads.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.DataTransferThrottler -->
  <!-- start class org.apache.hadoop.hdfs.util.Diff -->
  <class name="Diff" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Diff"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <constructor name="Diff" type="java.util.List, java.util.List"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
    </constructor>
    <method name="search" return="int"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="elements" type="java.util.List"/>
      <param name="name" type="K"/>
      <doc>
      <![CDATA[Search the element from the list.
 @return -1 if the list is null; otherwise, return the insertion point
    defined in {@link Collections#binarySearch(List, Object)}.
    Note that, when the list is null, -1 is the correct insertion point.]]>
      </doc>
    </method>
    <method name="getList" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.util.Diff.ListType"/>
      <doc>
      <![CDATA[@return the created list, which is never null.]]>
      </doc>
    </method>
    <method name="searchIndex" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.util.Diff.ListType"/>
      <param name="name" type="K"/>
    </method>
    <method name="search" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="type" type="org.apache.hadoop.hdfs.util.Diff.ListType"/>
      <param name="name" type="K"/>
      <doc>
      <![CDATA[@return null if the element is not found;
         otherwise, return the element in the created/deleted list.]]>
      </doc>
    </method>
    <method name="isEmpty" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return true if no changes contained in the diff]]>
      </doc>
    </method>
    <method name="create" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="element" type="E"/>
      <doc>
      <![CDATA[Create an element in current state.
 @return the c-list insertion point for undo.]]>
      </doc>
    </method>
    <method name="undoCreate"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="element" type="E"/>
      <param name="insertionPoint" type="int"/>
      <doc>
      <![CDATA[Undo the previous create(E) operation. Note that the behavior is
 undefined if the previous operation is not create(E).]]>
      </doc>
    </method>
    <method name="delete" return="org.apache.hadoop.hdfs.util.Diff.UndoInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="element" type="E"/>
      <doc>
      <![CDATA[Delete an element from current state.
 @return the undo information.]]>
      </doc>
    </method>
    <method name="undoDelete"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="element" type="E"/>
      <param name="undoInfo" type="org.apache.hadoop.hdfs.util.Diff.UndoInfo"/>
      <doc>
      <![CDATA[Undo the previous delete(E) operation. Note that the behavior is
 undefined if the previous operation is not delete(E).]]>
      </doc>
    </method>
    <method name="modify" return="org.apache.hadoop.hdfs.util.Diff.UndoInfo"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="oldElement" type="E"/>
      <param name="newElement" type="E"/>
      <doc>
      <![CDATA[Modify an element in current state.
 @return the undo information.]]>
      </doc>
    </method>
    <method name="undoModify"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="oldElement" type="E"/>
      <param name="newElement" type="E"/>
      <param name="undoInfo" type="org.apache.hadoop.hdfs.util.Diff.UndoInfo"/>
      <doc>
      <![CDATA[Undo the previous modify(E, E) operation. Note that the behavior
 is undefined if the previous operation is not modify(E, E).]]>
      </doc>
    </method>
    <method name="accessPrevious" return="org.apache.hadoop.hdfs.util.Diff.Container"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="K"/>
      <doc>
      <![CDATA[Find an element in the previous state.
 
 @return null if the element cannot be determined in the previous state
         since no change is recorded and it should be determined in the
         current state; otherwise, return a {@link Container} containing the
         element in the previous state. Note that the element can possibly
         be null which means that the element is not found in the previous
         state.]]>
      </doc>
    </method>
    <method name="accessCurrent" return="org.apache.hadoop.hdfs.util.Diff.Container"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="K"/>
      <doc>
      <![CDATA[Find an element in the current state.
 
 @return null if the element cannot be determined in the current state since
         no change is recorded and it should be determined in the previous
         state; otherwise, return a {@link Container} containing the element in
         the current state. Note that the element can possibly be null which
         means that the element is not found in the current state.]]>
      </doc>
    </method>
    <method name="apply2Previous" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="previous" type="java.util.List"/>
      <doc>
      <![CDATA[Apply this diff to previous state in order to obtain current state.
 @return the current state of the list.]]>
      </doc>
    </method>
    <method name="apply2Current" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="current" type="java.util.List"/>
      <doc>
      <![CDATA[Apply the reverse of this diff to current state in order
 to obtain the previous state.
 @return the previous state of the list.]]>
      </doc>
    </method>
    <method name="combinePosterior"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="posterior" type="org.apache.hadoop.hdfs.util.Diff"/>
      <param name="deletedProcesser" type="org.apache.hadoop.hdfs.util.Diff.Processor"/>
      <doc>
      <![CDATA[Combine this diff with a posterior diff.  We have the following cases:
 
 <pre>
 1. For (c, 0) in the posterior diff, check the element in this diff:
 1.1 (c', 0)  in this diff: impossible
 1.2 (0, d')  in this diff: put in c-list --> (c, d')
 1.3 (c', d') in this diff: impossible
 1.4 (0, 0)   in this diff: put in c-list --> (c, 0)
 This is the same logic as create(E).
 
 2. For (0, d) in the posterior diff,
 2.1 (c', 0)  in this diff: remove from c-list --> (0, 0)
 2.2 (0, d')  in this diff: impossible
 2.3 (c', d') in this diff: remove from c-list --> (0, d')
 2.4 (0, 0)   in this diff: put in d-list --> (0, d)
 This is the same logic as delete(E).
 
 3. For (c, d) in the posterior diff,
 3.1 (c', 0)  in this diff: replace the element in c-list --> (c, 0)
 3.2 (0, d')  in this diff: impossible
 3.3 (c', d') in this diff: replace the element in c-list --> (c, d')
 3.4 (0, 0)   in this diff: put in c-list and d-list --> (c, d)
 This is the same logic as modify(E, E).
 </pre>
 
 @param posterior The posterior diff to combine with.
 @param deletedProcesser
     process the deleted/overwritten elements in case 2.1, 2.3, 3.1 and 3.3.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[The difference between the current state and a previous state of a list.
 
 Given a previous state of a set and a sequence of create, delete and modify
 operations such that the current state of the set can be obtained by applying
 the operations on the previous state, the following algorithm construct the
 difference between the current state and the previous state of the set.
 
 <pre>
 Two lists are maintained in the algorithm:
 - c-list for newly created elements
 - d-list for the deleted elements

 Denote the state of an element by the following
   (0, 0): neither in c-list nor d-list
   (c, 0): in c-list but not in d-list
   (0, d): in d-list but not in c-list
   (c, d): in both c-list and d-list

 For each case below, ( , ) at the end shows the result state of the element.

 Case 1. Suppose the element i is NOT in the previous state.           (0, 0)
   1.1. create i in current: add it to c-list                          (c, 0)
   1.1.1. create i in current and then create: impossible
   1.1.2. create i in current and then delete: remove it from c-list   (0, 0)
   1.1.3. create i in current and then modify: replace it in c-list    (c', 0)

   1.2. delete i from current: impossible

   1.3. modify i in current: impossible

 Case 2. Suppose the element i is ALREADY in the previous state.       (0, 0)
   2.1. create i in current: impossible

   2.2. delete i from current: add it to d-list                        (0, d)
   2.2.1. delete i from current and then create: add it to c-list      (c, d)
   2.2.2. delete i from current and then delete: impossible
   2.2.2. delete i from current and then modify: impossible

   2.3. modify i in current: put it in both c-list and d-list          (c, d)
   2.3.1. modify i in current and then create: impossible
   2.3.2. modify i in current and then delete: remove it from c-list   (0, d)
   2.3.3. modify i in current and then modify: replace it in c-list    (c', d)
 </pre>

 @param <K> The key type.
 @param <E> The element type, which must implement {@link Element} interface.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.Diff -->
  <!-- start class org.apache.hadoop.hdfs.util.Diff.Container -->
  <class name="Diff.Container" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getElement" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the element.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Containing exactly one element.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.Diff.Container -->
  <!-- start interface org.apache.hadoop.hdfs.util.Diff.Element -->
  <interface name="Diff.Element"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.lang.Comparable"/>
    <method name="getKey" return="K"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the key of this object.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[An interface for the elements in a {@link Diff}.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.util.Diff.Element -->
  <!-- start class org.apache.hadoop.hdfs.util.Diff.ListType -->
  <class name="Diff.ListType" extends="java.lang.Enum"
    abstract="false"
    static="true" final="true" visibility="public"
    deprecated="not deprecated">
    <method name="values" return="org.apache.hadoop.hdfs.util.Diff.ListType[]"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="valueOf" return="org.apache.hadoop.hdfs.util.Diff.ListType"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
    </method>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.Diff.ListType -->
  <!-- start interface org.apache.hadoop.hdfs.util.Diff.Processor -->
  <interface name="Diff.Processor"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="process"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="element" type="E"/>
      <doc>
      <![CDATA[Process the given element.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[An interface for passing a method in order to process elements.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.util.Diff.Processor -->
  <!-- start class org.apache.hadoop.hdfs.util.Diff.UndoInfo -->
  <class name="Diff.UndoInfo" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getTrashedElement" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Undo information for some operations such as delete(E)
 and {@link Diff#modify(Element, Element)}.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.Diff.UndoInfo -->
  <!-- start class org.apache.hadoop.hdfs.util.EnumCounters -->
  <class name="EnumCounters" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="EnumCounters" type="java.lang.Class"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct counters for the given enum constants.
 @param enumClass the enum class of the counters.]]>
      </doc>
    </constructor>
    <constructor name="EnumCounters" type="java.lang.Class, long"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="get" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <doc>
      <![CDATA[@return the value of counter e.]]>
      </doc>
    </method>
    <method name="asArray" return="long[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the values of counter as a shadow copy of array]]>
      </doc>
    </method>
    <method name="negation"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Negate all counters.]]>
      </doc>
    </method>
    <method name="set"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <param name="value" type="long"/>
      <doc>
      <![CDATA[Set counter e to the given value.]]>
      </doc>
    </method>
    <method name="set"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.util.EnumCounters"/>
      <doc>
      <![CDATA[Set this counters to that counters.]]>
      </doc>
    </method>
    <method name="reset"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Reset all counters to zero.]]>
      </doc>
    </method>
    <method name="add"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <param name="value" type="long"/>
      <doc>
      <![CDATA[Add the given value to counter e.]]>
      </doc>
    </method>
    <method name="add"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.util.EnumCounters"/>
      <doc>
      <![CDATA[Add that counters to this counters.]]>
      </doc>
    </method>
    <method name="subtract"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <param name="value" type="long"/>
      <doc>
      <![CDATA[Subtract the given value from counter e.]]>
      </doc>
    </method>
    <method name="subtract"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.util.EnumCounters"/>
      <doc>
      <![CDATA[Subtract this counters from that counters.]]>
      </doc>
    </method>
    <method name="sum" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the sum of all counters.]]>
      </doc>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="reset"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <method name="allLessOrEqual" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <method name="anyGreaterOrEqual" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="val" type="long"/>
    </method>
    <doc>
    <![CDATA[Counters for an enum type.
 
 For example, suppose there is an enum type
 <pre>
 enum Fruit { APPLE, ORANGE, GRAPE }
 </pre>
 An {@link EnumCounters} object can be created for counting the numbers of
 APPLE, ORANGLE and GRAPE.

 @param <E> the enum type]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.EnumCounters -->
  <!-- start interface org.apache.hadoop.hdfs.util.EnumCounters.Factory -->
  <interface name="EnumCounters.Factory"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="newInstance" return="C"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create a new counters instance.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A factory for creating counters.
 
 @param <E> the enum type
 @param <C> the counter type]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.util.EnumCounters.Factory -->
  <!-- start class org.apache.hadoop.hdfs.util.EnumCounters.Map -->
  <class name="EnumCounters.Map" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Map" type="org.apache.hadoop.hdfs.util.EnumCounters.Factory"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct a map.]]>
      </doc>
    </constructor>
    <method name="getCounts" return="C"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="key" type="K"/>
      <doc>
      <![CDATA[@return the counters for the given key.]]>
      </doc>
    </method>
    <method name="sum" return="C"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the sum of the values of all the counters.]]>
      </doc>
    </method>
    <method name="sum" return="long"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <doc>
      <![CDATA[@return the sum of the values of all the counters for e.]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A key-value map which maps the keys to {@link EnumCounters}.
 Note that null key is supported.

 @param <K> the key type
 @param <E> the enum type
 @param <C> the counter type]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.EnumCounters.Map -->
  <!-- start class org.apache.hadoop.hdfs.util.EnumDoubles -->
  <class name="EnumDoubles" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="EnumDoubles" type="java.lang.Class"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct doubles for the given enum constants.
 @param enumClass the enum class.]]>
      </doc>
    </constructor>
    <method name="get" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <doc>
      <![CDATA[@return the value corresponding to e.]]>
      </doc>
    </method>
    <method name="negation"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Negate all values.]]>
      </doc>
    </method>
    <method name="set"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <param name="value" type="double"/>
      <doc>
      <![CDATA[Set e to the given value.]]>
      </doc>
    </method>
    <method name="set"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.util.EnumDoubles"/>
      <doc>
      <![CDATA[Set the values of this object to that object.]]>
      </doc>
    </method>
    <method name="reset"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Reset all values to zero.]]>
      </doc>
    </method>
    <method name="add"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <param name="value" type="double"/>
      <doc>
      <![CDATA[Add the given value to e.]]>
      </doc>
    </method>
    <method name="add"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.util.EnumDoubles"/>
      <doc>
      <![CDATA[Add the values of that object to this.]]>
      </doc>
    </method>
    <method name="subtract"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="E"/>
      <param name="value" type="double"/>
      <doc>
      <![CDATA[Subtract the given value from e.]]>
      </doc>
    </method>
    <method name="subtract"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <param name="that" type="org.apache.hadoop.hdfs.util.EnumDoubles"/>
      <doc>
      <![CDATA[Subtract the values of this object from that object.]]>
      </doc>
    </method>
    <method name="equals" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="hashCode" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Similar to {@link EnumCounters} except that the value type is double.

 @param <E> the enum type]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.EnumDoubles -->
  <!-- start class org.apache.hadoop.hdfs.util.FoldedTreeSet -->
  <class name="FoldedTreeSet" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.util.SortedSet"/>
    <constructor name="FoldedTreeSet"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create a new TreeSet that uses the natural ordering of objects. The element
 type must implement Comparable.]]>
      </doc>
    </constructor>
    <constructor name="FoldedTreeSet" type="java.util.Comparator"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Create a new TreeSet that orders the elements using the supplied
 Comparator.

 @param comparator Comparator able to compare elements of type E]]>
      </doc>
    </constructor>
    <method name="comparator" return="java.util.Comparator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="subSet" return="java.util.SortedSet"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fromElement" type="E"/>
      <param name="toElement" type="E"/>
    </method>
    <method name="headSet" return="java.util.SortedSet"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="toElement" type="E"/>
    </method>
    <method name="tailSet" return="java.util.SortedSet"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="fromElement" type="E"/>
    </method>
    <method name="first" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="last" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="size" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="isEmpty" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="get" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
      <param name="cmp" type="java.util.Comparator"/>
      <doc>
      <![CDATA[Lookup and return a stored object using a user provided comparator.

 @param obj Lookup key
 @param cmp User provided Comparator. The comparator should expect that the
            proved obj will always be the first method parameter and any
            stored object will be the second parameter.

 @return A matching stored object or null if non is found]]>
      </doc>
    </method>
    <method name="get" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="E"/>
      <doc>
      <![CDATA[Lookup and return a stored object.

 @param entry Lookup entry

 @return A matching stored object or null if non is found]]>
      </doc>
    </method>
    <method name="contains" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="iterator" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toArray" return="java.lang.Object[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toArray" return="T[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="T[]"/>
    </method>
    <method name="addOrReplace" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="E"/>
      <doc>
      <![CDATA[Add or replace an entry in the TreeSet.

 @param entry Entry to add or replace/update.

 @return the previous entry, or null if this set did not already contain the
         specified entry]]>
      </doc>
    </method>
    <method name="add" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="E"/>
    </method>
    <method name="addSortedLast" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="entry" type="E"/>
      <doc>
      <![CDATA[Insert an entry last in the sorted tree. The entry must be the considered
 larger than the currently largest entry in the set when doing
 current.compareTo(entry), if entry is not the largest entry the method will
 fall back on the regular add method.

 @param entry entry to add

 @return True if added, false if already existed in the set]]>
      </doc>
    </method>
    <method name="removeAndGet" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
      <param name="cmp" type="java.util.Comparator"/>
      <doc>
      <![CDATA[Remove object using a provided comparator, and return the removed entry.

 @param obj Lookup entry
 @param cmp User provided Comparator. The comparator should expect that the
            proved obj will always be the first method parameter and any
            stored object will be the second parameter.

 @return The removed entry or null if not found]]>
      </doc>
    </method>
    <method name="removeAndGet" return="E"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
      <doc>
      <![CDATA[Remove object and return the removed entry.

 @param obj Lookup entry

 @return The removed entry or null if not found]]>
      </doc>
    </method>
    <method name="remove" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
      <param name="cmp" type="java.util.Comparator"/>
      <doc>
      <![CDATA[Remove object using a provided comparator.

 @param obj Lookup entry
 @param cmp User provided Comparator. The comparator should expect that the
            proved obj will always be the first method parameter and any
            stored object will be the second parameter.

 @return True if found and removed, else false]]>
      </doc>
    </method>
    <method name="remove" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
    </method>
    <method name="containsAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="java.util.Collection"/>
    </method>
    <method name="addAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="java.util.Collection"/>
    </method>
    <method name="retainAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="java.util.Collection"/>
    </method>
    <method name="removeAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="java.util.Collection"/>
    </method>
    <method name="clear"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="fillRatio" return="double"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns the current size divided by the capacity of the tree. A value
 between 0.0 and 1.0, where 1.0 means that every allocated node in the tree
 is completely full.

 An empty set will return 1.0

 @return the fill ratio of the tree]]>
      </doc>
    </method>
    <method name="compact" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="timeout" type="long"/>
      <doc>
      <![CDATA[Compact all the entries to use the fewest number of nodes in the tree.

 Having a compact tree minimize memory usage, but can cause inserts to get
 slower due to new nodes needs to be allocated as there is no space in any
 of the existing nodes anymore for entries added in the middle of the set.

 Useful to do to reduce memory consumption and if the tree is know to not
 change after compaction or mainly added to at either extreme.

 @param timeout Maximum time to spend compacting the tree set in
                milliseconds.

 @return true if compaction completed, false if aborted]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A memory efficient implementation of RBTree. Instead of having a Node for
 each entry each node contains an array holding 64 entries.

 Based on the Apache Harmony folded TreeMap.

 @param <E> Entry type]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.FoldedTreeSet -->
  <!-- start class org.apache.hadoop.hdfs.util.Holder -->
  <class name="Holder" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Holder" type="T"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="held" type="T"
      transient="false" volatile="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[A Holder is simply a wrapper around some other object. This is useful
 in particular for storing immutable values like boxed Integers in a
 collection without having to do the &quot;lookup&quot; of the value twice.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.Holder -->
  <!-- start class org.apache.hadoop.hdfs.util.LightWeightHashSet -->
  <class name="LightWeightHashSet" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="java.util.Collection"/>
    <constructor name="LightWeightHashSet" type="int, float, float"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@param initCapacity
          Recommended size of the internal array.
 @param maxLoadFactor
          used to determine when to expand the internal array
 @param minLoadFactor
          used to determine when to shrink the internal array]]>
      </doc>
    </constructor>
    <constructor name="LightWeightHashSet"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="LightWeightHashSet" type="int"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="isEmpty" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Check if the set is empty.

 @return true is set empty, false otherwise]]>
      </doc>
    </method>
    <method name="getCapacity" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the current capacity (for testing).]]>
      </doc>
    </method>
    <method name="size" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Return the number of stored elements.]]>
      </doc>
    </method>
    <method name="getIndex" return="int"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="hashCode" type="int"/>
      <doc>
      <![CDATA[Get index in the internal table for a given hash.]]>
      </doc>
    </method>
    <method name="contains" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="key" type="java.lang.Object"/>
      <doc>
      <![CDATA[Check if the set contains given element

 @return true if element present, false otherwise.]]>
      </doc>
    </method>
    <method name="getElement" return="T"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="key" type="T"/>
      <doc>
      <![CDATA[Return the element in this set which is equal to
 the given key, if such an element exists.
 Otherwise returns null.]]>
      </doc>
    </method>
    <method name="getContainedElem" return="T"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="index" type="int"/>
      <param name="key" type="T"/>
      <param name="hashCode" type="int"/>
      <doc>
      <![CDATA[Check if the set contains given element at given index. If it
 does, return that element.

 @return the element, or null, if no element matches]]>
      </doc>
    </method>
    <method name="addAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="toAdd" type="java.util.Collection"/>
      <doc>
      <![CDATA[All all elements in the collection. Expand if necessary.

 @param toAdd - elements to add.
 @return true if the set has changed, false otherwise]]>
      </doc>
    </method>
    <method name="add" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="element" type="T"/>
      <doc>
      <![CDATA[Add given element to the hash table. Expand table if necessary.

 @return true if the element was not present in the table, false otherwise]]>
      </doc>
    </method>
    <method name="addElem" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="element" type="T"/>
      <doc>
      <![CDATA[Add given element to the hash table

 @return true if the element was not present in the table, false otherwise]]>
      </doc>
    </method>
    <method name="remove" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="key" type="java.lang.Object"/>
      <doc>
      <![CDATA[Remove the element corresponding to the key.

 @return If such element exists, return true. Otherwise, return false.]]>
      </doc>
    </method>
    <method name="removeElem" return="org.apache.hadoop.hdfs.util.LightWeightHashSet.LinkedElement"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="key" type="T"/>
      <doc>
      <![CDATA[Remove the element corresponding to the key, given key.hashCode() == index.

 @return If such element exists, return true. Otherwise, return false.]]>
      </doc>
    </method>
    <method name="pollN" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="n" type="int"/>
      <doc>
      <![CDATA[Remove and return n elements from the hashtable.
 The order in which entries are removed is unspecified, and
 and may not correspond to the order in which they were inserted.

 @return first element]]>
      </doc>
    </method>
    <method name="pollAll" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Remove all elements from the set and return them. Clear the entries.]]>
      </doc>
    </method>
    <method name="pollToArray" return="T[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="array" type="T[]"/>
      <doc>
      <![CDATA[Get array.length elements from the set, and put them into the array.]]>
      </doc>
    </method>
    <method name="shrinkIfNecessary"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Checks if we need to shrink, and shrinks if necessary.]]>
      </doc>
    </method>
    <method name="expandIfNecessary"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Checks if we need to expand, and expands if necessary.]]>
      </doc>
    </method>
    <method name="iterator" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="printDetails"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="out" type="java.io.PrintStream"/>
      <doc>
      <![CDATA[Print detailed information of this object.]]>
      </doc>
    </method>
    <method name="clear"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Clear the set. Resize it to the original capacity.]]>
      </doc>
    </method>
    <method name="toArray" return="java.lang.Object[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="toArray" return="U[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="U[]"/>
    </method>
    <method name="containsAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="java.util.Collection"/>
    </method>
    <method name="removeAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="java.util.Collection"/>
    </method>
    <method name="retainAll" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="c" type="java.util.Collection"/>
    </method>
    <field name="DEFAULT_MAX_LOAD_FACTOR" type="float"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="DEFAUT_MIN_LOAD_FACTOR" type="float"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="MINIMUM_CAPACITY" type="int"
      transient="false" volatile="false"
      static="true" final="true" visibility="protected"
      deprecated="not deprecated">
    </field>
    <field name="entries" type="org.apache.hadoop.hdfs.util.LightWeightHashSet.LinkedElement[]"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[An internal array of entries, which are the rows of the hash table. The
 size must be a power of two.]]>
      </doc>
    </field>
    <field name="size" type="int"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[The size of the set (not the entry array).]]>
      </doc>
    </field>
    <field name="modification" type="int"
      transient="false" volatile="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Modification version for fail-fast.

 @see ConcurrentModificationException]]>
      </doc>
    </field>
    <doc>
    <![CDATA[A low memory linked hash set implementation, which uses an array for storing
 the elements and linked lists for collision resolution. This class does not
 support null element.

 This class is not thread safe.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.LightWeightHashSet -->
  <!-- start class org.apache.hadoop.hdfs.util.LightWeightLinkedSet -->
  <class name="LightWeightLinkedSet" extends="org.apache.hadoop.hdfs.util.LightWeightHashSet"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="LightWeightLinkedSet" type="int, float, float"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@param initCapacity
          Recommended size of the internal array.
 @param maxLoadFactor
          used to determine when to expand the internal array
 @param minLoadFactor
          used to determine when to shrink the internal array]]>
      </doc>
    </constructor>
    <constructor name="LightWeightLinkedSet"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="addElem" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="element" type="T"/>
      <doc>
      <![CDATA[Add given element to the hash table

 @return true if the element was not present in the table, false otherwise]]>
      </doc>
    </method>
    <method name="removeElem" return="org.apache.hadoop.hdfs.util.LightWeightLinkedSet.DoubleLinkedElement"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="key" type="T"/>
      <doc>
      <![CDATA[Remove the element corresponding to the key, given key.hashCode() == index.

 @return Return the entry with the element if exists. Otherwise return null.]]>
      </doc>
    </method>
    <method name="pollFirst" return="T"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Remove and return first element on the linked list of all elements.

 @return first element]]>
      </doc>
    </method>
    <method name="pollN" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="n" type="int"/>
      <doc>
      <![CDATA[Remove and return n elements from the hashtable.
 The order in which entries are removed is corresponds 
 to the order in which they were inserted.

 @return first element]]>
      </doc>
    </method>
    <method name="pollAll" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Remove all elements from the set and return them in order. Traverse the
 link list, don't worry about hashtable - faster version of the parent
 method.]]>
      </doc>
    </method>
    <method name="toArray" return="U[]"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="a" type="U[]"/>
    </method>
    <method name="iterator" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="clear"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Clear the set. Resize it to the original capacity.]]>
      </doc>
    </method>
    <method name="getBookmark" return="java.util.Iterator"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Returns a new iterator starting at the bookmarked element.

 @return the iterator to the bookmarked element.]]>
      </doc>
    </method>
    <method name="resetBookmark"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Resets the bookmark to the beginning of the list.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[A low memory linked hash set implementation, which uses an array for storing
 the elements and linked lists for collision resolution. In addition it stores
 elements in a linked list to ensure ordered traversal. This class does not
 support null element.

 This class is not thread safe.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.LightWeightLinkedSet -->
  <!-- start class org.apache.hadoop.hdfs.util.MD5FileUtils -->
  <class name="MD5FileUtils" extends="java.lang.Object"
    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="MD5FileUtils"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="verifySavedMD5"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dataFile" type="java.io.File"/>
      <param name="expectedMD5" type="org.apache.hadoop.io.MD5Hash"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Verify that the previously saved md5 for the given file matches
 expectedMd5.
 @throws IOException]]>
      </doc>
    </method>
    <method name="readStoredMd5ForFile" return="org.apache.hadoop.io.MD5Hash"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dataFile" type="java.io.File"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read the md5 checksum stored alongside the given data file.
 @param dataFile the file containing data
 @return the checksum stored in dataFile.md5]]>
      </doc>
    </method>
    <method name="computeMd5ForFile" return="org.apache.hadoop.io.MD5Hash"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dataFile" type="java.io.File"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Read dataFile and compute its MD5 checksum.]]>
      </doc>
    </method>
    <method name="saveMD5File"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="dataFile" type="java.io.File"/>
      <param name="digest" type="org.apache.hadoop.io.MD5Hash"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Save the ".md5" file that lists the md5sum of another file.
 @param dataFile the original file whose md5 was computed
 @param digest the computed digest
 @throws IOException]]>
      </doc>
    </method>
    <method name="renameMD5File"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="oldDataFile" type="java.io.File"/>
      <param name="newDataFile" type="java.io.File"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="getDigestFileForFile" return="java.io.File"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="file" type="java.io.File"/>
      <doc>
      <![CDATA[@return a reference to the file with .md5 suffix that will
 contain the md5 checksum for the given data file.]]>
      </doc>
    </method>
    <field name="MD5_SUFFIX" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Static functions for dealing with files of the same format
 that the Unix "md5sum" utility writes.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.MD5FileUtils -->
  <!-- start class org.apache.hadoop.hdfs.util.ReadOnlyList.Util -->
  <class name="ReadOnlyList.Util" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Util"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="emptyList" return="org.apache.hadoop.hdfs.util.ReadOnlyList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return an empty list.]]>
      </doc>
    </method>
    <method name="binarySearch" return="int"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="list" type="org.apache.hadoop.hdfs.util.ReadOnlyList"/>
      <param name="key" type="K"/>
      <doc>
      <![CDATA[The same as {@link Collections#binarySearch(List, Object)}
 except that the list is a {@link ReadOnlyList}.

 @return the insertion point defined
         in {@link Collections#binarySearch(List, Object)}.]]>
      </doc>
    </method>
    <method name="asReadOnlyList" return="org.apache.hadoop.hdfs.util.ReadOnlyList"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="list" type="java.util.List"/>
      <doc>
      <![CDATA[@return a {@link ReadOnlyList} view of the given list.]]>
      </doc>
    </method>
    <method name="asList" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="list" type="org.apache.hadoop.hdfs.util.ReadOnlyList"/>
      <doc>
      <![CDATA[@return a {@link List} view of the given list.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Utilities for {@link ReadOnlyList}]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.ReadOnlyList.Util -->
  <!-- start interface org.apache.hadoop.hdfs.util.ReferenceCountMap.ReferenceCounter -->
  <interface name="ReferenceCountMap.ReferenceCounter"    abstract="true"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="getRefCount" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="incrementAndGetRefCount" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="decrementAndGetRefCount" return="int"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[Interface for the reference count holder]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.util.ReferenceCountMap.ReferenceCounter -->
  <!-- start interface org.apache.hadoop.hdfs.util.RwLock -->
  <interface name="RwLock"    abstract="true"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <method name="readLock"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Acquire read lock.]]>
      </doc>
    </method>
    <method name="readUnlock"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Release read lock.]]>
      </doc>
    </method>
    <method name="hasReadLock" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Check if the current thread holds read lock.]]>
      </doc>
    </method>
    <method name="writeLock"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Acquire write lock.]]>
      </doc>
    </method>
    <method name="writeLockInterruptibly"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
      <doc>
      <![CDATA[Acquire write lock, unless interrupted while waiting]]>
      </doc>
    </method>
    <method name="writeUnlock"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Release write lock.]]>
      </doc>
    </method>
    <method name="hasWriteLock" return="boolean"
      abstract="true" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Check if the current thread holds write lock.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Read-write lock interface.]]>
    </doc>
  </interface>
  <!-- end interface org.apache.hadoop.hdfs.util.RwLock -->
  <!-- start class org.apache.hadoop.hdfs.util.XMLUtils.InvalidXmlException -->
  <class name="XMLUtils.InvalidXmlException" extends="java.lang.RuntimeException"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="InvalidXmlException" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Exception that reflects an invalid XML document.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.XMLUtils.InvalidXmlException -->
  <!-- start class org.apache.hadoop.hdfs.util.XMLUtils.Stanza -->
  <class name="XMLUtils.Stanza" extends="java.lang.Object"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="Stanza"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="setValue"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="value" type="java.lang.String"/>
    </method>
    <method name="getValue" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="hasChildren" return="boolean"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
      <doc>
      <![CDATA[Discover if a stanza has a given entry.

 @param name        entry to look for
 
 @return            true if the entry was found]]>
      </doc>
    </method>
    <method name="getChildren" return="java.util.List"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
      <exception name="XMLUtils.InvalidXmlException" type="org.apache.hadoop.hdfs.util.XMLUtils.InvalidXmlException"/>
      <doc>
      <![CDATA[Pull an entry from a stanza.

 @param name        entry to look for
 
 @return            the entry]]>
      </doc>
    </method>
    <method name="getValue" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
      <exception name="XMLUtils.InvalidXmlException" type="org.apache.hadoop.hdfs.util.XMLUtils.InvalidXmlException"/>
      <doc>
      <![CDATA[Pull a string entry from a stanza.

 @param name        entry to look for
 
 @return            the entry]]>
      </doc>
    </method>
    <method name="getValueOrNull" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
      <exception name="XMLUtils.InvalidXmlException" type="org.apache.hadoop.hdfs.util.XMLUtils.InvalidXmlException"/>
      <doc>
      <![CDATA[Pull a string entry from a stanza, or null.

 @param name        entry to look for
 
 @return            the entry, or null if it was not found.]]>
      </doc>
    </method>
    <method name="addChild"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="name" type="java.lang.String"/>
      <param name="child" type="org.apache.hadoop.hdfs.util.XMLUtils.Stanza"/>
      <doc>
      <![CDATA[Add an entry to a stanza.

 @param name        name of the entry to add
 @param child       the entry to add]]>
      </doc>
    </method>
    <method name="toString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Convert a stanza to a human-readable string.]]>
      </doc>
    </method>
    <doc>
    <![CDATA[Represents a bag of key-value pairs encountered during parsing an XML
 file.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.XMLUtils.Stanza -->
  <!-- start class org.apache.hadoop.hdfs.util.XMLUtils.UnmanglingError -->
  <class name="XMLUtils.UnmanglingError" extends="java.lang.RuntimeException"
    abstract="false"
    static="true" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="UnmanglingError" type="java.lang.String, java.lang.Exception"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <constructor name="UnmanglingError" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <doc>
    <![CDATA[Exception that reflects a string that cannot be unmangled.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.util.XMLUtils.UnmanglingError -->
</package>
<package name="org.apache.hadoop.hdfs.web">
  <!-- start class org.apache.hadoop.hdfs.web.AuthFilter -->
  <class name="AuthFilter" extends="org.apache.hadoop.security.authentication.server.AuthenticationFilter"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="AuthFilter"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getConfiguration" return="java.util.Properties"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="protected"
      deprecated="not deprecated">
      <param name="prefix" type="java.lang.String"/>
      <param name="config" type="javax.servlet.FilterConfig"/>
      <exception name="ServletException" type="javax.servlet.ServletException"/>
      <doc>
      <![CDATA[Returns the filter configuration properties,
 including the ones prefixed with {@link #CONF_PREFIX}.
 The prefix is removed from the returned property names.

 @param prefix parameter not used.
 @param config parameter contains the initialization values.
 @return Hadoop-Auth configuration properties.
 @throws ServletException]]>
      </doc>
    </method>
    <method name="doFilter"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="request" type="javax.servlet.ServletRequest"/>
      <param name="response" type="javax.servlet.ServletResponse"/>
      <param name="filterChain" type="javax.servlet.FilterChain"/>
      <exception name="IOException" type="java.io.IOException"/>
      <exception name="ServletException" type="javax.servlet.ServletException"/>
    </method>
    <field name="CONF_PREFIX" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Subclass of {@link AuthenticationFilter} that
 obtains Hadoop-Auth configuration for webhdfs.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.AuthFilter -->
  <!-- start class org.apache.hadoop.hdfs.web.JsonUtil -->
  <class name="JsonUtil" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="JsonUtil"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="token" type="org.apache.hadoop.security.token.Token"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Convert a token object to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="java.lang.Exception"/>
      <doc>
      <![CDATA[Convert an exception object to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="key" type="java.lang.String"/>
      <param name="value" type="java.lang.Object"/>
      <doc>
      <![CDATA[Convert a key-value pair to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="status" type="org.apache.hadoop.hdfs.protocol.HdfsFileStatus"/>
      <param name="includeType" type="boolean"/>
      <doc>
      <![CDATA[Convert a HdfsFileStatus object to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="locatedblocks" type="org.apache.hadoop.hdfs.protocol.LocatedBlocks"/>
      <exception name="IOException" type="java.io.IOException"/>
      <doc>
      <![CDATA[Convert LocatedBlocks to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="contentsummary" type="org.apache.hadoop.fs.ContentSummary"/>
      <doc>
      <![CDATA[Convert a ContentSummary to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="checksum" type="org.apache.hadoop.fs.MD5MD5CRC32FileChecksum"/>
      <doc>
      <![CDATA[Convert a MD5MD5CRC32FileChecksum to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="status" type="org.apache.hadoop.fs.permission.AclStatus"/>
      <doc>
      <![CDATA[Convert a AclStatus object to a Json string.]]>
      </doc>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xAttrs" type="java.util.List"/>
      <param name="encoding" type="org.apache.hadoop.fs.XAttrCodec"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="xAttrs" type="java.util.List"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <method name="toJsonString" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="true" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="obj" type="java.lang.Object"/>
      <exception name="IOException" type="java.io.IOException"/>
    </method>
    <doc>
    <![CDATA[JSON Utilities]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.JsonUtil -->
  <!-- start class org.apache.hadoop.hdfs.web.ParamFilter -->
  <class name="ParamFilter" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="com.sun.jersey.spi.container.ResourceFilter"/>
    <constructor name="ParamFilter"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getRequestFilter" return="com.sun.jersey.spi.container.ContainerRequestFilter"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getResponseFilter" return="com.sun.jersey.spi.container.ContainerResponseFilter"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <doc>
    <![CDATA[A filter to change parameter names to lower cases
 so that parameter names are considered as case insensitive.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.ParamFilter -->
</package>
<package name="org.apache.hadoop.hdfs.web.resources">
  <!-- start class org.apache.hadoop.hdfs.web.resources.ExceptionHandler -->
  <class name="ExceptionHandler" extends="java.lang.Object"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="javax.ws.rs.ext.ExceptionMapper"/>
    <constructor name="ExceptionHandler"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="toResponse" return="javax.ws.rs.core.Response"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="e" type="java.lang.Exception"/>
    </method>
    <method name="initResponse"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="response" type="javax.servlet.http.HttpServletResponse"/>
    </method>
    <field name="LOG" type="org.apache.commons.logging.Log"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
    </field>
    <doc>
    <![CDATA[Handle exceptions.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.resources.ExceptionHandler -->
  <!-- start class org.apache.hadoop.hdfs.web.resources.NamenodeAddressParam -->
  <class name="NamenodeAddressParam" extends="org.apache.hadoop.hdfs.web.resources.StringParam"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="NamenodeAddressParam" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor.
 @param str a string representation of the parameter value.]]>
      </doc>
    </constructor>
    <constructor name="NamenodeAddressParam" type="org.apache.hadoop.hdfs.server.namenode.NameNode"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Construct an object using the RPC address of the given namenode.]]>
      </doc>
    </constructor>
    <method name="getName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="NAME" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Parameter name.]]>
      </doc>
    </field>
    <field name="DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Default parameter value.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[Namenode RPC address parameter.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.resources.NamenodeAddressParam -->
  <!-- start class org.apache.hadoop.hdfs.web.resources.TokenKindParam -->
  <class name="TokenKindParam" extends="org.apache.hadoop.hdfs.web.resources.StringParam"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="TokenKindParam" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor.
 @param str a string representation of the parameter value.]]>
      </doc>
    </constructor>
    <method name="getName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="NAME" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Parameter name]]>
      </doc>
    </field>
    <field name="DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Default parameter value.]]>
      </doc>
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.resources.TokenKindParam -->
  <!-- start class org.apache.hadoop.hdfs.web.resources.TokenServiceParam -->
  <class name="TokenServiceParam" extends="org.apache.hadoop.hdfs.web.resources.StringParam"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="TokenServiceParam" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor.
 @param str a string representation of the parameter value.]]>
      </doc>
    </constructor>
    <method name="getName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <field name="NAME" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Parameter name]]>
      </doc>
    </field>
    <field name="DEFAULT" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Default parameter value.]]>
      </doc>
    </field>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.resources.TokenServiceParam -->
  <!-- start class org.apache.hadoop.hdfs.web.resources.UriFsPathParam -->
  <class name="UriFsPathParam" extends="org.apache.hadoop.hdfs.web.resources.StringParam"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <constructor name="UriFsPathParam" type="java.lang.String"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Constructor.
 @param str a string representation of the parameter value.]]>
      </doc>
    </constructor>
    <method name="getName" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getAbsolutePath" return="java.lang.String"
      abstract="false" native="false" synchronized="false"
      static="false" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[@return the absolute path.]]>
      </doc>
    </method>
    <field name="NAME" type="java.lang.String"
      transient="false" volatile="false"
      static="true" final="true" visibility="public"
      deprecated="not deprecated">
      <doc>
      <![CDATA[Parameter name.]]>
      </doc>
    </field>
    <doc>
    <![CDATA[The FileSystem path parameter.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.resources.UriFsPathParam -->
  <!-- start class org.apache.hadoop.hdfs.web.resources.UserProvider -->
  <class name="UserProvider" extends="com.sun.jersey.server.impl.inject.AbstractHttpContextInjectable"
    abstract="false"
    static="false" final="false" visibility="public"
    deprecated="not deprecated">
    <implements name="com.sun.jersey.spi.inject.InjectableProvider"/>
    <constructor name="UserProvider"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </constructor>
    <method name="getValue" return="org.apache.hadoop.security.UserGroupInformation"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="context" type="com.sun.jersey.api.core.HttpContext"/>
    </method>
    <method name="getScope" return="com.sun.jersey.core.spi.component.ComponentScope"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
    </method>
    <method name="getInjectable" return="com.sun.jersey.spi.inject.Injectable"
      abstract="false" native="false" synchronized="false"
      static="false" final="false" visibility="public"
      deprecated="not deprecated">
      <param name="componentContext" type="com.sun.jersey.core.spi.component.ComponentContext"/>
      <param name="context" type="javax.ws.rs.core.Context"/>
      <param name="type" type="java.lang.reflect.Type"/>
    </method>
    <doc>
    <![CDATA[Inject user information to http operations.]]>
    </doc>
  </class>
  <!-- end class org.apache.hadoop.hdfs.web.resources.UserProvider -->
</package>

</api>
